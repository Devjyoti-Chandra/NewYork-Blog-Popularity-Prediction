{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing, metrics, ensemble, neighbors, linear_model, tree, model_selection\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/NYTimesBlogTrain.csv')\n",
    "test=pd.read_csv('data/NYTimesBlogTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More School Daze</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>508</td>\n",
       "      <td>2014-09-01 22:00:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New 96-Page Murakami Work Coming in December</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>285</td>\n",
       "      <td>2014-09-01 21:14:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Public Pension Funds Stay Mum on Corporate Expats</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>1211</td>\n",
       "      <td>2014-09-01 21:05:36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Boot Camp for Bankers</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>1405</td>\n",
       "      <td>2014-09-01 20:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Of Little Help to Older Knees</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>181</td>\n",
       "      <td>2014-09-01 18:58:51</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  \\\n",
       "0  Business  Crosswords/Games            NaN   \n",
       "1   Culture              Arts            NaN   \n",
       "2  Business      Business Day       Dealbook   \n",
       "3  Business      Business Day       Dealbook   \n",
       "4   Science            Health            NaN   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                                   More School Daze   \n",
       "1       New 96-Page Murakami Work Coming in December   \n",
       "2  Public Pension Funds Stay Mum on Corporate Expats   \n",
       "3                              Boot Camp for Bankers   \n",
       "4                      Of Little Help to Older Knees   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...   \n",
       "1  The Strange Library will arrive just three and...   \n",
       "2  Public pension funds have major stakes in Amer...   \n",
       "3  As they struggle to find new business to bolst...   \n",
       "4  Middle-aged and older patients are unlikely to...   \n",
       "\n",
       "                                            Abstract  WordCount  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...        508   \n",
       "1  The Strange Library will arrive just three and...        285   \n",
       "2  Public pension funds have major stakes in Amer...       1211   \n",
       "3  As they struggle to find new business to bolst...       1405   \n",
       "4  Middle-aged and older patients are unlikely to...        181   \n",
       "\n",
       "               PubDate  Popular  UniqueID  \n",
       "0  2014-09-01 22:00:09        1         1  \n",
       "1  2014-09-01 21:14:07        0         2  \n",
       "2  2014-09-01 21:05:36        0         3  \n",
       "3  2014-09-01 20:43:34        1         4  \n",
       "4  2014-09-01 18:58:51        1         5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Culture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'Birdman' Tops the Gothams</td>\n",
       "      <td>The backstage tale won two awards; Citizenfour...</td>\n",
       "      <td>The backstage tale won two awards; Citizenfour...</td>\n",
       "      <td>111</td>\n",
       "      <td>2014-12-01 22:45:24</td>\n",
       "      <td>6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'Sleepy Hollow' Recap: A Not-So-Shocking Death</td>\n",
       "      <td>In the fall season finale, a question of where...</td>\n",
       "      <td>In the fall season finale, a question of where...</td>\n",
       "      <td>558</td>\n",
       "      <td>2014-12-01 22:01:34</td>\n",
       "      <td>6534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drinking Buddy For Falstaff</td>\n",
       "      <td>In which Timothy Polin reveals his potty mouth.</td>\n",
       "      <td>In which Timothy Polin reveals his potty mouth.</td>\n",
       "      <td>788</td>\n",
       "      <td>2014-12-01 22:00:26</td>\n",
       "      <td>6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Encouraging Public Service, Through Wall Stree...</td>\n",
       "      <td>The debate about pay for Wall Street executive...</td>\n",
       "      <td>The debate about pay for Wall Street executive...</td>\n",
       "      <td>915</td>\n",
       "      <td>2014-12-01 21:04:13</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Therapy Prevents Repeat Suicide Attempts</td>\n",
       "      <td>Short-term psychotherapy may be an effective w...</td>\n",
       "      <td>Short-term psychotherapy may be an effective w...</td>\n",
       "      <td>213</td>\n",
       "      <td>2014-12-01 19:13:20</td>\n",
       "      <td>6537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  \\\n",
       "0   Culture               NaN            NaN   \n",
       "1   Culture              Arts            NaN   \n",
       "2  Business  Crosswords/Games            NaN   \n",
       "3  Business      Business Day       Dealbook   \n",
       "4   Science            Health            NaN   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                         'Birdman' Tops the Gothams   \n",
       "1     'Sleepy Hollow' Recap: A Not-So-Shocking Death   \n",
       "2                        Drinking Buddy For Falstaff   \n",
       "3  Encouraging Public Service, Through Wall Stree...   \n",
       "4           Therapy Prevents Repeat Suicide Attempts   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  The backstage tale won two awards; Citizenfour...   \n",
       "1  In the fall season finale, a question of where...   \n",
       "2    In which Timothy Polin reveals his potty mouth.   \n",
       "3  The debate about pay for Wall Street executive...   \n",
       "4  Short-term psychotherapy may be an effective w...   \n",
       "\n",
       "                                            Abstract  WordCount  \\\n",
       "0  The backstage tale won two awards; Citizenfour...        111   \n",
       "1  In the fall season finale, a question of where...        558   \n",
       "2    In which Timothy Polin reveals his potty mouth.        788   \n",
       "3  The debate about pay for Wall Street executive...        915   \n",
       "4  Short-term psychotherapy may be an effective w...        213   \n",
       "\n",
       "               PubDate  UniqueID  \n",
       "0  2014-12-01 22:45:24      6533  \n",
       "1  2014-12-01 22:01:34      6534  \n",
       "2  2014-12-01 22:00:26      6535  \n",
       "3  2014-12-01 21:04:13      6536  \n",
       "4  2014-12-01 19:13:20      6537  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definig function for cheching NA values in datasets.\n",
    "# We will discard the columns having NA values greater than 30%.\n",
    "\n",
    "def na_checker(data):   \n",
    "    col_to_discard = []\n",
    "    col_to_fill = []\n",
    "    for i in data.columns:\n",
    "        p = round(1-(float(data[i].count())/float(len(data[i]))),4) \n",
    "        if p > 0.3:\n",
    "            col_to_discard.append((p,i))\n",
    "        elif p <= 0.3 and p > 0:\n",
    "            col_to_fill.append((p,i))\n",
    "    print(\"Discard following columns: \", col_to_discard)\n",
    "    print(\"Consider filling those columns: \", col_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard following columns:  [(0.3521, 'SectionName'), (0.7388, 'SubsectionName')]\n",
      "Consider filling those columns:  [(0.2826, 'NewsDesk'), (0.0014, 'Snippet'), (0.0014, 'Abstract')]\n"
     ]
    }
   ],
   "source": [
    "na_checker(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard following columns:  [(0.3005, 'NewsDesk'), (0.3203, 'SectionName'), (0.7219, 'SubsectionName')]\n",
      "Consider filling those columns:  [(0.0021, 'Snippet'), (0.0043, 'Abstract')]\n"
     ]
    }
   ],
   "source": [
    "na_checker(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems both Snippet and Abstract both give the same information. So we will drop one of them. Lets drop Abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['Abstract'], 1, inplace=True)\n",
    "test.drop(['Abstract'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the dataset contains a lot of missing values, we need to look into the data and impute these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.NewsDesk.fillna('Unknown', inplace=True)\n",
    "train.SectionName.fillna('Unknown', inplace=True)\n",
    "train.SubsectionName.fillna('Unknown', inplace=True)\n",
    "\n",
    "test.NewsDesk.fillna('Unknown', inplace=True)\n",
    "test.SectionName.fillna('Unknown', inplace=True)\n",
    "test.SubsectionName.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NewsDesk</th>\n",
       "      <th>Business</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Magazine</th>\n",
       "      <th>Metro</th>\n",
       "      <th>National</th>\n",
       "      <th>OpEd</th>\n",
       "      <th>Science</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Styles</th>\n",
       "      <th>TStyle</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SectionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arts</th>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Day</th>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crosswords/Games</th>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magazine</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multimedia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N.Y. / Region</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opinion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Style</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>World</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NewsDesk          Business  Culture  Foreign  Magazine  Metro  National  OpEd  \\\n",
       "SectionName                                                                     \n",
       "Arts                     0      675        0         0      0         0     0   \n",
       "Business Day          1091        0        0         0      0         0     0   \n",
       "Crosswords/Games       122        0        0         0      0         0     0   \n",
       "Health                   0        0        0         0      0         0     0   \n",
       "Magazine                 0        0        0        31      0         0     0   \n",
       "Multimedia               0        0        0         0      0         0     0   \n",
       "N.Y. / Region            0        0        0         0    198         0     0   \n",
       "Open                     0        0        0         0      0         0     0   \n",
       "Opinion                  0        0        0         0      0         0   520   \n",
       "Sports                   0        0        0         0      0         0     0   \n",
       "Style                    0        0        0         0      0         0     0   \n",
       "Technology             330        0        0         0      0         0     0   \n",
       "Travel                   0        0        0         0      0         0     0   \n",
       "U.S.                     0        0        0         0      0         2     0   \n",
       "Unknown                  5        1      163         0      0         2     1   \n",
       "World                    0        0      212         0      0         0     0   \n",
       "\n",
       "NewsDesk          Science  Sports  Styles  TStyle  Travel  Unknown  \n",
       "SectionName                                                         \n",
       "Arts                    0       0       0       0       0        0  \n",
       "Business Day            0       0       0       0       0        1  \n",
       "Crosswords/Games        0       0       0       0       0        1  \n",
       "Health                192       0       1       0       0        1  \n",
       "Magazine                0       0       0       0       0        0  \n",
       "Multimedia              0       0       0       0       0      141  \n",
       "N.Y. / Region           0       0       0       0       0        0  \n",
       "Open                    0       0       0       0       0        4  \n",
       "Opinion                 0       0       0       0       0       87  \n",
       "Sports                  0       1       0       0       0        0  \n",
       "Style                   0       0       2       0       0        0  \n",
       "Technology              0       0       0       0       0        0  \n",
       "Travel                  0       0       0       0     116        1  \n",
       "U.S.                    0       0     177       0       0      326  \n",
       "Unknown                 2       1     117     724       0     1284  \n",
       "World                   0       0       0       0       0        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['SectionName'], train['NewsDesk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[operator.and_(train['SectionName']=='Arts' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Culture'\n",
    "train.loc[operator.and_(train['SectionName']=='Business Day' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "train.loc[operator.and_(train['SectionName']=='Crosswords/Games' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "train.loc[operator.and_(train['SectionName']=='Health' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Science'\n",
    "train.loc[operator.and_(train['SectionName']=='Magazine' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Magazine'\n",
    "train.loc[operator.and_(train['SectionName']=='Arts' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "train.loc[operator.and_(train['SectionName']=='N.Y. / Region' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Metro'\n",
    "\n",
    "train.loc[operator.and_(train['SectionName']=='Opinion' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'OpEd'\n",
    "train.loc[operator.and_(train['SectionName']=='Arts' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "train.loc[operator.and_(train['SectionName']=='Arts' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "train.loc[operator.and_(train['SectionName']=='Technology' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "train.loc[operator.and_(train['SectionName']=='Travel' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Travel'\n",
    "train.loc[operator.and_(train['SectionName']=='U.S.' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Styles'\n",
    "train.loc[operator.and_(train['SectionName']=='World' ,train['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Foreign'\n",
    "\n",
    "# Removing National and Sports Label as they are not present in test set.\n",
    "train.loc[train['NewsDesk']=='National', 'NewsDesk'] = 'Styles'\n",
    "train.loc[train['NewsDesk']=='Sports', 'NewsDesk'] = 'TStyle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[operator.and_(test['SectionName']=='Arts' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Culture'\n",
    "test.loc[operator.and_(test['SectionName']=='Business Day' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "test.loc[operator.and_(test['SectionName']=='Crosswords/Games' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "test.loc[operator.and_(test['SectionName']=='Health' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Science'\n",
    "test.loc[operator.and_(test['SectionName']=='Magazine' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Magazine'\n",
    "test.loc[operator.and_(test['SectionName']=='Arts' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "test.loc[operator.and_(test['SectionName']=='N.Y. / Region' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Metro'\n",
    "\n",
    "test.loc[operator.and_(test['SectionName']=='Opinion' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'OpEd'\n",
    "test.loc[operator.and_(test['SectionName']=='Arts' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "test.loc[operator.and_(test['SectionName']=='Arts' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Arts'\n",
    "test.loc[operator.and_(test['SectionName']=='Technology' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Business'\n",
    "test.loc[operator.and_(test['SectionName']=='Travel' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Travel'\n",
    "test.loc[operator.and_(test['SectionName']=='U.S.' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Styles'\n",
    "test.loc[operator.and_(test['SectionName']=='World' ,test['NewsDesk']=='Unknown'), 'NewsDesk'] = 'Foreign'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PubDate to datetime format. Create three new columns: Month, Weekday and Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['PubDate'] = pd.to_datetime(train['PubDate'])\n",
    "train['Month'] = train['PubDate'].dt.month\n",
    "train['Weekday'] = train['PubDate'].dt.weekday\n",
    "train['Hour'] = train['PubDate'].dt.hour\n",
    "\n",
    "test['PubDate'] = pd.to_datetime(test['PubDate'])\n",
    "test['Month'] = test['PubDate'].dt.month\n",
    "test['Weekday'] = test['PubDate'].dt.weekday\n",
    "test['Hour'] = test['PubDate'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After going through the dataset it was found that few phrase in the Headline did not attract the readers. So a new colunm was created which indicates whether the Headline contains these phrases or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Popular</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4313</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Popular      0     1\n",
       "Headline            \n",
       "0         4313  1093\n",
       "1         1126     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Headline'].str.contains(\"Word of the day|pictures|Raising|on this day|tune into the times|\"+\n",
    "                                           \"morning agenda|today in politics|Weekend reading|International Arts|\"+\n",
    "                                           \"what we're|poem|poet|poetry|New York Parking Alert|The Daily Gift|\"+\n",
    "                                           \"Classical Playlist|NYTLNreads|behind the cover story|politics helpline|\"+\n",
    "                                           \"the upshot|verbatim|text to text|weekly news|first draft|analytics|\"+\n",
    "                                           \"6 Q's About the News|Q. and A.|'Big Ticket|in performance|popcast|walkabout|\"+\n",
    "                                           \"box office|inside the times|sneak peeks|under cover|lunchtime|review|\"+\n",
    "                                           \"weekly wrap|test yourself|today in small business|fashion week|\"+\n",
    "                                           \"Daily clip report|throwback\", case=False).astype(int), train['Popular'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['HeadLine_n']=train['Headline'].str.contains(\"Word of the day|pictures|Raising|on this day|tune into the times|\"+\n",
    "                                           \"morning agenda|today in politics|Weekend reading|International Arts|\"+\n",
    "                                           \"what we're|poem|poet|poetry|New York Parking Alert|The Daily Gift|\"+\n",
    "                                           \"Classical Playlist|NYTLNreads|behind the cover story|politics helpline|\"+\n",
    "                                           \"the upshot|verbatim|text to text|weekly news|first draft|analytics|\"+\n",
    "                                           \"6 Q's About the News|Q. and A.|'Big Ticket|in performance|popcast|walkabout|\"+\n",
    "                                           \"box office|inside the times|sneak peeks|under cover|lunchtime|review|\"+\n",
    "                                           \"weekly wrap|test yourself|today in small business|fashion week|\"+\n",
    "                                           \"Daily clip report|throwback\", case=False).astype(int)\n",
    "\n",
    "test['HeadLine_n']=train['Headline'].str.contains(\"Word of the day|pictures|Raising|on this day|tune into the times|\"+\n",
    "                                           \"morning agenda|today in politics|Weekend reading|International Arts|\"+\n",
    "                                           \"what we're|poem|poet|poetry|New York Parking Alert|The Daily Gift|\"+\n",
    "                                           \"Classical Playlist|NYTLNreads|behind the cover story|politics helpline|\"+\n",
    "                                           \"the upshot|verbatim|text to text|weekly news|first draft|analytics|\"+\n",
    "                                           \"6 Q's About the News|Q. and A.|'Big Ticket|in performance|popcast|walkabout|\"+\n",
    "                                           \"box office|inside the times|sneak peeks|under cover|lunchtime|review|\"+\n",
    "                                           \"weekly wrap|test yourself|today in small business|fashion week|\"+\n",
    "                                           \"Daily clip report|throwback\", case=False).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can check whether the classes are  balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbaeaf0cc18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAENCAYAAACWzLaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbaeb7456a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_srs = train['Popular'].value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Popular', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the classes are imbalanced, we will use StratifiedKFold instead of KFold while validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After cleaning Snippet and HeadLine, we will create TF-IDF and count word matrix respectively, to make some insights of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Snippet'].fillna('unavailable', inplace=True)\n",
    "test['Snippet'].fillna('unavailable', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Snippet'] = train['Snippet'].apply(lambda x: (x).lower())\n",
    "test['Snippet'] = test['Snippet'].apply(lambda x: (x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to clean the text\n",
    "# adapted from a kaggle kernal\n",
    "def cleanData(text):\n",
    "        \n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"Find\", \"find\", text) \n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Snippet'] = train['Snippet'].apply(lambda x: cleanData(x))\n",
    "test['Snippet'] = test['Snippet'].apply(lambda x: cleanData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for stemming and lemmatizing the text\n",
    "\n",
    "def cleanData2(text, stemming = False, lemmatize=False):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r'-', r'', txt)\n",
    "    \n",
    "   \n",
    "    if stemming:\n",
    "        st = EnglishStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "\n",
    "    \n",
    "    if lemmatize:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w) for w in txt.split()])\n",
    "        \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Snippet'] = train['Snippet'].map(lambda x: cleanData2(x,  stemming = True, lemmatize=True))\n",
    "test['Snippet'] = test['Snippet'].map(lambda x: cleanData2(x,  stemming = True, lemmatize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's us explore Headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of unique words in the text\n",
    "train['num_unique_words'] = train['Headline'].apply(lambda x: len(set(str(x).split())))\n",
    "test['num_unique_words'] = test['Headline'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters in the text\n",
    "train['num_chars'] = train['Headline'].apply(lambda x: len(str(x)))\n",
    "test['num_chars'] = test['Headline'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Number of stopwords in the text \n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "train['num_stopwords'] = train['Headline'].apply(lambda x: len([w for w in str(x).split() if w in eng_stopwords]))\n",
    "test['num_stopwords'] = test['Headline'].apply(lambda x: len([w for w in str(x).split() if w in eng_stopwords]))\n",
    "\n",
    "# Number of punctuations in the text\n",
    "train['num_punctuations'] = train['Headline'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test['num_punctuations'] = test['Headline'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "# Average length of the words in the text\n",
    "train['mean_word_len'] = train['Headline'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test['mean_word_len'] = test['Headline'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit transform the tfidf vectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(analyzer='char',stop_words='english', max_features=1000, ngram_range=(1,3))\n",
    "full_tfidf = tfidf_vec.fit_transform(train['Snippet'].values.tolist() + test['Snippet'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['Snippet'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['Snippet'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_comp = 50\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "train_df = pd.concat([train, train_svd], axis=1)\n",
    "test_df = pd.concat([test, test_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train_svd.columns:\n",
    "    train_df[i] = round(train_df[i], 4)\n",
    "    test_df[i] = round(test_df[i], 4)\n",
    "    \n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Headline'] = train['Headline'].map(lambda x: re.sub(r\"[^A-Za-z]\", \" \", x))\n",
    "test['Headline'] = test['Headline'].map(lambda x: re.sub(r\"[^A-Za-z]\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit transform the count vectorizer\n",
    "count_vec = CountVectorizer(stop_words='english', analyzer='word', min_df=0.01, ngram_range=(1,3))\n",
    "count_vec.fit(train['Headline'].values.tolist() + test['Headline'].values.tolist())\n",
    "train_count = count_vec.transform(train['Headline'].values.tolist())\n",
    "test_count = count_vec.transform(test['Headline'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_count = pd.DataFrame(train_count.A, columns=count_vec.get_feature_names())\n",
    "test_count = pd.DataFrame(test_count.A, columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_count], axis=1)\n",
    "test_df = pd.concat([test_df, test_count], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.columns = train_df.columns.str.replace('\\s+', '_')\n",
    "test_df.columns = test_df.columns.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HeadLine_n</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>svd_word_3</th>\n",
       "      <th>svd_word_4</th>\n",
       "      <th>svd_word_5</th>\n",
       "      <th>svd_word_6</th>\n",
       "      <th>svd_word_7</th>\n",
       "      <th>svd_word_8</th>\n",
       "      <th>svd_word_9</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "      <th>svd_word_20</th>\n",
       "      <th>svd_word_21</th>\n",
       "      <th>svd_word_22</th>\n",
       "      <th>svd_word_23</th>\n",
       "      <th>svd_word_24</th>\n",
       "      <th>svd_word_25</th>\n",
       "      <th>svd_word_26</th>\n",
       "      <th>svd_word_27</th>\n",
       "      <th>svd_word_28</th>\n",
       "      <th>svd_word_29</th>\n",
       "      <th>svd_word_30</th>\n",
       "      <th>svd_word_31</th>\n",
       "      <th>svd_word_32</th>\n",
       "      <th>svd_word_33</th>\n",
       "      <th>svd_word_34</th>\n",
       "      <th>svd_word_35</th>\n",
       "      <th>svd_word_36</th>\n",
       "      <th>svd_word_37</th>\n",
       "      <th>svd_word_38</th>\n",
       "      <th>svd_word_39</th>\n",
       "      <th>svd_word_40</th>\n",
       "      <th>svd_word_41</th>\n",
       "      <th>svd_word_42</th>\n",
       "      <th>svd_word_43</th>\n",
       "      <th>svd_word_44</th>\n",
       "      <th>svd_word_45</th>\n",
       "      <th>svd_word_46</th>\n",
       "      <th>svd_word_47</th>\n",
       "      <th>svd_word_48</th>\n",
       "      <th>svd_word_49</th>\n",
       "      <th>big</th>\n",
       "      <th>billion</th>\n",
       "      <th>business</th>\n",
       "      <th>china</th>\n",
       "      <th>daily</th>\n",
       "      <th>day</th>\n",
       "      <th>deal</th>\n",
       "      <th>ebola</th>\n",
       "      <th>fashion</th>\n",
       "      <th>fashion_week</th>\n",
       "      <th>million</th>\n",
       "      <th>morning</th>\n",
       "      <th>new</th>\n",
       "      <th>new_york</th>\n",
       "      <th>new_york_today</th>\n",
       "      <th>news</th>\n",
       "      <th>obama</th>\n",
       "      <th>paris</th>\n",
       "      <th>pictures</th>\n",
       "      <th>politics</th>\n",
       "      <th>report</th>\n",
       "      <th>says</th>\n",
       "      <th>small</th>\n",
       "      <th>spring</th>\n",
       "      <th>spring_summer</th>\n",
       "      <th>summer</th>\n",
       "      <th>test</th>\n",
       "      <th>today</th>\n",
       "      <th>week</th>\n",
       "      <th>word</th>\n",
       "      <th>york</th>\n",
       "      <th>york_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>More School Daze</td>\n",
       "      <td>a puzzl from ethan cooper that remind me that ...</td>\n",
       "      <td>508</td>\n",
       "      <td>2014-09-01 22:00:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>-0.0183</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0851</td>\n",
       "      <td>-0.0820</td>\n",
       "      <td>-0.0373</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>-0.0635</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.1179</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>-0.0344</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.0611</td>\n",
       "      <td>-0.0483</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>-0.0649</td>\n",
       "      <td>-0.0768</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>New 96-Page Murakami Work Coming in December</td>\n",
       "      <td>the strang librari will arriv just three and a...</td>\n",
       "      <td>285</td>\n",
       "      <td>2014-09-01 21:14:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0423</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>-0.0362</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>-0.0968</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0821</td>\n",
       "      <td>-0.0137</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>-0.0783</td>\n",
       "      <td>-0.1023</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.1031</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0960</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>-0.0616</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0988</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>-0.0908</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-0.0937</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>-0.0461</td>\n",
       "      <td>-0.0377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Public Pension Funds Stay Mum on Corporate Expats</td>\n",
       "      <td>public pension fund have major stake in americ...</td>\n",
       "      <td>1211</td>\n",
       "      <td>2014-09-01 21:05:36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>-0.1017</td>\n",
       "      <td>-0.1037</td>\n",
       "      <td>-0.0359</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0863</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0149</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0123</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>-0.0716</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0638</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>-0.0588</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>-0.0374</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0775</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Boot Camp for Bankers</td>\n",
       "      <td>a they struggl to find new busi to bolster slu...</td>\n",
       "      <td>1405</td>\n",
       "      <td>2014-09-01 20:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.0855</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>-0.0524</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.0484</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0787</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>-0.0761</td>\n",
       "      <td>-0.0777</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>-0.1129</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Of Little Help to Older Knees</td>\n",
       "      <td>middl age and older patient are unlik to benef...</td>\n",
       "      <td>181</td>\n",
       "      <td>2014-09-01 18:58:51</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>-0.0370</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0685</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>-0.0746</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>-0.0438</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>-0.0181</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  \\\n",
       "0  Business  Crosswords/Games        Unknown   \n",
       "1   Culture              Arts        Unknown   \n",
       "2  Business      Business Day       Dealbook   \n",
       "3  Business      Business Day       Dealbook   \n",
       "4   Science            Health        Unknown   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                                   More School Daze   \n",
       "1       New 96-Page Murakami Work Coming in December   \n",
       "2  Public Pension Funds Stay Mum on Corporate Expats   \n",
       "3                              Boot Camp for Bankers   \n",
       "4                      Of Little Help to Older Knees   \n",
       "\n",
       "                                             Snippet  WordCount  \\\n",
       "0  a puzzl from ethan cooper that remind me that ...        508   \n",
       "1  the strang librari will arriv just three and a...        285   \n",
       "2  public pension fund have major stake in americ...       1211   \n",
       "3  a they struggl to find new busi to bolster slu...       1405   \n",
       "4  middl age and older patient are unlik to benef...        181   \n",
       "\n",
       "              PubDate  Popular  UniqueID  Month  Weekday  Hour  HeadLine_n  \\\n",
       "0 2014-09-01 22:00:09        1         1      9        0    22           0   \n",
       "1 2014-09-01 21:14:07        0         2      9        0    21           0   \n",
       "2 2014-09-01 21:05:36        0         3      9        0    21           0   \n",
       "3 2014-09-01 20:43:34        1         4      9        0    20           0   \n",
       "4 2014-09-01 18:58:51        1         5      9        0    18           0   \n",
       "\n",
       "   num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
       "0                 3         16              0                 0   \n",
       "1                 7         44              1                 1   \n",
       "2                 8         49              1                 0   \n",
       "3                 4         21              1                 0   \n",
       "4                 6         29              1                 0   \n",
       "\n",
       "   mean_word_len  svd_word_0  svd_word_1  svd_word_2  svd_word_3  svd_word_4  \\\n",
       "0       4.666667      0.6179     -0.0183     -0.0439     -0.0037      0.0245   \n",
       "1       5.428571      0.7489      0.0058     -0.0423      0.0001      0.1064   \n",
       "2       5.250000      0.7755     -0.1017     -0.1037     -0.0359     -0.0205   \n",
       "3       4.500000      0.7251      0.0172     -0.0855      0.0488      0.0298   \n",
       "4       4.000000      0.8294      0.0691      0.0382     -0.0370      0.0033   \n",
       "\n",
       "   svd_word_5  svd_word_6  svd_word_7  svd_word_8  svd_word_9  svd_word_10  \\\n",
       "0      0.0398      0.0723      0.0667     -0.0225     -0.0516       0.1326   \n",
       "1      0.0159     -0.0735     -0.0085      0.0660     -0.0362       0.0184   \n",
       "2     -0.0621      0.0145      0.0155     -0.0092     -0.0863       0.0821   \n",
       "3     -0.0177     -0.0255     -0.0524      0.0064     -0.0008      -0.0021   \n",
       "4      0.0789     -0.0046     -0.0685      0.0280     -0.0341      -0.0207   \n",
       "\n",
       "   svd_word_11  svd_word_12  svd_word_13  svd_word_14  svd_word_15  \\\n",
       "0      -0.0202       0.0614       0.0037      -0.0851      -0.0820   \n",
       "1      -0.0968       0.0924      -0.0020      -0.0532      -0.0235   \n",
       "2      -0.0149      -0.0046      -0.0101      -0.0020       0.0416   \n",
       "3       0.1270       0.0282      -0.0194       0.0387      -0.0484   \n",
       "4       0.0635      -0.0142      -0.0746       0.0230       0.0249   \n",
       "\n",
       "   svd_word_16  svd_word_17  svd_word_18  svd_word_19  svd_word_20  \\\n",
       "0      -0.0373      -0.0244       0.0134      -0.0635       0.0033   \n",
       "1       0.0114      -0.0821      -0.0137       0.0454      -0.0783   \n",
       "2      -0.0059      -0.0123      -0.0256      -0.0024       0.0752   \n",
       "3       0.0857      -0.0109      -0.0509      -0.0787       0.0608   \n",
       "4       0.0550      -0.0428       0.0352      -0.0516       0.0096   \n",
       "\n",
       "   svd_word_21  svd_word_22  svd_word_23  svd_word_24  svd_word_25  \\\n",
       "0       0.0453      -0.0286      -0.0023       0.0553       0.0591   \n",
       "1      -0.1023      -0.0218      -0.0113       0.0387      -0.1031   \n",
       "2       0.0532      -0.0509      -0.0487       0.0599      -0.0716   \n",
       "3       0.0194       0.0158       0.0394      -0.0761      -0.0777   \n",
       "4      -0.0348       0.0547       0.0226       0.0498      -0.0115   \n",
       "\n",
       "   svd_word_26  svd_word_27  svd_word_28  svd_word_29  svd_word_30  \\\n",
       "0      -0.0226       0.0919      -0.0025      -0.0226       0.0326   \n",
       "1       0.0461      -0.0548      -0.0960       0.0560      -0.0915   \n",
       "2       0.1369      -0.0027      -0.0638      -0.0694       0.1234   \n",
       "3       0.0722       0.0312      -0.0725       0.0054       0.0303   \n",
       "4       0.0277       0.0382       0.0683      -0.0089      -0.0438   \n",
       "\n",
       "   svd_word_31  svd_word_32  svd_word_33  svd_word_34  svd_word_35  \\\n",
       "0      -0.0198      -0.0166      -0.1179      -0.0402      -0.0344   \n",
       "1      -0.0616       0.0151       0.0007      -0.0988       0.0318   \n",
       "2       0.0477      -0.0084      -0.0179       0.0432       0.0364   \n",
       "3       0.0290       0.0328       0.0061       0.1023       0.1025   \n",
       "4      -0.0392       0.0091      -0.0255       0.0120      -0.0175   \n",
       "\n",
       "   svd_word_36  svd_word_37  svd_word_38  svd_word_39  svd_word_40  \\\n",
       "0       0.0258       0.0741       0.0218       0.1542       0.0021   \n",
       "1       0.0782      -0.0205      -0.0079       0.0928      -0.0908   \n",
       "2       0.0197      -0.0588       0.0557      -0.0374       0.0206   \n",
       "3       0.0919      -0.0259      -0.0532       0.0059      -0.1129   \n",
       "4      -0.0694      -0.0120       0.0295       0.0062      -0.0090   \n",
       "\n",
       "   svd_word_41  svd_word_42  svd_word_43  svd_word_44  svd_word_45  \\\n",
       "0      -0.0611      -0.0483       0.0072      -0.0327      -0.0027   \n",
       "1       0.0271       0.0492      -0.0172      -0.0245       0.0238   \n",
       "2      -0.0218       0.0523       0.0009      -0.0775      -0.0381   \n",
       "3      -0.0415      -0.0014       0.0306      -0.0135       0.0656   \n",
       "4      -0.0194      -0.0379      -0.0181       0.0222       0.0883   \n",
       "\n",
       "   svd_word_46  svd_word_47  svd_word_48  svd_word_49  big  billion  business  \\\n",
       "0       0.1137      -0.0649      -0.0768       0.0508    0        0         0   \n",
       "1      -0.0937       0.0228      -0.0461      -0.0377    0        0         0   \n",
       "2      -0.0176       0.0339      -0.0008       0.0742    0        0         0   \n",
       "3      -0.0004      -0.0596      -0.0037       0.0181    0        0         0   \n",
       "4      -0.0211       0.0097       0.0070      -0.0329    0        0         0   \n",
       "\n",
       "   china  daily  day  deal  ebola  fashion  fashion_week  million  morning  \\\n",
       "0      0      0    0     0      0        0             0        0        0   \n",
       "1      0      0    0     0      0        0             0        0        0   \n",
       "2      0      0    0     0      0        0             0        0        0   \n",
       "3      0      0    0     0      0        0             0        0        0   \n",
       "4      0      0    0     0      0        0             0        0        0   \n",
       "\n",
       "   new  new_york  new_york_today  news  obama  paris  pictures  politics  \\\n",
       "0    0         0               0     0      0      0         0         0   \n",
       "1    1         0               0     0      0      0         0         0   \n",
       "2    0         0               0     0      0      0         0         0   \n",
       "3    0         0               0     0      0      0         0         0   \n",
       "4    0         0               0     0      0      0         0         0   \n",
       "\n",
       "   report  says  small  spring  spring_summer  summer  test  today  week  \\\n",
       "0       0     0      0       0              0       0     0      0     0   \n",
       "1       0     0      0       0              0       0     0      0     0   \n",
       "2       0     0      0       0              0       0     0      0     0   \n",
       "3       0     0      0       0              0       0     0      0     0   \n",
       "4       0     0      0       0              0       0     0      0     0   \n",
       "\n",
       "   word  york  york_today  \n",
       "0     0     0           0  \n",
       "1     0     0           0  \n",
       "2     0     0           0  \n",
       "3     0     0           0  \n",
       "4     0     0           0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train_X, train_y, test_X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_df.drop(['SectionName', 'SubsectionName', 'Headline', 'Snippet', 'PubDate', 'Popular', 'UniqueID'], 1)\n",
    "test_X = test_df.drop(['SectionName', 'SubsectionName', 'Headline', 'Snippet', 'PubDate', 'UniqueID'], 1)\n",
    "train_y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding NewsDesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features=['NewsDesk']\n",
    "\n",
    "for i in cat_features:\n",
    "    dummies=pd.get_dummies(train_X[i], drop_first=False)\n",
    "    train_X[dummies.columns]=dummies    \n",
    "    dummies=pd.get_dummies(test_X[i], drop_first=False)\n",
    "    test_X[dummies.columns]=dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X.drop(['NewsDesk'], 1, inplace=True)\n",
    "test_X.drop(['NewsDesk'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HeadLine_n</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>svd_word_3</th>\n",
       "      <th>svd_word_4</th>\n",
       "      <th>svd_word_5</th>\n",
       "      <th>svd_word_6</th>\n",
       "      <th>svd_word_7</th>\n",
       "      <th>svd_word_8</th>\n",
       "      <th>svd_word_9</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "      <th>svd_word_20</th>\n",
       "      <th>svd_word_21</th>\n",
       "      <th>svd_word_22</th>\n",
       "      <th>svd_word_23</th>\n",
       "      <th>svd_word_24</th>\n",
       "      <th>svd_word_25</th>\n",
       "      <th>svd_word_26</th>\n",
       "      <th>svd_word_27</th>\n",
       "      <th>svd_word_28</th>\n",
       "      <th>svd_word_29</th>\n",
       "      <th>svd_word_30</th>\n",
       "      <th>svd_word_31</th>\n",
       "      <th>svd_word_32</th>\n",
       "      <th>svd_word_33</th>\n",
       "      <th>svd_word_34</th>\n",
       "      <th>svd_word_35</th>\n",
       "      <th>svd_word_36</th>\n",
       "      <th>svd_word_37</th>\n",
       "      <th>svd_word_38</th>\n",
       "      <th>svd_word_39</th>\n",
       "      <th>svd_word_40</th>\n",
       "      <th>svd_word_41</th>\n",
       "      <th>svd_word_42</th>\n",
       "      <th>svd_word_43</th>\n",
       "      <th>svd_word_44</th>\n",
       "      <th>svd_word_45</th>\n",
       "      <th>svd_word_46</th>\n",
       "      <th>svd_word_47</th>\n",
       "      <th>svd_word_48</th>\n",
       "      <th>svd_word_49</th>\n",
       "      <th>big</th>\n",
       "      <th>billion</th>\n",
       "      <th>business</th>\n",
       "      <th>china</th>\n",
       "      <th>daily</th>\n",
       "      <th>day</th>\n",
       "      <th>deal</th>\n",
       "      <th>ebola</th>\n",
       "      <th>fashion</th>\n",
       "      <th>fashion_week</th>\n",
       "      <th>million</th>\n",
       "      <th>morning</th>\n",
       "      <th>new</th>\n",
       "      <th>new_york</th>\n",
       "      <th>new_york_today</th>\n",
       "      <th>news</th>\n",
       "      <th>obama</th>\n",
       "      <th>paris</th>\n",
       "      <th>pictures</th>\n",
       "      <th>politics</th>\n",
       "      <th>report</th>\n",
       "      <th>says</th>\n",
       "      <th>small</th>\n",
       "      <th>spring</th>\n",
       "      <th>spring_summer</th>\n",
       "      <th>summer</th>\n",
       "      <th>test</th>\n",
       "      <th>today</th>\n",
       "      <th>week</th>\n",
       "      <th>word</th>\n",
       "      <th>york</th>\n",
       "      <th>york_today</th>\n",
       "      <th>Business</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Magazine</th>\n",
       "      <th>Metro</th>\n",
       "      <th>OpEd</th>\n",
       "      <th>Science</th>\n",
       "      <th>Styles</th>\n",
       "      <th>TStyle</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>-0.0183</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0851</td>\n",
       "      <td>-0.0820</td>\n",
       "      <td>-0.0373</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>-0.0635</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.1179</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>-0.0344</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.0611</td>\n",
       "      <td>-0.0483</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>-0.0649</td>\n",
       "      <td>-0.0768</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0423</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>-0.0362</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>-0.0968</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0821</td>\n",
       "      <td>-0.0137</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>-0.0783</td>\n",
       "      <td>-0.1023</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.1031</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0960</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>-0.0616</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0988</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>-0.0908</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-0.0937</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>-0.0461</td>\n",
       "      <td>-0.0377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>-0.1017</td>\n",
       "      <td>-0.1037</td>\n",
       "      <td>-0.0359</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0863</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0149</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0123</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>-0.0716</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0638</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>-0.0588</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>-0.0374</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0775</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1405</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.0855</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>-0.0524</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.0484</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0787</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>-0.0761</td>\n",
       "      <td>-0.0777</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>-0.1129</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>-0.0370</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0685</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>-0.0746</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>-0.0438</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>-0.0181</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordCount  Month  Weekday  Hour  HeadLine_n  num_unique_words  num_chars  \\\n",
       "0        508      9        0    22           0                 3         16   \n",
       "1        285      9        0    21           0                 7         44   \n",
       "2       1211      9        0    21           0                 8         49   \n",
       "3       1405      9        0    20           0                 4         21   \n",
       "4        181      9        0    18           0                 6         29   \n",
       "\n",
       "   num_stopwords  num_punctuations  mean_word_len  svd_word_0  svd_word_1  \\\n",
       "0              0                 0       4.666667      0.6179     -0.0183   \n",
       "1              1                 1       5.428571      0.7489      0.0058   \n",
       "2              1                 0       5.250000      0.7755     -0.1017   \n",
       "3              1                 0       4.500000      0.7251      0.0172   \n",
       "4              1                 0       4.000000      0.8294      0.0691   \n",
       "\n",
       "   svd_word_2  svd_word_3  svd_word_4  svd_word_5  svd_word_6  svd_word_7  \\\n",
       "0     -0.0439     -0.0037      0.0245      0.0398      0.0723      0.0667   \n",
       "1     -0.0423      0.0001      0.1064      0.0159     -0.0735     -0.0085   \n",
       "2     -0.1037     -0.0359     -0.0205     -0.0621      0.0145      0.0155   \n",
       "3     -0.0855      0.0488      0.0298     -0.0177     -0.0255     -0.0524   \n",
       "4      0.0382     -0.0370      0.0033      0.0789     -0.0046     -0.0685   \n",
       "\n",
       "   svd_word_8  svd_word_9  svd_word_10  svd_word_11  svd_word_12  svd_word_13  \\\n",
       "0     -0.0225     -0.0516       0.1326      -0.0202       0.0614       0.0037   \n",
       "1      0.0660     -0.0362       0.0184      -0.0968       0.0924      -0.0020   \n",
       "2     -0.0092     -0.0863       0.0821      -0.0149      -0.0046      -0.0101   \n",
       "3      0.0064     -0.0008      -0.0021       0.1270       0.0282      -0.0194   \n",
       "4      0.0280     -0.0341      -0.0207       0.0635      -0.0142      -0.0746   \n",
       "\n",
       "   svd_word_14  svd_word_15  svd_word_16  svd_word_17  svd_word_18  \\\n",
       "0      -0.0851      -0.0820      -0.0373      -0.0244       0.0134   \n",
       "1      -0.0532      -0.0235       0.0114      -0.0821      -0.0137   \n",
       "2      -0.0020       0.0416      -0.0059      -0.0123      -0.0256   \n",
       "3       0.0387      -0.0484       0.0857      -0.0109      -0.0509   \n",
       "4       0.0230       0.0249       0.0550      -0.0428       0.0352   \n",
       "\n",
       "   svd_word_19  svd_word_20  svd_word_21  svd_word_22  svd_word_23  \\\n",
       "0      -0.0635       0.0033       0.0453      -0.0286      -0.0023   \n",
       "1       0.0454      -0.0783      -0.1023      -0.0218      -0.0113   \n",
       "2      -0.0024       0.0752       0.0532      -0.0509      -0.0487   \n",
       "3      -0.0787       0.0608       0.0194       0.0158       0.0394   \n",
       "4      -0.0516       0.0096      -0.0348       0.0547       0.0226   \n",
       "\n",
       "   svd_word_24  svd_word_25  svd_word_26  svd_word_27  svd_word_28  \\\n",
       "0       0.0553       0.0591      -0.0226       0.0919      -0.0025   \n",
       "1       0.0387      -0.1031       0.0461      -0.0548      -0.0960   \n",
       "2       0.0599      -0.0716       0.1369      -0.0027      -0.0638   \n",
       "3      -0.0761      -0.0777       0.0722       0.0312      -0.0725   \n",
       "4       0.0498      -0.0115       0.0277       0.0382       0.0683   \n",
       "\n",
       "   svd_word_29  svd_word_30  svd_word_31  svd_word_32  svd_word_33  \\\n",
       "0      -0.0226       0.0326      -0.0198      -0.0166      -0.1179   \n",
       "1       0.0560      -0.0915      -0.0616       0.0151       0.0007   \n",
       "2      -0.0694       0.1234       0.0477      -0.0084      -0.0179   \n",
       "3       0.0054       0.0303       0.0290       0.0328       0.0061   \n",
       "4      -0.0089      -0.0438      -0.0392       0.0091      -0.0255   \n",
       "\n",
       "   svd_word_34  svd_word_35  svd_word_36  svd_word_37  svd_word_38  \\\n",
       "0      -0.0402      -0.0344       0.0258       0.0741       0.0218   \n",
       "1      -0.0988       0.0318       0.0782      -0.0205      -0.0079   \n",
       "2       0.0432       0.0364       0.0197      -0.0588       0.0557   \n",
       "3       0.1023       0.1025       0.0919      -0.0259      -0.0532   \n",
       "4       0.0120      -0.0175      -0.0694      -0.0120       0.0295   \n",
       "\n",
       "   svd_word_39  svd_word_40  svd_word_41  svd_word_42  svd_word_43  \\\n",
       "0       0.1542       0.0021      -0.0611      -0.0483       0.0072   \n",
       "1       0.0928      -0.0908       0.0271       0.0492      -0.0172   \n",
       "2      -0.0374       0.0206      -0.0218       0.0523       0.0009   \n",
       "3       0.0059      -0.1129      -0.0415      -0.0014       0.0306   \n",
       "4       0.0062      -0.0090      -0.0194      -0.0379      -0.0181   \n",
       "\n",
       "   svd_word_44  svd_word_45  svd_word_46  svd_word_47  svd_word_48  \\\n",
       "0      -0.0327      -0.0027       0.1137      -0.0649      -0.0768   \n",
       "1      -0.0245       0.0238      -0.0937       0.0228      -0.0461   \n",
       "2      -0.0775      -0.0381      -0.0176       0.0339      -0.0008   \n",
       "3      -0.0135       0.0656      -0.0004      -0.0596      -0.0037   \n",
       "4       0.0222       0.0883      -0.0211       0.0097       0.0070   \n",
       "\n",
       "   svd_word_49  big  billion  business  china  daily  day  deal  ebola  \\\n",
       "0       0.0508    0        0         0      0      0    0     0      0   \n",
       "1      -0.0377    0        0         0      0      0    0     0      0   \n",
       "2       0.0742    0        0         0      0      0    0     0      0   \n",
       "3       0.0181    0        0         0      0      0    0     0      0   \n",
       "4      -0.0329    0        0         0      0      0    0     0      0   \n",
       "\n",
       "   fashion  fashion_week  million  morning  new  new_york  new_york_today  \\\n",
       "0        0             0        0        0    0         0               0   \n",
       "1        0             0        0        0    1         0               0   \n",
       "2        0             0        0        0    0         0               0   \n",
       "3        0             0        0        0    0         0               0   \n",
       "4        0             0        0        0    0         0               0   \n",
       "\n",
       "   news  obama  paris  pictures  politics  report  says  small  spring  \\\n",
       "0     0      0      0         0         0       0     0      0       0   \n",
       "1     0      0      0         0         0       0     0      0       0   \n",
       "2     0      0      0         0         0       0     0      0       0   \n",
       "3     0      0      0         0         0       0     0      0       0   \n",
       "4     0      0      0         0         0       0     0      0       0   \n",
       "\n",
       "   spring_summer  summer  test  today  week  word  york  york_today  Business  \\\n",
       "0              0       0     0      0     0     0     0           0         1   \n",
       "1              0       0     0      0     0     0     0           0         0   \n",
       "2              0       0     0      0     0     0     0           0         1   \n",
       "3              0       0     0      0     0     0     0           0         1   \n",
       "4              0       0     0      0     0     0     0           0         0   \n",
       "\n",
       "   Culture  Foreign  Magazine  Metro  OpEd  Science  Styles  TStyle  Travel  \\\n",
       "0        0        0         0      0     0        0       0       0       0   \n",
       "1        1        0         0      0     0        0       0       0       0   \n",
       "2        0        0         0      0     0        0       0       0       0   \n",
       "3        0        0         0      0     0        0       0       0       0   \n",
       "4        0        0         0      0     0        1       0       0       0   \n",
       "\n",
       "   Unknown  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i,feat))\n",
    "    outfile.close()\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=5, eta=0.1):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params['eval_metric'] = 'auc'\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"subsample\"] = 1\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"seed\"] = seed_val\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    if feature_names is not None:\n",
    "        create_feature_map(feature_names)\n",
    "        model.dump_model('xgbmodel.txt', 'xgb.fmap', with_stats=True)\n",
    "        importance = model.get_fscore(fmap='xgb.fmap')\n",
    "        importance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        imp_df = pd.DataFrame(importance, columns=['feature','fscore'])\n",
    "        imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "        imp_df.to_csv(\"imp_feat.txt\", index=False)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    pred_test_y2 = model.predict(xgb.DMatrix(test_X2), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        return pred_test_y, loss, pred_test_y2\n",
    "    else:\n",
    "        return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = 'auc'\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"min_data_in_leaf\"] = 128\n",
    "    params[\"learning_rate\"] = eta\n",
    "    params[\"bagging_fraction\"] = 1\n",
    "    params[\"feature_fraction\"] = 0.7\n",
    "    params[\"bagging_freq\"] = 1\n",
    "    params[\"bagging_seed\"] = seed_val\n",
    "    params[\"verbosity\"] = 0\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest], early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        print(loss)\n",
    "        return pred_test_y, loss, pred_test_y2\n",
    "    else:\n",
    "        return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runRF(train_X, train_y, test_X, test_y=None, test_X2=None, depth=10, leaf=5, feat=0.3):\n",
    "    model = RandomForestClassifier(n_estimators = 4000,\n",
    "                                   criterion = 'gini',\n",
    "                                   max_depth = depth,\n",
    "                                   min_samples_split = 2,\n",
    "                                   min_samples_leaf = leaf,\n",
    "                                   max_features =  feat,\n",
    "                                   n_jobs = -1,\n",
    "                                   random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]   \n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth, leaf, feat : \", depth, leaf, feat)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runET(train_X, train_y, test_X, test_y=None, test_X2=None, depth=10, leaf=5, feat=0.7):\n",
    "    model = ensemble.ExtraTreesClassifier(\n",
    "                                        n_estimators = 500,\n",
    "                                        criterion = 'gini',\n",
    "                                        max_depth = depth,\n",
    "                                        min_samples_split = 10,\n",
    "                                        min_samples_leaf = leaf,\n",
    "                                        max_features =  feat,\n",
    "                                        #min_impurity_split = 0.1,\n",
    "                                        n_jobs = -1,\n",
    "                                        random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth, leaf, feat : \", depth, leaf, feat)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runGBM(train_X, train_y, test_X, test_y=None, test_X2=None, depth=6, leaf=5, feat=0.7):\n",
    "    model = GradientBoostingClassifier(n_estimators=3000,\n",
    "                                       learning_rate=0.05,\n",
    "                                       max_depth=depth,\n",
    "                                       max_features=feat,\n",
    "                                       min_samples_leaf=leaf,\n",
    "                                       random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]   \n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth, leaf, feat : \", depth, leaf, feat)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runCatB(train_X, train_y, test_X, test_y=None, test_X2=None, depth=6):\n",
    "    model = CatBoostClassifier(\n",
    "                                iterations = 500,\n",
    "                                learning_rate = 0.05,\n",
    "                                depth = depth,\n",
    "                                od_type='Iter',\n",
    "                                od_wait=100,\n",
    "                                l2_leaf_reg=6,\n",
    "                                eval_metric = 'AUC', \n",
    "                                verbose=False,\n",
    "                                random_seed=0)\n",
    "    \n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y))#, plot=True)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth : \", depth)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runADA(train_X, train_y, test_X, test_y=None, test_X2=None, depth=4):\n",
    "    model = AdaBoostClassifier(\n",
    "                                DecisionTreeClassifier(max_depth=depth, max_features=0.7, min_samples_leaf=5),\n",
    "                                n_estimators = 20,\n",
    "                                learning_rate = 0.05,\n",
    "                                random_state=0)\n",
    "    \n",
    "    model.fit(train_X, train_y)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth : \", depth)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.809886\ttest-auc:0.794498\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.948201\ttest-auc:0.925631\n",
      "[40]\ttrain-auc:0.964688\ttest-auc:0.936046\n",
      "[60]\ttrain-auc:0.978386\ttest-auc:0.937988\n",
      "[80]\ttrain-auc:0.988609\ttest-auc:0.938989\n",
      "[100]\ttrain-auc:0.993826\ttest-auc:0.939817\n",
      "[120]\ttrain-auc:0.996651\ttest-auc:0.940547\n",
      "[140]\ttrain-auc:0.998577\ttest-auc:0.940624\n",
      "[160]\ttrain-auc:0.999482\ttest-auc:0.940838\n",
      "[180]\ttrain-auc:0.999798\ttest-auc:0.939441\n",
      "[200]\ttrain-auc:0.999918\ttest-auc:0.939017\n",
      "[220]\ttrain-auc:0.999978\ttest-auc:0.938501\n",
      "[240]\ttrain-auc:0.999996\ttest-auc:0.93798\n",
      "Stopping. Best iteration:\n",
      "[148]\ttrain-auc:0.998925\ttest-auc:0.941541\n",
      "\n",
      "[0.94154051108150649]\n",
      "[0]\ttrain-auc:0.813615\ttest-auc:0.772047\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.950169\ttest-auc:0.921887\n",
      "[40]\ttrain-auc:0.965716\ttest-auc:0.93161\n",
      "[60]\ttrain-auc:0.97861\ttest-auc:0.934787\n",
      "[80]\ttrain-auc:0.988191\ttest-auc:0.936127\n",
      "[100]\ttrain-auc:0.994207\ttest-auc:0.936244\n",
      "[120]\ttrain-auc:0.997666\ttest-auc:0.936006\n",
      "[140]\ttrain-auc:0.999004\ttest-auc:0.935245\n",
      "[160]\ttrain-auc:0.999663\ttest-auc:0.934921\n",
      "Stopping. Best iteration:\n",
      "[77]\ttrain-auc:0.986886\ttest-auc:0.93707\n",
      "\n",
      "[0.94154051108150649, 0.93706974089320938]\n",
      "[0]\ttrain-auc:0.795178\ttest-auc:0.796737\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.950405\ttest-auc:0.929639\n",
      "[40]\ttrain-auc:0.96502\ttest-auc:0.931826\n",
      "[60]\ttrain-auc:0.978116\ttest-auc:0.933424\n",
      "[80]\ttrain-auc:0.98845\ttest-auc:0.933453\n",
      "[100]\ttrain-auc:0.994264\ttest-auc:0.933182\n",
      "[120]\ttrain-auc:0.997198\ttest-auc:0.931885\n",
      "[140]\ttrain-auc:0.99882\ttest-auc:0.931259\n",
      "[160]\ttrain-auc:0.999585\ttest-auc:0.930734\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-auc:0.982165\ttest-auc:0.934612\n",
      "\n",
      "[0.94154051108150649, 0.93706974089320938, 0.93461225681339544]\n",
      "[0]\ttrain-auc:0.80918\ttest-auc:0.800248\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.95283\ttest-auc:0.923968\n",
      "[40]\ttrain-auc:0.966787\ttest-auc:0.931779\n",
      "[60]\ttrain-auc:0.981302\ttest-auc:0.929569\n",
      "[80]\ttrain-auc:0.990725\ttest-auc:0.929023\n",
      "[100]\ttrain-auc:0.995378\ttest-auc:0.929122\n",
      "[120]\ttrain-auc:0.997387\ttest-auc:0.928534\n",
      "[140]\ttrain-auc:0.999115\ttest-auc:0.929204\n",
      "Stopping. Best iteration:\n",
      "[41]\ttrain-auc:0.967963\ttest-auc:0.931792\n",
      "\n",
      "[0.94154051108150649, 0.93706974089320938, 0.93461225681339544, 0.93179172626487816]\n",
      "[0]\ttrain-auc:0.806004\ttest-auc:0.758786\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.950132\ttest-auc:0.914948\n",
      "[40]\ttrain-auc:0.966547\ttest-auc:0.92272\n",
      "[60]\ttrain-auc:0.978244\ttest-auc:0.924082\n",
      "[80]\ttrain-auc:0.988345\ttest-auc:0.923804\n",
      "[100]\ttrain-auc:0.993937\ttest-auc:0.923281\n",
      "[120]\ttrain-auc:0.997142\ttest-auc:0.921156\n",
      "[140]\ttrain-auc:0.998582\ttest-auc:0.920633\n",
      "[160]\ttrain-auc:0.999345\ttest-auc:0.92052\n",
      "Stopping. Best iteration:\n",
      "[78]\ttrain-auc:0.987014\ttest-auc:0.924542\n",
      "\n",
      "[0.94154051108150649, 0.93706974089320938, 0.93461225681339544, 0.93179172626487816, 0.92454170601726926]\n",
      "0.933239941213\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's auc: 0.914521\n",
      "[40]\tvalid_0's auc: 0.920665\n",
      "[60]\tvalid_0's auc: 0.926394\n",
      "[80]\tvalid_0's auc: 0.93104\n",
      "[100]\tvalid_0's auc: 0.93322\n",
      "[120]\tvalid_0's auc: 0.934548\n",
      "[140]\tvalid_0's auc: 0.935788\n",
      "[160]\tvalid_0's auc: 0.937386\n",
      "[180]\tvalid_0's auc: 0.93731\n",
      "[200]\tvalid_0's auc: 0.936858\n",
      "[220]\tvalid_0's auc: 0.937096\n",
      "[240]\tvalid_0's auc: 0.936099\n",
      "[260]\tvalid_0's auc: 0.936248\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.937891\n",
      "0.937891082314\n",
      "[0.9378910823139962]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's auc: 0.909525\n",
      "[40]\tvalid_0's auc: 0.917991\n",
      "[60]\tvalid_0's auc: 0.923825\n",
      "[80]\tvalid_0's auc: 0.927937\n",
      "[100]\tvalid_0's auc: 0.929978\n",
      "[120]\tvalid_0's auc: 0.931327\n",
      "[140]\tvalid_0's auc: 0.931621\n",
      "[160]\tvalid_0's auc: 0.93249\n",
      "[180]\tvalid_0's auc: 0.931431\n",
      "[200]\tvalid_0's auc: 0.932041\n",
      "[220]\tvalid_0's auc: 0.93249\n",
      "[240]\tvalid_0's auc: 0.93176\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.932642\n",
      "0.932641747674\n",
      "[0.9378910823139962, 0.93264174767357377]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's auc: 0.92354\n",
      "[40]\tvalid_0's auc: 0.929295\n",
      "[60]\tvalid_0's auc: 0.93269\n",
      "[80]\tvalid_0's auc: 0.934066\n",
      "[100]\tvalid_0's auc: 0.93475\n",
      "[120]\tvalid_0's auc: 0.936293\n",
      "[140]\tvalid_0's auc: 0.935713\n",
      "[160]\tvalid_0's auc: 0.935713\n",
      "[180]\tvalid_0's auc: 0.934737\n",
      "[200]\tvalid_0's auc: 0.934412\n",
      "[220]\tvalid_0's auc: 0.93417\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.936489\n",
      "0.936488938007\n",
      "[0.9378910823139962, 0.93264174767357377, 0.93648893800696464]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's auc: 0.909278\n",
      "[40]\tvalid_0's auc: 0.91524\n",
      "[60]\tvalid_0's auc: 0.919552\n",
      "[80]\tvalid_0's auc: 0.922675\n",
      "[100]\tvalid_0's auc: 0.923225\n",
      "[120]\tvalid_0's auc: 0.923985\n",
      "[140]\tvalid_0's auc: 0.923693\n",
      "[160]\tvalid_0's auc: 0.923233\n",
      "[180]\tvalid_0's auc: 0.922984\n",
      "[200]\tvalid_0's auc: 0.922164\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.924702\n",
      "0.924702223711\n",
      "[0.9378910823139962, 0.93264174767357377, 0.93648893800696464, 0.92470222371128263]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's auc: 0.904096\n",
      "[40]\tvalid_0's auc: 0.91268\n",
      "[60]\tvalid_0's auc: 0.915437\n",
      "[80]\tvalid_0's auc: 0.919189\n",
      "[100]\tvalid_0's auc: 0.919337\n",
      "[120]\tvalid_0's auc: 0.919447\n",
      "[140]\tvalid_0's auc: 0.920134\n",
      "[160]\tvalid_0's auc: 0.920568\n",
      "[180]\tvalid_0's auc: 0.920302\n",
      "[200]\tvalid_0's auc: 0.921302\n",
      "[220]\tvalid_0's auc: 0.920387\n",
      "[240]\tvalid_0's auc: 0.92061\n",
      "[260]\tvalid_0's auc: 0.92018\n",
      "[280]\tvalid_0's auc: 0.919843\n",
      "[300]\tvalid_0's auc: 0.919771\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's auc: 0.921302\n",
      "0.921301605505\n",
      "[0.9378910823139962, 0.93264174767357377, 0.93648893800696464, 0.92470222371128263, 0.92130160550458717]\n",
      "0.930230602169\n",
      "Depth, leaf, feat :  10 5 0.3\n",
      "Train and Test loss :  0.97814847814 0.927972225586\n",
      "[0.92797222558637116]\n",
      "Depth, leaf, feat :  10 5 0.3\n",
      "Train and Test loss :  0.977573314996 0.916996748192\n",
      "[0.92797222558637116, 0.91699674819247945]\n",
      "Depth, leaf, feat :  10 5 0.3\n",
      "Train and Test loss :  0.977256493028 0.931688804554\n",
      "[0.92797222558637116, 0.91699674819247945, 0.93168880455407965]\n",
      "Depth, leaf, feat :  10 5 0.3\n",
      "Train and Test loss :  0.979642461197 0.917365737579\n",
      "[0.92797222558637116, 0.91699674819247945, 0.93168880455407965, 0.91736573757887363]\n",
      "Depth, leaf, feat :  10 5 0.3\n",
      "Train and Test loss :  0.979113372952 0.916339213438\n",
      "[0.92797222558637116, 0.91699674819247945, 0.93168880455407965, 0.91736573757887363, 0.91633921343766866]\n",
      "0.921696796223\n",
      "Depth, leaf, feat :  10 5 0.7\n",
      "Train and Test loss :  0.970919449177 0.932130313673\n",
      "[0.93213031367324695]\n",
      "Depth, leaf, feat :  10 5 0.7\n",
      "Train and Test loss :  0.971219618402 0.93608814474\n",
      "[0.93213031367324695, 0.93608814474002844]\n",
      "Depth, leaf, feat :  10 5 0.7\n",
      "Train and Test loss :  0.968385603452 0.939658444023\n",
      "[0.93213031367324695, 0.93608814474002844, 0.93965844402277054]\n",
      "Depth, leaf, feat :  10 5 0.7\n",
      "Train and Test loss :  0.970047431285 0.930324858575\n",
      "[0.93213031367324695, 0.93608814474002844, 0.93965844402277054, 0.93032485857505509]\n",
      "Depth, leaf, feat :  10 5 0.7\n",
      "Train and Test loss :  0.970215582625 0.92811909741\n",
      "[0.93213031367324695, 0.93608814474002844, 0.93965844402277054, 0.93032485857505509, 0.92811909740960608]\n",
      "0.93284514419\n",
      "Depth, leaf, feat :  6 5 0.7\n",
      "Train and Test loss :  0.999999734354 0.932085906907\n",
      "[0.93208590690727067]\n",
      "Depth, leaf, feat :  6 5 0.7\n",
      "Train and Test loss :  0.999999216818 0.930038571972\n",
      "[0.93208590690727067, 0.93003857197218676]\n",
      "Depth, leaf, feat :  6 5 0.7\n",
      "Train and Test loss :  1.0 0.934887503388\n",
      "[0.93208590690727067, 0.93003857197218676, 0.93488750338845217]\n",
      "Depth, leaf, feat :  6 5 0.7\n",
      "Train and Test loss :  0.99999921558 0.922374135021\n",
      "[0.93208590690727067, 0.93003857197218676, 0.93488750338845217, 0.92237413502055343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth, leaf, feat :  6 5 0.7\n",
      "Train and Test loss :  0.999999737335 0.913189759849\n",
      "[0.93208590690727067, 0.93003857197218676, 0.93488750338845217, 0.92237413502055343, 0.91318975984889372]\n",
      "0.925767562286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/catboost/core.py:1240: FutureWarning: The 'verbose' parameter is deprecated, use 'logging_level' parameter instead (posible values: 'Silent', 'Verbose', 'Info', 'Debug').\n",
      "  super(CatBoostClassifier, self).__init__(params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learn: 0.7401085\ttest: 0.7400509\tbestTest: 0.7400509 (0)\ttotal: 178ms\tremaining: 1m 28s\n",
      "1: learn: 0.8084422\ttest: 0.8073089\tbestTest: 0.8073089 (1)\ttotal: 389ms\tremaining: 1m 36s\n",
      "2: learn: 0.8773635\ttest: 0.8699043\tbestTest: 0.8699043 (2)\ttotal: 622ms\tremaining: 1m 43s\n",
      "3: learn: 0.8793504\ttest: 0.8744863\tbestTest: 0.8744863 (3)\ttotal: 823ms\tremaining: 1m 42s\n",
      "4: learn: 0.8836232\ttest: 0.872813\tbestTest: 0.8744863 (3)\ttotal: 1.01s\tremaining: 1m 40s\n",
      "5: learn: 0.8852035\ttest: 0.875871\tbestTest: 0.875871 (5)\ttotal: 1.2s\tremaining: 1m 38s\n",
      "6: learn: 0.8938797\ttest: 0.8836301\tbestTest: 0.8836301 (6)\ttotal: 1.4s\tremaining: 1m 38s\n",
      "7: learn: 0.8999016\ttest: 0.8900246\tbestTest: 0.8900246 (7)\ttotal: 1.58s\tremaining: 1m 36s\n",
      "8: learn: 0.9011211\ttest: 0.8907755\tbestTest: 0.8907755 (8)\ttotal: 1.78s\tremaining: 1m 36s\n",
      "9: learn: 0.9036984\ttest: 0.894328\tbestTest: 0.894328 (9)\ttotal: 1.95s\tremaining: 1m 35s\n",
      "10: learn: 0.9094376\ttest: 0.9003209\tbestTest: 0.9003209 (10)\ttotal: 2.17s\tremaining: 1m 36s\n",
      "11: learn: 0.9120945\ttest: 0.904586\tbestTest: 0.904586 (11)\ttotal: 2.34s\tremaining: 1m 35s\n",
      "12: learn: 0.9129727\ttest: 0.9063623\tbestTest: 0.9063623 (12)\ttotal: 2.51s\tremaining: 1m 34s\n",
      "13: learn: 0.9173089\ttest: 0.9121473\tbestTest: 0.9121473 (13)\ttotal: 2.71s\tremaining: 1m 33s\n",
      "14: learn: 0.9173801\ttest: 0.912339\tbestTest: 0.912339 (14)\ttotal: 2.92s\tremaining: 1m 34s\n",
      "15: learn: 0.9172958\ttest: 0.9119757\tbestTest: 0.912339 (14)\ttotal: 3.07s\tremaining: 1m 32s\n",
      "16: learn: 0.9179173\ttest: 0.9116043\tbestTest: 0.912339 (14)\ttotal: 3.26s\tremaining: 1m 32s\n",
      "17: learn: 0.9181903\ttest: 0.9113984\tbestTest: 0.912339 (14)\ttotal: 3.48s\tremaining: 1m 33s\n",
      "18: learn: 0.9195062\ttest: 0.9117294\tbestTest: 0.912339 (14)\ttotal: 3.68s\tremaining: 1m 33s\n",
      "19: learn: 0.9194578\ttest: 0.9118465\tbestTest: 0.912339 (14)\ttotal: 3.91s\tremaining: 1m 33s\n",
      "20: learn: 0.9204059\ttest: 0.9132009\tbestTest: 0.9132009 (20)\ttotal: 4.11s\tremaining: 1m 33s\n",
      "21: learn: 0.9205443\ttest: 0.9130798\tbestTest: 0.9132009 (20)\ttotal: 4.33s\tremaining: 1m 34s\n",
      "22: learn: 0.9210142\ttest: 0.9134431\tbestTest: 0.9134431 (22)\ttotal: 4.53s\tremaining: 1m 34s\n",
      "23: learn: 0.9212326\ttest: 0.9142182\tbestTest: 0.9142182 (23)\ttotal: 4.7s\tremaining: 1m 33s\n",
      "24: learn: 0.9215158\ttest: 0.91528\tbestTest: 0.91528 (24)\ttotal: 4.9s\tremaining: 1m 33s\n",
      "25: learn: 0.9225669\ttest: 0.9167535\tbestTest: 0.9167535 (25)\ttotal: 5.13s\tremaining: 1m 33s\n",
      "26: learn: 0.9225104\ttest: 0.9165718\tbestTest: 0.9167535 (25)\ttotal: 5.32s\tremaining: 1m 33s\n",
      "27: learn: 0.9236351\ttest: 0.9170885\tbestTest: 0.9170885 (27)\ttotal: 5.54s\tremaining: 1m 33s\n",
      "28: learn: 0.9238524\ttest: 0.9167817\tbestTest: 0.9170885 (27)\ttotal: 5.76s\tremaining: 1m 33s\n",
      "29: learn: 0.9242049\ttest: 0.9167212\tbestTest: 0.9170885 (27)\ttotal: 5.97s\tremaining: 1m 33s\n",
      "30: learn: 0.925955\ttest: 0.9179\tbestTest: 0.9179 (30)\ttotal: 6.2s\tremaining: 1m 33s\n",
      "31: learn: 0.926231\ttest: 0.9185863\tbestTest: 0.9185863 (31)\ttotal: 6.36s\tremaining: 1m 33s\n",
      "32: learn: 0.9278055\ttest: 0.920633\tbestTest: 0.920633 (32)\ttotal: 6.54s\tremaining: 1m 32s\n",
      "33: learn: 0.928876\ttest: 0.9216301\tbestTest: 0.9216301 (33)\ttotal: 6.73s\tremaining: 1m 32s\n",
      "34: learn: 0.9289759\ttest: 0.9215252\tbestTest: 0.9216301 (33)\ttotal: 6.95s\tremaining: 1m 32s\n",
      "35: learn: 0.9292623\ttest: 0.9221065\tbestTest: 0.9221065 (35)\ttotal: 7.14s\tremaining: 1m 32s\n",
      "36: learn: 0.9297242\ttest: 0.922385\tbestTest: 0.922385 (36)\ttotal: 7.33s\tremaining: 1m 31s\n",
      "37: learn: 0.9304141\ttest: 0.9226192\tbestTest: 0.9226192 (37)\ttotal: 7.48s\tremaining: 1m 30s\n",
      "38: learn: 0.9311688\ttest: 0.9230956\tbestTest: 0.9230956 (38)\ttotal: 7.69s\tremaining: 1m 30s\n",
      "39: learn: 0.9316241\ttest: 0.9234629\tbestTest: 0.9234629 (39)\ttotal: 7.91s\tremaining: 1m 30s\n",
      "40: learn: 0.9318393\ttest: 0.9236567\tbestTest: 0.9236567 (40)\ttotal: 8.13s\tremaining: 1m 30s\n",
      "41: learn: 0.932395\ttest: 0.9239554\tbestTest: 0.9239554 (41)\ttotal: 8.28s\tremaining: 1m 30s\n",
      "42: learn: 0.9329231\ttest: 0.9245529\tbestTest: 0.9245529 (42)\ttotal: 8.47s\tremaining: 1m 30s\n",
      "43: learn: 0.9336242\ttest: 0.9254814\tbestTest: 0.9254814 (43)\ttotal: 8.69s\tremaining: 1m 30s\n",
      "44: learn: 0.9336877\ttest: 0.9254895\tbestTest: 0.9254895 (44)\ttotal: 8.9s\tremaining: 1m 30s\n",
      "45: learn: 0.9338699\ttest: 0.9260224\tbestTest: 0.9260224 (45)\ttotal: 9.09s\tremaining: 1m 29s\n",
      "46: learn: 0.9345099\ttest: 0.9264826\tbestTest: 0.9264826 (46)\ttotal: 9.29s\tremaining: 1m 29s\n",
      "47: learn: 0.9344126\ttest: 0.9264826\tbestTest: 0.9264826 (47)\ttotal: 9.47s\tremaining: 1m 29s\n",
      "48: learn: 0.9349395\ttest: 0.9261233\tbestTest: 0.9264826 (47)\ttotal: 9.69s\tremaining: 1m 29s\n",
      "49: learn: 0.935088\ttest: 0.9261798\tbestTest: 0.9264826 (47)\ttotal: 9.91s\tremaining: 1m 29s\n",
      "50: learn: 0.9353579\ttest: 0.9262525\tbestTest: 0.9264826 (47)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "51: learn: 0.9358996\ttest: 0.9261152\tbestTest: 0.9264826 (47)\ttotal: 10.3s\tremaining: 1m 29s\n",
      "52: learn: 0.9364372\ttest: 0.9268378\tbestTest: 0.9268378 (52)\ttotal: 10.6s\tremaining: 1m 29s\n",
      "53: learn: 0.9368966\ttest: 0.9272819\tbestTest: 0.9272819 (53)\ttotal: 10.8s\tremaining: 1m 29s\n",
      "54: learn: 0.937443\ttest: 0.9277462\tbestTest: 0.9277462 (54)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "55: learn: 0.9379817\ttest: 0.9281741\tbestTest: 0.9281741 (55)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "56: learn: 0.9382745\ttest: 0.9284365\tbestTest: 0.9284365 (56)\ttotal: 11.3s\tremaining: 1m 27s\n",
      "57: learn: 0.9385773\ttest: 0.9289855\tbestTest: 0.9289855 (57)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "58: learn: 0.9388039\ttest: 0.9291308\tbestTest: 0.9291308 (58)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "59: learn: 0.9390374\ttest: 0.9291631\tbestTest: 0.9291631 (59)\ttotal: 11.9s\tremaining: 1m 26s\n",
      "60: learn: 0.9392324\ttest: 0.9295022\tbestTest: 0.9295022 (60)\ttotal: 12.1s\tremaining: 1m 26s\n",
      "61: learn: 0.9395017\ttest: 0.9294901\tbestTest: 0.9295022 (60)\ttotal: 12.3s\tremaining: 1m 26s\n",
      "62: learn: 0.9398551\ttest: 0.9296556\tbestTest: 0.9296556 (62)\ttotal: 12.5s\tremaining: 1m 26s\n",
      "63: learn: 0.9399799\ttest: 0.9299019\tbestTest: 0.9299019 (63)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "64: learn: 0.9403951\ttest: 0.929805\tbestTest: 0.9299019 (63)\ttotal: 13s\tremaining: 1m 26s\n",
      "65: learn: 0.9406969\ttest: 0.9303944\tbestTest: 0.9303944 (65)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "66: learn: 0.94106\ttest: 0.9304711\tbestTest: 0.9304711 (66)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "67: learn: 0.9413323\ttest: 0.930786\tbestTest: 0.930786 (67)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "68: learn: 0.9417401\ttest: 0.9308304\tbestTest: 0.9308304 (68)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "69: learn: 0.9419826\ttest: 0.930564\tbestTest: 0.9308304 (68)\ttotal: 14s\tremaining: 1m 26s\n",
      "70: learn: 0.9425073\ttest: 0.9306689\tbestTest: 0.9308304 (68)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "71: learn: 0.9429575\ttest: 0.9307214\tbestTest: 0.9308304 (68)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "72: learn: 0.9433358\ttest: 0.9310242\tbestTest: 0.9310242 (72)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "73: learn: 0.9436663\ttest: 0.9312543\tbestTest: 0.9312543 (73)\ttotal: 14.8s\tremaining: 1m 24s\n",
      "74: learn: 0.9437149\ttest: 0.9314723\tbestTest: 0.9314723 (74)\ttotal: 15s\tremaining: 1m 24s\n",
      "75: learn: 0.9441532\ttest: 0.9316136\tbestTest: 0.9316136 (75)\ttotal: 15.2s\tremaining: 1m 24s\n",
      "76: learn: 0.9443445\ttest: 0.9318518\tbestTest: 0.9318518 (76)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "77: learn: 0.9446277\ttest: 0.9320617\tbestTest: 0.9320617 (77)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "78: learn: 0.9447634\ttest: 0.9322393\tbestTest: 0.9322393 (78)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "79: learn: 0.9451093\ttest: 0.9323241\tbestTest: 0.9323241 (79)\ttotal: 16s\tremaining: 1m 24s\n",
      "80: learn: 0.9454071\ttest: 0.9323443\tbestTest: 0.9323443 (80)\ttotal: 16.2s\tremaining: 1m 23s\n",
      "81: learn: 0.9455208\ttest: 0.932643\tbestTest: 0.932643 (81)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "82: learn: 0.9457141\ttest: 0.9326511\tbestTest: 0.9326511 (82)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "83: learn: 0.9459546\ttest: 0.9326148\tbestTest: 0.9326511 (82)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "84: learn: 0.9464125\ttest: 0.9328973\tbestTest: 0.9328973 (84)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "85: learn: 0.9465536\ttest: 0.9330144\tbestTest: 0.9330144 (85)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "86: learn: 0.9468291\ttest: 0.9334787\tbestTest: 0.9334787 (86)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "87: learn: 0.9471457\ttest: 0.9336765\tbestTest: 0.9336765 (87)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "88: learn: 0.9472724\ttest: 0.9338541\tbestTest: 0.9338541 (88)\ttotal: 17.8s\tremaining: 1m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89: learn: 0.9476002\ttest: 0.9338258\tbestTest: 0.9338541 (88)\ttotal: 18s\tremaining: 1m 22s\n",
      "90: learn: 0.9477158\ttest: 0.9339914\tbestTest: 0.9339914 (90)\ttotal: 18.2s\tremaining: 1m 21s\n",
      "91: learn: 0.9478935\ttest: 0.9339227\tbestTest: 0.9339914 (90)\ttotal: 18.4s\tremaining: 1m 21s\n",
      "92: learn: 0.9480619\ttest: 0.9340075\tbestTest: 0.9340075 (92)\ttotal: 18.6s\tremaining: 1m 21s\n",
      "93: learn: 0.9481581\ttest: 0.9341125\tbestTest: 0.9341125 (93)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "94: learn: 0.9482774\ttest: 0.9339752\tbestTest: 0.9341125 (93)\ttotal: 19s\tremaining: 1m 21s\n",
      "95: learn: 0.9484854\ttest: 0.9340681\tbestTest: 0.9341125 (93)\ttotal: 19.2s\tremaining: 1m 20s\n",
      "96: learn: 0.9488453\ttest: 0.9343466\tbestTest: 0.9343466 (96)\ttotal: 19.4s\tremaining: 1m 20s\n",
      "97: learn: 0.9489853\ttest: 0.9343264\tbestTest: 0.9343466 (96)\ttotal: 19.6s\tremaining: 1m 20s\n",
      "98: learn: 0.949396\ttest: 0.9339389\tbestTest: 0.9343466 (96)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "99: learn: 0.9496274\ttest: 0.9339792\tbestTest: 0.9343466 (96)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "100: learn: 0.9496856\ttest: 0.933947\tbestTest: 0.9343466 (96)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "101: learn: 0.9499286\ttest: 0.9339308\tbestTest: 0.9343466 (96)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "102: learn: 0.950084\ttest: 0.9340317\tbestTest: 0.9343466 (96)\ttotal: 20.7s\tremaining: 1m 19s\n",
      "103: learn: 0.9503685\ttest: 0.9343385\tbestTest: 0.9343466 (96)\ttotal: 20.9s\tremaining: 1m 19s\n",
      "104: learn: 0.9506198\ttest: 0.9342053\tbestTest: 0.9343466 (96)\ttotal: 21.1s\tremaining: 1m 19s\n",
      "105: learn: 0.9509285\ttest: 0.9346131\tbestTest: 0.9346131 (105)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "106: learn: 0.9513761\ttest: 0.9347947\tbestTest: 0.9347947 (106)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "107: learn: 0.9516883\ttest: 0.9347503\tbestTest: 0.9347947 (106)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "108: learn: 0.9521465\ttest: 0.9347584\tbestTest: 0.9347947 (106)\ttotal: 22s\tremaining: 1m 18s\n",
      "109: learn: 0.9523117\ttest: 0.9347988\tbestTest: 0.9347988 (109)\ttotal: 22.2s\tremaining: 1m 18s\n",
      "110: learn: 0.9525309\ttest: 0.9348916\tbestTest: 0.9348916 (110)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "111: learn: 0.952881\ttest: 0.9346131\tbestTest: 0.9348916 (110)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "112: learn: 0.9529934\ttest: 0.9344758\tbestTest: 0.9348916 (110)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "113: learn: 0.9531942\ttest: 0.9345162\tbestTest: 0.9348916 (110)\ttotal: 23s\tremaining: 1m 18s\n",
      "114: learn: 0.953433\ttest: 0.9345606\tbestTest: 0.9348916 (110)\ttotal: 23.3s\tremaining: 1m 17s\n",
      "115: learn: 0.9535738\ttest: 0.9346373\tbestTest: 0.9348916 (110)\ttotal: 23.5s\tremaining: 1m 17s\n",
      "116: learn: 0.9539773\ttest: 0.9345767\tbestTest: 0.9348916 (110)\ttotal: 23.7s\tremaining: 1m 17s\n",
      "117: learn: 0.954125\ttest: 0.9346898\tbestTest: 0.9348916 (110)\ttotal: 23.9s\tremaining: 1m 17s\n",
      "118: learn: 0.9542483\ttest: 0.9346454\tbestTest: 0.9348916 (110)\ttotal: 24.1s\tremaining: 1m 17s\n",
      "119: learn: 0.9545495\ttest: 0.934605\tbestTest: 0.9348916 (110)\ttotal: 24.3s\tremaining: 1m 16s\n",
      "120: learn: 0.9548962\ttest: 0.9346292\tbestTest: 0.9348916 (110)\ttotal: 24.5s\tremaining: 1m 16s\n",
      "121: learn: 0.9550543\ttest: 0.9347301\tbestTest: 0.9348916 (110)\ttotal: 24.7s\tremaining: 1m 16s\n",
      "122: learn: 0.9553768\ttest: 0.9348674\tbestTest: 0.9348916 (110)\ttotal: 24.9s\tremaining: 1m 16s\n",
      "123: learn: 0.9555011\ttest: 0.9347624\tbestTest: 0.9348916 (110)\ttotal: 25.1s\tremaining: 1m 16s\n",
      "124: learn: 0.9559152\ttest: 0.9348553\tbestTest: 0.9348916 (110)\ttotal: 25.3s\tremaining: 1m 16s\n",
      "125: learn: 0.9561684\ttest: 0.9348391\tbestTest: 0.9348916 (110)\ttotal: 25.6s\tremaining: 1m 15s\n",
      "126: learn: 0.9565823\ttest: 0.9347826\tbestTest: 0.9348916 (110)\ttotal: 25.8s\tremaining: 1m 15s\n",
      "127: learn: 0.9567852\ttest: 0.9348149\tbestTest: 0.9348916 (110)\ttotal: 26s\tremaining: 1m 15s\n",
      "128: learn: 0.9571747\ttest: 0.9348512\tbestTest: 0.9348916 (110)\ttotal: 26.2s\tremaining: 1m 15s\n",
      "129: learn: 0.9573558\ttest: 0.9348472\tbestTest: 0.9348916 (110)\ttotal: 26.4s\tremaining: 1m 15s\n",
      "130: learn: 0.9575521\ttest: 0.9348795\tbestTest: 0.9348916 (110)\ttotal: 26.6s\tremaining: 1m 15s\n",
      "131: learn: 0.9578098\ttest: 0.9349078\tbestTest: 0.9349078 (131)\ttotal: 26.8s\tremaining: 1m 14s\n",
      "132: learn: 0.9581336\ttest: 0.9350531\tbestTest: 0.9350531 (132)\ttotal: 27s\tremaining: 1m 14s\n",
      "133: learn: 0.9582888\ttest: 0.9350773\tbestTest: 0.9350773 (133)\ttotal: 27.3s\tremaining: 1m 14s\n",
      "134: learn: 0.9583966\ttest: 0.9350531\tbestTest: 0.9350773 (133)\ttotal: 27.5s\tremaining: 1m 14s\n",
      "135: learn: 0.9586548\ttest: 0.9348997\tbestTest: 0.9350773 (133)\ttotal: 27.7s\tremaining: 1m 14s\n",
      "136: learn: 0.9588745\ttest: 0.9350046\tbestTest: 0.9350773 (133)\ttotal: 27.9s\tremaining: 1m 13s\n",
      "137: learn: 0.9590921\ttest: 0.9350208\tbestTest: 0.9350773 (133)\ttotal: 28.1s\tremaining: 1m 13s\n",
      "138: learn: 0.9592956\ttest: 0.9350168\tbestTest: 0.9350773 (133)\ttotal: 28.3s\tremaining: 1m 13s\n",
      "139: learn: 0.9593814\ttest: 0.9350975\tbestTest: 0.9350975 (139)\ttotal: 28.5s\tremaining: 1m 13s\n",
      "140: learn: 0.9595081\ttest: 0.9349845\tbestTest: 0.9350975 (139)\ttotal: 28.7s\tremaining: 1m 13s\n",
      "141: learn: 0.9597437\ttest: 0.9349804\tbestTest: 0.9350975 (139)\ttotal: 28.9s\tremaining: 1m 12s\n",
      "142: learn: 0.9598696\ttest: 0.9350208\tbestTest: 0.9350975 (139)\ttotal: 29.1s\tremaining: 1m 12s\n",
      "143: learn: 0.9599344\ttest: 0.9350369\tbestTest: 0.9350975 (139)\ttotal: 29.6s\tremaining: 1m 13s\n",
      "144: learn: 0.9600455\ttest: 0.9351823\tbestTest: 0.9351823 (144)\ttotal: 29.9s\tremaining: 1m 13s\n",
      "145: learn: 0.9603536\ttest: 0.9352307\tbestTest: 0.9352307 (145)\ttotal: 30.1s\tremaining: 1m 12s\n",
      "146: learn: 0.9607295\ttest: 0.935263\tbestTest: 0.935263 (146)\ttotal: 30.3s\tremaining: 1m 12s\n",
      "147: learn: 0.9609171\ttest: 0.9353478\tbestTest: 0.9353478 (147)\ttotal: 30.5s\tremaining: 1m 12s\n",
      "148: learn: 0.96109\ttest: 0.9354003\tbestTest: 0.9354003 (148)\ttotal: 30.7s\tremaining: 1m 12s\n",
      "149: learn: 0.9613047\ttest: 0.9353357\tbestTest: 0.9354003 (148)\ttotal: 30.9s\tremaining: 1m 12s\n",
      "150: learn: 0.9616051\ttest: 0.935376\tbestTest: 0.9354003 (148)\ttotal: 31.1s\tremaining: 1m 11s\n",
      "151: learn: 0.9617892\ttest: 0.9353922\tbestTest: 0.9354003 (148)\ttotal: 31.3s\tremaining: 1m 11s\n",
      "152: learn: 0.9620214\ttest: 0.9352751\tbestTest: 0.9354003 (148)\ttotal: 31.5s\tremaining: 1m 11s\n",
      "153: learn: 0.9621313\ttest: 0.9356062\tbestTest: 0.9356062 (153)\ttotal: 31.7s\tremaining: 1m 11s\n",
      "154: learn: 0.9622581\ttest: 0.9355093\tbestTest: 0.9356062 (153)\ttotal: 31.9s\tremaining: 1m 11s\n",
      "155: learn: 0.96252\ttest: 0.9355375\tbestTest: 0.9356062 (153)\ttotal: 32.1s\tremaining: 1m 10s\n",
      "156: learn: 0.9626741\ttest: 0.935695\tbestTest: 0.935695 (156)\ttotal: 32.3s\tremaining: 1m 10s\n",
      "157: learn: 0.962745\ttest: 0.9358363\tbestTest: 0.9358363 (157)\ttotal: 32.5s\tremaining: 1m 10s\n",
      "158: learn: 0.9629442\ttest: 0.9358282\tbestTest: 0.9358363 (157)\ttotal: 32.7s\tremaining: 1m 10s\n",
      "159: learn: 0.9630677\ttest: 0.9360543\tbestTest: 0.9360543 (159)\ttotal: 33s\tremaining: 1m 10s\n",
      "160: learn: 0.9634213\ttest: 0.9361188\tbestTest: 0.9361188 (160)\ttotal: 33.2s\tremaining: 1m 9s\n",
      "161: learn: 0.9636607\ttest: 0.9359776\tbestTest: 0.9361188 (160)\ttotal: 33.4s\tremaining: 1m 9s\n",
      "162: learn: 0.9638384\ttest: 0.9359897\tbestTest: 0.9361188 (160)\ttotal: 33.6s\tremaining: 1m 9s\n",
      "163: learn: 0.9640063\ttest: 0.9358968\tbestTest: 0.9361188 (160)\ttotal: 33.8s\tremaining: 1m 9s\n",
      "164: learn: 0.9643439\ttest: 0.9357999\tbestTest: 0.9361188 (160)\ttotal: 34s\tremaining: 1m 9s\n",
      "165: learn: 0.9644805\ttest: 0.9357353\tbestTest: 0.9361188 (160)\ttotal: 34.2s\tremaining: 1m 8s\n",
      "166: learn: 0.9647357\ttest: 0.9361067\tbestTest: 0.9361188 (160)\ttotal: 34.4s\tremaining: 1m 8s\n",
      "167: learn: 0.965042\ttest: 0.936244\tbestTest: 0.936244 (167)\ttotal: 34.6s\tremaining: 1m 8s\n",
      "168: learn: 0.9652035\ttest: 0.9362924\tbestTest: 0.9362924 (168)\ttotal: 34.9s\tremaining: 1m 8s\n",
      "169: learn: 0.9653932\ttest: 0.9362642\tbestTest: 0.9362924 (168)\ttotal: 35.1s\tremaining: 1m 8s\n",
      "170: learn: 0.9657016\ttest: 0.9360987\tbestTest: 0.9362924 (168)\ttotal: 35.3s\tremaining: 1m 7s\n",
      "171: learn: 0.9658456\ttest: 0.9363086\tbestTest: 0.9363086 (171)\ttotal: 35.5s\tremaining: 1m 7s\n",
      "172: learn: 0.9661211\ttest: 0.9364216\tbestTest: 0.9364216 (172)\ttotal: 35.7s\tremaining: 1m 7s\n",
      "173: learn: 0.9662\ttest: 0.9363651\tbestTest: 0.9364216 (172)\ttotal: 35.9s\tremaining: 1m 7s\n",
      "174: learn: 0.9665474\ttest: 0.936353\tbestTest: 0.9364216 (172)\ttotal: 36.2s\tremaining: 1m 7s\n",
      "175: learn: 0.9668152\ttest: 0.9364216\tbestTest: 0.9364216 (175)\ttotal: 36.4s\tremaining: 1m 6s\n",
      "176: learn: 0.9669608\ttest: 0.936462\tbestTest: 0.936462 (176)\ttotal: 36.6s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177: learn: 0.9672485\ttest: 0.9364337\tbestTest: 0.936462 (176)\ttotal: 36.8s\tremaining: 1m 6s\n",
      "178: learn: 0.9675099\ttest: 0.9364983\tbestTest: 0.9364983 (178)\ttotal: 37.1s\tremaining: 1m 6s\n",
      "179: learn: 0.9677022\ttest: 0.9366558\tbestTest: 0.9366558 (179)\ttotal: 37.3s\tremaining: 1m 6s\n",
      "180: learn: 0.967903\ttest: 0.9367728\tbestTest: 0.9367728 (180)\ttotal: 37.5s\tremaining: 1m 6s\n",
      "181: learn: 0.9681132\ttest: 0.9368294\tbestTest: 0.9368294 (181)\ttotal: 37.7s\tremaining: 1m 5s\n",
      "182: learn: 0.9682999\ttest: 0.9370191\tbestTest: 0.9370191 (182)\ttotal: 37.9s\tremaining: 1m 5s\n",
      "183: learn: 0.9684357\ttest: 0.9370514\tbestTest: 0.9370514 (183)\ttotal: 38s\tremaining: 1m 5s\n",
      "184: learn: 0.9687069\ttest: 0.9368536\tbestTest: 0.9370514 (183)\ttotal: 38.2s\tremaining: 1m 5s\n",
      "185: learn: 0.9688394\ttest: 0.9369141\tbestTest: 0.9370514 (183)\ttotal: 38.5s\tremaining: 1m 4s\n",
      "186: learn: 0.9689925\ttest: 0.9367204\tbestTest: 0.9370514 (183)\ttotal: 38.7s\tremaining: 1m 4s\n",
      "187: learn: 0.9691742\ttest: 0.9367769\tbestTest: 0.9370514 (183)\ttotal: 38.9s\tremaining: 1m 4s\n",
      "188: learn: 0.9694874\ttest: 0.9364499\tbestTest: 0.9370514 (183)\ttotal: 39.1s\tremaining: 1m 4s\n",
      "189: learn: 0.9696061\ttest: 0.9364055\tbestTest: 0.9370514 (183)\ttotal: 39.3s\tremaining: 1m 4s\n",
      "190: learn: 0.9698914\ttest: 0.9364701\tbestTest: 0.9370514 (183)\ttotal: 39.5s\tremaining: 1m 3s\n",
      "191: learn: 0.9700016\ttest: 0.9363853\tbestTest: 0.9370514 (183)\ttotal: 39.7s\tremaining: 1m 3s\n",
      "192: learn: 0.9701969\ttest: 0.936357\tbestTest: 0.9370514 (183)\ttotal: 39.9s\tremaining: 1m 3s\n",
      "193: learn: 0.9703411\ttest: 0.9363449\tbestTest: 0.9370514 (183)\ttotal: 40.2s\tremaining: 1m 3s\n",
      "194: learn: 0.9705154\ttest: 0.9362844\tbestTest: 0.9370514 (183)\ttotal: 40.4s\tremaining: 1m 3s\n",
      "195: learn: 0.9708036\ttest: 0.9361956\tbestTest: 0.9370514 (183)\ttotal: 40.6s\tremaining: 1m 3s\n",
      "196: learn: 0.9710347\ttest: 0.9363086\tbestTest: 0.9370514 (183)\ttotal: 40.8s\tremaining: 1m 2s\n",
      "197: learn: 0.9711463\ttest: 0.936349\tbestTest: 0.9370514 (183)\ttotal: 41.1s\tremaining: 1m 2s\n",
      "198: learn: 0.9714582\ttest: 0.9360825\tbestTest: 0.9370514 (183)\ttotal: 41.3s\tremaining: 1m 2s\n",
      "199: learn: 0.9716253\ttest: 0.9363893\tbestTest: 0.9370514 (183)\ttotal: 41.5s\tremaining: 1m 2s\n",
      "200: learn: 0.9718675\ttest: 0.936353\tbestTest: 0.9370514 (183)\ttotal: 41.7s\tremaining: 1m 2s\n",
      "201: learn: 0.9721483\ttest: 0.9362924\tbestTest: 0.9370514 (183)\ttotal: 41.9s\tremaining: 1m 1s\n",
      "202: learn: 0.972278\ttest: 0.936349\tbestTest: 0.9370514 (183)\ttotal: 42.1s\tremaining: 1m 1s\n",
      "203: learn: 0.9725824\ttest: 0.9362682\tbestTest: 0.9370514 (183)\ttotal: 42.3s\tremaining: 1m 1s\n",
      "204: learn: 0.9728334\ttest: 0.9363045\tbestTest: 0.9370514 (183)\ttotal: 42.5s\tremaining: 1m 1s\n",
      "205: learn: 0.9730356\ttest: 0.9363772\tbestTest: 0.9370514 (183)\ttotal: 42.7s\tremaining: 1m\n",
      "206: learn: 0.9732367\ttest: 0.9362319\tbestTest: 0.9370514 (183)\ttotal: 42.9s\tremaining: 1m\n",
      "207: learn: 0.9733817\ttest: 0.9362965\tbestTest: 0.9370514 (183)\ttotal: 43.1s\tremaining: 1m\n",
      "208: learn: 0.9734792\ttest: 0.9363772\tbestTest: 0.9370514 (183)\ttotal: 43.3s\tremaining: 1m\n",
      "209: learn: 0.9737542\ttest: 0.9362319\tbestTest: 0.9370514 (183)\ttotal: 43.5s\tremaining: 1m\n",
      "210: learn: 0.9738641\ttest: 0.9362319\tbestTest: 0.9370514 (183)\ttotal: 43.7s\tremaining: 59.9s\n",
      "211: learn: 0.9740129\ttest: 0.9361592\tbestTest: 0.9370514 (183)\ttotal: 43.9s\tremaining: 59.7s\n",
      "212: learn: 0.9742746\ttest: 0.9362278\tbestTest: 0.9370514 (183)\ttotal: 44.1s\tremaining: 59.5s\n",
      "213: learn: 0.9744233\ttest: 0.9361673\tbestTest: 0.9370514 (183)\ttotal: 44.3s\tremaining: 59.3s\n",
      "214: learn: 0.9745843\ttest: 0.9363328\tbestTest: 0.9370514 (183)\ttotal: 44.6s\tremaining: 59.1s\n",
      "215: learn: 0.974715\ttest: 0.9363368\tbestTest: 0.9370514 (183)\ttotal: 44.8s\tremaining: 58.9s\n",
      "216: learn: 0.9748715\ttest: 0.936462\tbestTest: 0.9370514 (183)\ttotal: 45s\tremaining: 58.6s\n",
      "217: learn: 0.9751379\ttest: 0.9363167\tbestTest: 0.9370514 (183)\ttotal: 45.2s\tremaining: 58.4s\n",
      "218: learn: 0.9753148\ttest: 0.9363045\tbestTest: 0.9370514 (183)\ttotal: 45.4s\tremaining: 58.2s\n",
      "219: learn: 0.9754171\ttest: 0.9363328\tbestTest: 0.9370514 (183)\ttotal: 45.6s\tremaining: 58s\n",
      "220: learn: 0.9755616\ttest: 0.936458\tbestTest: 0.9370514 (183)\ttotal: 45.8s\tremaining: 57.8s\n",
      "221: learn: 0.9756913\ttest: 0.9365589\tbestTest: 0.9370514 (183)\ttotal: 46s\tremaining: 57.6s\n",
      "222: learn: 0.9759997\ttest: 0.936575\tbestTest: 0.9370514 (183)\ttotal: 46.2s\tremaining: 57.4s\n",
      "223: learn: 0.9761431\ttest: 0.9367809\tbestTest: 0.9370514 (183)\ttotal: 46.4s\tremaining: 57.2s\n",
      "224: learn: 0.9762975\ttest: 0.9367567\tbestTest: 0.9370514 (183)\ttotal: 46.6s\tremaining: 57s\n",
      "225: learn: 0.9764178\ttest: 0.9368617\tbestTest: 0.9370514 (183)\ttotal: 46.8s\tremaining: 56.7s\n",
      "226: learn: 0.9765878\ttest: 0.9367971\tbestTest: 0.9370514 (183)\ttotal: 47s\tremaining: 56.5s\n",
      "227: learn: 0.9768067\ttest: 0.9368253\tbestTest: 0.9370514 (183)\ttotal: 47.3s\tremaining: 56.4s\n",
      "228: learn: 0.9769153\ttest: 0.9368738\tbestTest: 0.9370514 (183)\ttotal: 47.5s\tremaining: 56.2s\n",
      "229: learn: 0.9770747\ttest: 0.9368213\tbestTest: 0.9370514 (183)\ttotal: 47.7s\tremaining: 56s\n",
      "230: learn: 0.9772628\ttest: 0.9365831\tbestTest: 0.9370514 (183)\ttotal: 47.9s\tremaining: 55.8s\n",
      "231: learn: 0.9774416\ttest: 0.9365791\tbestTest: 0.9370514 (183)\ttotal: 48.2s\tremaining: 55.6s\n",
      "232: learn: 0.9775824\ttest: 0.9364943\tbestTest: 0.9370514 (183)\ttotal: 48.4s\tremaining: 55.4s\n",
      "233: learn: 0.9777402\ttest: 0.9365266\tbestTest: 0.9370514 (183)\ttotal: 48.6s\tremaining: 55.3s\n",
      "234: learn: 0.9780768\ttest: 0.9366114\tbestTest: 0.9370514 (183)\ttotal: 48.8s\tremaining: 55s\n",
      "235: learn: 0.9781886\ttest: 0.9365548\tbestTest: 0.9370514 (183)\ttotal: 49s\tremaining: 54.8s\n",
      "236: learn: 0.9783408\ttest: 0.9364378\tbestTest: 0.9370514 (183)\ttotal: 49.2s\tremaining: 54.6s\n",
      "237: learn: 0.9784194\ttest: 0.9364055\tbestTest: 0.9370514 (183)\ttotal: 49.5s\tremaining: 54.5s\n",
      "238: learn: 0.978679\ttest: 0.9365468\tbestTest: 0.9370514 (183)\ttotal: 49.7s\tremaining: 54.3s\n",
      "239: learn: 0.9788543\ttest: 0.9365185\tbestTest: 0.9370514 (183)\ttotal: 49.9s\tremaining: 54.1s\n",
      "240: learn: 0.979091\ttest: 0.9365306\tbestTest: 0.9370514 (183)\ttotal: 50.1s\tremaining: 53.9s\n",
      "241: learn: 0.979278\ttest: 0.9365104\tbestTest: 0.9370514 (183)\ttotal: 50.4s\tremaining: 53.7s\n",
      "242: learn: 0.9794624\ttest: 0.9366235\tbestTest: 0.9370514 (183)\ttotal: 50.6s\tremaining: 53.5s\n",
      "243: learn: 0.9795227\ttest: 0.9365387\tbestTest: 0.9370514 (183)\ttotal: 50.7s\tremaining: 53.2s\n",
      "244: learn: 0.9797153\ttest: 0.9364943\tbestTest: 0.9370514 (183)\ttotal: 50.9s\tremaining: 53s\n",
      "245: learn: 0.9798199\ttest: 0.9364055\tbestTest: 0.9370514 (183)\ttotal: 51.1s\tremaining: 52.8s\n",
      "246: learn: 0.9800614\ttest: 0.9364135\tbestTest: 0.9370514 (183)\ttotal: 51.3s\tremaining: 52.6s\n",
      "247: learn: 0.9801764\ttest: 0.9365468\tbestTest: 0.9370514 (183)\ttotal: 51.6s\tremaining: 52.4s\n",
      "248: learn: 0.9804035\ttest: 0.9365468\tbestTest: 0.9370514 (183)\ttotal: 51.8s\tremaining: 52.2s\n",
      "249: learn: 0.9806381\ttest: 0.9363772\tbestTest: 0.9370514 (183)\ttotal: 52s\tremaining: 52s\n",
      "250: learn: 0.9808071\ttest: 0.9361431\tbestTest: 0.9370514 (183)\ttotal: 52.2s\tremaining: 51.8s\n",
      "251: learn: 0.9808809\ttest: 0.9362117\tbestTest: 0.9370514 (183)\ttotal: 52.4s\tremaining: 51.6s\n",
      "252: learn: 0.9810884\ttest: 0.9362561\tbestTest: 0.9370514 (183)\ttotal: 52.6s\tremaining: 51.4s\n",
      "253: learn: 0.9812637\ttest: 0.9362359\tbestTest: 0.9370514 (183)\ttotal: 52.8s\tremaining: 51.2s\n",
      "254: learn: 0.9813293\ttest: 0.9363045\tbestTest: 0.9370514 (183)\ttotal: 53s\tremaining: 51s\n",
      "255: learn: 0.9814531\ttest: 0.9361431\tbestTest: 0.9370514 (183)\ttotal: 53.3s\tremaining: 50.8s\n",
      "256: learn: 0.9815458\ttest: 0.936135\tbestTest: 0.9370514 (183)\ttotal: 53.5s\tremaining: 50.6s\n",
      "257: learn: 0.9817222\ttest: 0.9361633\tbestTest: 0.9370514 (183)\ttotal: 53.7s\tremaining: 50.4s\n",
      "258: learn: 0.9818882\ttest: 0.9360139\tbestTest: 0.9370514 (183)\ttotal: 53.9s\tremaining: 50.2s\n",
      "259: learn: 0.9820569\ttest: 0.936135\tbestTest: 0.9370514 (183)\ttotal: 54.1s\tremaining: 50s\n",
      "260: learn: 0.9822578\ttest: 0.936139\tbestTest: 0.9370514 (183)\ttotal: 54.4s\tremaining: 49.8s\n",
      "261: learn: 0.982339\ttest: 0.9362803\tbestTest: 0.9370514 (183)\ttotal: 54.6s\tremaining: 49.6s\n",
      "262: learn: 0.9825109\ttest: 0.9362036\tbestTest: 0.9370514 (183)\ttotal: 54.8s\tremaining: 49.4s\n",
      "263: learn: 0.9826376\ttest: 0.93624\tbestTest: 0.9370514 (183)\ttotal: 55s\tremaining: 49.2s\n",
      "264: learn: 0.9827548\ttest: 0.9361673\tbestTest: 0.9370514 (183)\ttotal: 55.3s\tremaining: 49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265: learn: 0.9828292\ttest: 0.9361511\tbestTest: 0.9370514 (183)\ttotal: 55.5s\tremaining: 48.8s\n",
      "266: learn: 0.9829551\ttest: 0.9362359\tbestTest: 0.9370514 (183)\ttotal: 55.7s\tremaining: 48.6s\n",
      "267: learn: 0.9830319\ttest: 0.9360987\tbestTest: 0.9370514 (183)\ttotal: 55.8s\tremaining: 48.3s\n",
      "268: learn: 0.9831363\ttest: 0.9361915\tbestTest: 0.9370514 (183)\ttotal: 56s\tremaining: 48.1s\n",
      "269: learn: 0.9832648\ttest: 0.9362723\tbestTest: 0.9370514 (183)\ttotal: 56.2s\tremaining: 47.9s\n",
      "270: learn: 0.9834136\ttest: 0.9363368\tbestTest: 0.9370514 (183)\ttotal: 56.5s\tremaining: 47.7s\n",
      "271: learn: 0.9834715\ttest: 0.9363005\tbestTest: 0.9370514 (183)\ttotal: 56.7s\tremaining: 47.5s\n",
      "272: learn: 0.9834901\ttest: 0.9362561\tbestTest: 0.9370514 (183)\ttotal: 56.9s\tremaining: 47.3s\n",
      "273: learn: 0.98362\ttest: 0.936244\tbestTest: 0.9370514 (183)\ttotal: 57.1s\tremaining: 47.1s\n",
      "274: learn: 0.9837722\ttest: 0.936248\tbestTest: 0.9370514 (183)\ttotal: 57.3s\tremaining: 46.9s\n",
      "275: learn: 0.9838625\ttest: 0.9361511\tbestTest: 0.9370514 (183)\ttotal: 57.5s\tremaining: 46.7s\n",
      "276: learn: 0.9840535\ttest: 0.9359816\tbestTest: 0.9370514 (183)\ttotal: 57.8s\tremaining: 46.5s\n",
      "277: learn: 0.9841763\ttest: 0.9358726\tbestTest: 0.9370514 (183)\ttotal: 58s\tremaining: 46.3s\n",
      "278: learn: 0.9843123\ttest: 0.935804\tbestTest: 0.9370514 (183)\ttotal: 58.2s\tremaining: 46.1s\n",
      "279: learn: 0.9843325\ttest: 0.9357717\tbestTest: 0.9370514 (183)\ttotal: 58.4s\tremaining: 45.9s\n",
      "280: learn: 0.9844812\ttest: 0.9359291\tbestTest: 0.9370514 (183)\ttotal: 58.7s\tremaining: 45.7s\n",
      "281: learn: 0.9845923\ttest: 0.9358524\tbestTest: 0.9370514 (183)\ttotal: 58.9s\tremaining: 45.6s\n",
      "282: learn: 0.9847601\ttest: 0.9360543\tbestTest: 0.9370514 (183)\ttotal: 59.2s\tremaining: 45.4s\n",
      "283: learn: 0.9848244\ttest: 0.9360381\tbestTest: 0.9370514 (183)\ttotal: 59.4s\tremaining: 45.2s\n",
      "284: learn: 0.9849177\ttest: 0.9359533\tbestTest: 0.9370514 (183)\ttotal: 59.6s\tremaining: 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9370513907\n",
      "bestIteration = 183\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.984917673598 0.935953332526\n",
      "[0.9359533325259376]\n",
      "0: learn: 0.7345524\ttest: 0.7557144\tbestTest: 0.7557144 (0)\ttotal: 290ms\tremaining: 2m 24s\n",
      "1: learn: 0.8728072\ttest: 0.8710066\tbestTest: 0.8710066 (1)\ttotal: 513ms\tremaining: 2m 7s\n",
      "2: learn: 0.8810186\ttest: 0.878935\tbestTest: 0.878935 (2)\ttotal: 713ms\tremaining: 1m 58s\n",
      "3: learn: 0.8820779\ttest: 0.879028\tbestTest: 0.879028 (3)\ttotal: 901ms\tremaining: 1m 51s\n",
      "4: learn: 0.8821497\ttest: 0.8769048\tbestTest: 0.879028 (3)\ttotal: 1.08s\tremaining: 1m 46s\n",
      "5: learn: 0.8963248\ttest: 0.8907726\tbestTest: 0.8907726 (5)\ttotal: 1.46s\tremaining: 1m 59s\n",
      "6: learn: 0.8968682\ttest: 0.8913455\tbestTest: 0.8913455 (6)\ttotal: 1.65s\tremaining: 1m 56s\n",
      "7: learn: 0.9013652\ttest: 0.89682\tbestTest: 0.89682 (7)\ttotal: 1.86s\tremaining: 1m 54s\n",
      "8: learn: 0.9051829\ttest: 0.8966621\tbestTest: 0.89682 (7)\ttotal: 2.04s\tremaining: 1m 51s\n",
      "9: learn: 0.9051065\ttest: 0.8969216\tbestTest: 0.8969216 (9)\ttotal: 2.24s\tremaining: 1m 49s\n",
      "10: learn: 0.9095314\ttest: 0.9000588\tbestTest: 0.9000588 (10)\ttotal: 2.63s\tremaining: 1m 56s\n",
      "11: learn: 0.9123765\ttest: 0.9030295\tbestTest: 0.9030295 (11)\ttotal: 2.81s\tremaining: 1m 54s\n",
      "12: learn: 0.9131266\ttest: 0.9031701\tbestTest: 0.9031701 (12)\ttotal: 3.01s\tremaining: 1m 52s\n",
      "13: learn: 0.9128322\ttest: 0.9023269\tbestTest: 0.9031701 (12)\ttotal: 3.22s\tremaining: 1m 51s\n",
      "14: learn: 0.9127958\ttest: 0.9017042\tbestTest: 0.9031701 (12)\ttotal: 3.43s\tremaining: 1m 51s\n",
      "15: learn: 0.9160875\ttest: 0.9053343\tbestTest: 0.9053343 (15)\ttotal: 3.81s\tremaining: 1m 55s\n",
      "16: learn: 0.9191414\ttest: 0.9091829\tbestTest: 0.9091829 (16)\ttotal: 4.03s\tremaining: 1m 54s\n",
      "17: learn: 0.9187482\ttest: 0.9093559\tbestTest: 0.9093559 (17)\ttotal: 4.24s\tremaining: 1m 53s\n",
      "18: learn: 0.9193201\ttest: 0.9103937\tbestTest: 0.9103937 (18)\ttotal: 4.45s\tremaining: 1m 52s\n",
      "19: learn: 0.9198808\ttest: 0.9097148\tbestTest: 0.9103937 (18)\ttotal: 4.66s\tremaining: 1m 51s\n",
      "20: learn: 0.9219488\ttest: 0.913265\tbestTest: 0.913265 (20)\ttotal: 5.03s\tremaining: 1m 54s\n",
      "21: learn: 0.923651\ttest: 0.9146617\tbestTest: 0.9146617 (21)\ttotal: 5.24s\tremaining: 1m 53s\n",
      "22: learn: 0.9238608\ttest: 0.9144065\tbestTest: 0.9146617 (21)\ttotal: 5.44s\tremaining: 1m 52s\n",
      "23: learn: 0.9241081\ttest: 0.9145925\tbestTest: 0.9146617 (21)\ttotal: 5.65s\tremaining: 1m 52s\n",
      "24: learn: 0.9253617\ttest: 0.9162011\tbestTest: 0.9162011 (24)\ttotal: 5.85s\tremaining: 1m 51s\n",
      "25: learn: 0.9266315\ttest: 0.9175027\tbestTest: 0.9175027 (25)\ttotal: 6.22s\tremaining: 1m 53s\n",
      "26: learn: 0.9282127\ttest: 0.9192237\tbestTest: 0.9192237 (26)\ttotal: 6.43s\tremaining: 1m 52s\n",
      "27: learn: 0.9281858\ttest: 0.9191329\tbestTest: 0.9192237 (26)\ttotal: 6.63s\tremaining: 1m 51s\n",
      "28: learn: 0.9284832\ttest: 0.9190248\tbestTest: 0.9192237 (26)\ttotal: 6.86s\tremaining: 1m 51s\n",
      "29: learn: 0.9279874\ttest: 0.9184497\tbestTest: 0.9192237 (26)\ttotal: 7.04s\tremaining: 1m 50s\n",
      "30: learn: 0.928118\ttest: 0.9184713\tbestTest: 0.9192237 (26)\ttotal: 7.43s\tremaining: 1m 52s\n",
      "31: learn: 0.9286638\ttest: 0.9187654\tbestTest: 0.9192237 (26)\ttotal: 7.63s\tremaining: 1m 51s\n",
      "32: learn: 0.9289802\ttest: 0.9187178\tbestTest: 0.9192237 (26)\ttotal: 7.82s\tremaining: 1m 50s\n",
      "33: learn: 0.9293765\ttest: 0.9196215\tbestTest: 0.9196215 (33)\ttotal: 8.04s\tremaining: 1m 50s\n",
      "34: learn: 0.9302558\ttest: 0.9205772\tbestTest: 0.9205772 (34)\ttotal: 8.25s\tremaining: 1m 49s\n",
      "35: learn: 0.9300571\ttest: 0.9202486\tbestTest: 0.9205772 (34)\ttotal: 8.55s\tremaining: 1m 50s\n",
      "36: learn: 0.9308262\ttest: 0.9207934\tbestTest: 0.9207934 (36)\ttotal: 8.77s\tremaining: 1m 49s\n",
      "37: learn: 0.930862\ttest: 0.9204777\tbestTest: 0.9207934 (36)\ttotal: 8.99s\tremaining: 1m 49s\n",
      "38: learn: 0.9309797\ttest: 0.9202356\tbestTest: 0.9207934 (36)\ttotal: 9.21s\tremaining: 1m 48s\n",
      "39: learn: 0.9316117\ttest: 0.9209577\tbestTest: 0.9209577 (39)\ttotal: 9.44s\tremaining: 1m 48s\n",
      "40: learn: 0.9322059\ttest: 0.9216193\tbestTest: 0.9216193 (40)\ttotal: 9.78s\tremaining: 1m 49s\n",
      "41: learn: 0.9323398\ttest: 0.9217447\tbestTest: 0.9217447 (41)\ttotal: 9.99s\tremaining: 1m 48s\n",
      "42: learn: 0.9327306\ttest: 0.9216582\tbestTest: 0.9217447 (41)\ttotal: 10.2s\tremaining: 1m 48s\n",
      "43: learn: 0.9328079\ttest: 0.9217577\tbestTest: 0.9217577 (43)\ttotal: 10.4s\tremaining: 1m 47s\n",
      "44: learn: 0.9329583\ttest: 0.9214247\tbestTest: 0.9217577 (43)\ttotal: 10.6s\tremaining: 1m 47s\n",
      "45: learn: 0.9330343\ttest: 0.9216712\tbestTest: 0.9217577 (43)\ttotal: 11s\tremaining: 1m 48s\n",
      "46: learn: 0.9339895\ttest: 0.923189\tbestTest: 0.923189 (46)\ttotal: 11.2s\tremaining: 1m 47s\n",
      "47: learn: 0.9344411\ttest: 0.9240279\tbestTest: 0.9240279 (47)\ttotal: 11.3s\tremaining: 1m 46s\n",
      "48: learn: 0.9346427\ttest: 0.9240971\tbestTest: 0.9240971 (48)\ttotal: 11.5s\tremaining: 1m 46s\n",
      "49: learn: 0.9350491\ttest: 0.9238506\tbestTest: 0.9240971 (48)\ttotal: 11.7s\tremaining: 1m 45s\n",
      "50: learn: 0.9354843\ttest: 0.9237771\tbestTest: 0.9240971 (48)\ttotal: 12.1s\tremaining: 1m 46s\n",
      "51: learn: 0.9357101\ttest: 0.9238895\tbestTest: 0.9240971 (48)\ttotal: 12.3s\tremaining: 1m 45s\n",
      "52: learn: 0.9360803\ttest: 0.9237858\tbestTest: 0.9240971 (48)\ttotal: 12.5s\tremaining: 1m 45s\n",
      "53: learn: 0.9360936\ttest: 0.9237858\tbestTest: 0.9240971 (48)\ttotal: 12.7s\tremaining: 1m 44s\n",
      "54: learn: 0.9365364\ttest: 0.9242528\tbestTest: 0.9242528 (54)\ttotal: 12.9s\tremaining: 1m 44s\n",
      "55: learn: 0.9370507\ttest: 0.9243479\tbestTest: 0.9243479 (55)\ttotal: 13.3s\tremaining: 1m 45s\n",
      "56: learn: 0.9370387\ttest: 0.9242268\tbestTest: 0.9243479 (55)\ttotal: 13.5s\tremaining: 1m 44s\n",
      "57: learn: 0.9371092\ttest: 0.9241317\tbestTest: 0.9243479 (55)\ttotal: 13.7s\tremaining: 1m 44s\n",
      "58: learn: 0.937289\ttest: 0.9238636\tbestTest: 0.9243479 (55)\ttotal: 13.9s\tremaining: 1m 43s\n",
      "59: learn: 0.9373739\ttest: 0.9237685\tbestTest: 0.9243479 (55)\ttotal: 14.1s\tremaining: 1m 43s\n",
      "60: learn: 0.9378012\ttest: 0.9234052\tbestTest: 0.9243479 (55)\ttotal: 14.5s\tremaining: 1m 44s\n",
      "61: learn: 0.9383484\ttest: 0.923362\tbestTest: 0.9243479 (55)\ttotal: 14.7s\tremaining: 1m 43s\n",
      "62: learn: 0.9386069\ttest: 0.9232279\tbestTest: 0.9243479 (55)\ttotal: 14.9s\tremaining: 1m 43s\n",
      "63: learn: 0.9390729\ttest: 0.9232193\tbestTest: 0.9243479 (55)\ttotal: 15.1s\tremaining: 1m 42s\n",
      "64: learn: 0.9394626\ttest: 0.923336\tbestTest: 0.9243479 (55)\ttotal: 15.3s\tremaining: 1m 42s\n",
      "65: learn: 0.9396159\ttest: 0.9232323\tbestTest: 0.9243479 (55)\ttotal: 15.7s\tremaining: 1m 43s\n",
      "66: learn: 0.940533\ttest: 0.9239804\tbestTest: 0.9243479 (55)\ttotal: 15.9s\tremaining: 1m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67: learn: 0.9409199\ttest: 0.9239328\tbestTest: 0.9243479 (55)\ttotal: 16.1s\tremaining: 1m 42s\n",
      "68: learn: 0.9411102\ttest: 0.9240712\tbestTest: 0.9243479 (55)\ttotal: 16.3s\tremaining: 1m 41s\n",
      "69: learn: 0.941378\ttest: 0.9239328\tbestTest: 0.9243479 (55)\ttotal: 16.5s\tremaining: 1m 41s\n",
      "70: learn: 0.9417278\ttest: 0.924123\tbestTest: 0.9243479 (55)\ttotal: 16.7s\tremaining: 1m 41s\n",
      "71: learn: 0.9418709\ttest: 0.9239501\tbestTest: 0.9243479 (55)\ttotal: 17s\tremaining: 1m 40s\n",
      "72: learn: 0.9421361\ttest: 0.9241922\tbestTest: 0.9243479 (55)\ttotal: 17.2s\tremaining: 1m 40s\n",
      "73: learn: 0.9424029\ttest: 0.9242052\tbestTest: 0.9243479 (55)\ttotal: 17.4s\tremaining: 1m 39s\n",
      "74: learn: 0.9427282\ttest: 0.9241922\tbestTest: 0.9243479 (55)\ttotal: 17.5s\tremaining: 1m 39s\n",
      "75: learn: 0.9430713\ttest: 0.9249144\tbestTest: 0.9249144 (75)\ttotal: 17.9s\tremaining: 1m 39s\n",
      "76: learn: 0.9434099\ttest: 0.9251306\tbestTest: 0.9251306 (76)\ttotal: 18.1s\tremaining: 1m 39s\n",
      "77: learn: 0.9435425\ttest: 0.9251695\tbestTest: 0.9251695 (77)\ttotal: 18.3s\tremaining: 1m 38s\n",
      "78: learn: 0.9439189\ttest: 0.9250484\tbestTest: 0.9251695 (77)\ttotal: 18.5s\tremaining: 1m 38s\n",
      "79: learn: 0.9440777\ttest: 0.925109\tbestTest: 0.9251695 (77)\ttotal: 18.7s\tremaining: 1m 38s\n",
      "80: learn: 0.9441957\ttest: 0.9251046\tbestTest: 0.9251695 (77)\ttotal: 19.1s\tremaining: 1m 38s\n",
      "81: learn: 0.944399\ttest: 0.9252819\tbestTest: 0.9252819 (81)\ttotal: 19.3s\tremaining: 1m 38s\n",
      "82: learn: 0.9445418\ttest: 0.9256019\tbestTest: 0.9256019 (82)\ttotal: 19.5s\tremaining: 1m 38s\n",
      "83: learn: 0.9448867\ttest: 0.92571\tbestTest: 0.92571 (83)\ttotal: 19.7s\tremaining: 1m 37s\n",
      "84: learn: 0.9450042\ttest: 0.9255544\tbestTest: 0.92571 (83)\ttotal: 19.9s\tremaining: 1m 37s\n",
      "85: learn: 0.9451911\ttest: 0.9258311\tbestTest: 0.9258311 (85)\ttotal: 20.3s\tremaining: 1m 37s\n",
      "86: learn: 0.9456051\ttest: 0.9259608\tbestTest: 0.9259608 (86)\ttotal: 20.5s\tremaining: 1m 37s\n",
      "87: learn: 0.9459468\ttest: 0.9260041\tbestTest: 0.9260041 (87)\ttotal: 20.7s\tremaining: 1m 37s\n",
      "88: learn: 0.9461896\ttest: 0.9261943\tbestTest: 0.9261943 (88)\ttotal: 20.9s\tremaining: 1m 36s\n",
      "89: learn: 0.9467353\ttest: 0.9268084\tbestTest: 0.9268084 (89)\ttotal: 21.2s\tremaining: 1m 36s\n",
      "90: learn: 0.947065\ttest: 0.9272451\tbestTest: 0.9272451 (90)\ttotal: 21.5s\tremaining: 1m 36s\n",
      "91: learn: 0.9474947\ttest: 0.9273403\tbestTest: 0.9273403 (91)\ttotal: 21.7s\tremaining: 1m 36s\n",
      "92: learn: 0.9477093\ttest: 0.9274613\tbestTest: 0.9274613 (92)\ttotal: 21.9s\tremaining: 1m 35s\n",
      "93: learn: 0.9478549\ttest: 0.927924\tbestTest: 0.927924 (93)\ttotal: 22.1s\tremaining: 1m 35s\n",
      "94: learn: 0.9480776\ttest: 0.9279197\tbestTest: 0.927924 (93)\ttotal: 22.3s\tremaining: 1m 35s\n",
      "95: learn: 0.9482622\ttest: 0.9278116\tbestTest: 0.927924 (93)\ttotal: 22.6s\tremaining: 1m 35s\n",
      "96: learn: 0.9485165\ttest: 0.9277208\tbestTest: 0.927924 (93)\ttotal: 22.8s\tremaining: 1m 34s\n",
      "97: learn: 0.9486715\ttest: 0.927963\tbestTest: 0.927963 (97)\ttotal: 23s\tremaining: 1m 34s\n",
      "98: learn: 0.9488736\ttest: 0.9278505\tbestTest: 0.927963 (97)\ttotal: 23.2s\tremaining: 1m 34s\n",
      "99: learn: 0.9492255\ttest: 0.9280711\tbestTest: 0.9280711 (99)\ttotal: 23.4s\tremaining: 1m 33s\n",
      "100: learn: 0.9495699\ttest: 0.9286764\tbestTest: 0.9286764 (100)\ttotal: 23.6s\tremaining: 1m 33s\n",
      "101: learn: 0.9497954\ttest: 0.9286116\tbestTest: 0.9286764 (100)\ttotal: 23.8s\tremaining: 1m 33s\n",
      "102: learn: 0.9501805\ttest: 0.9288191\tbestTest: 0.9288191 (102)\ttotal: 24.1s\tremaining: 1m 32s\n",
      "103: learn: 0.9502932\ttest: 0.9289705\tbestTest: 0.9289705 (103)\ttotal: 24.3s\tremaining: 1m 32s\n",
      "104: learn: 0.9505034\ttest: 0.9288494\tbestTest: 0.9289705 (103)\ttotal: 24.5s\tremaining: 1m 32s\n",
      "105: learn: 0.9507553\ttest: 0.9291089\tbestTest: 0.9291089 (105)\ttotal: 24.7s\tremaining: 1m 31s\n",
      "106: learn: 0.9509242\ttest: 0.9289532\tbestTest: 0.9291089 (105)\ttotal: 24.9s\tremaining: 1m 31s\n",
      "107: learn: 0.9512587\ttest: 0.929191\tbestTest: 0.929191 (107)\ttotal: 25.1s\tremaining: 1m 30s\n",
      "108: learn: 0.9513623\ttest: 0.9293035\tbestTest: 0.9293035 (108)\ttotal: 25.3s\tremaining: 1m 30s\n",
      "109: learn: 0.9516335\ttest: 0.9294894\tbestTest: 0.9294894 (109)\ttotal: 25.5s\tremaining: 1m 30s\n",
      "110: learn: 0.9518369\ttest: 0.9293337\tbestTest: 0.9294894 (109)\ttotal: 25.6s\tremaining: 1m 29s\n",
      "111: learn: 0.9520069\ttest: 0.9296191\tbestTest: 0.9296191 (111)\ttotal: 25.8s\tremaining: 1m 29s\n",
      "112: learn: 0.9523666\ttest: 0.9296105\tbestTest: 0.9296191 (111)\ttotal: 26s\tremaining: 1m 29s\n",
      "113: learn: 0.9526026\ttest: 0.929831\tbestTest: 0.929831 (113)\ttotal: 26.2s\tremaining: 1m 28s\n",
      "114: learn: 0.9529999\ttest: 0.9297532\tbestTest: 0.929831 (113)\ttotal: 26.4s\tremaining: 1m 28s\n",
      "115: learn: 0.9532401\ttest: 0.9299521\tbestTest: 0.9299521 (115)\ttotal: 26.6s\tremaining: 1m 28s\n",
      "116: learn: 0.9535475\ttest: 0.9304191\tbestTest: 0.9304191 (116)\ttotal: 26.8s\tremaining: 1m 27s\n",
      "117: learn: 0.9536339\ttest: 0.9305056\tbestTest: 0.9305056 (117)\ttotal: 27s\tremaining: 1m 27s\n",
      "118: learn: 0.953843\ttest: 0.9306267\tbestTest: 0.9306267 (118)\ttotal: 27.3s\tremaining: 1m 27s\n",
      "119: learn: 0.9541362\ttest: 0.930778\tbestTest: 0.930778 (119)\ttotal: 27.5s\tremaining: 1m 27s\n",
      "120: learn: 0.9543589\ttest: 0.9309856\tbestTest: 0.9309856 (120)\ttotal: 27.7s\tremaining: 1m 26s\n",
      "121: learn: 0.9545842\ttest: 0.9312537\tbestTest: 0.9312537 (121)\ttotal: 27.9s\tremaining: 1m 26s\n",
      "122: learn: 0.954958\ttest: 0.9312494\tbestTest: 0.9312537 (121)\ttotal: 28.1s\tremaining: 1m 26s\n",
      "123: learn: 0.9552615\ttest: 0.9312926\tbestTest: 0.9312926 (123)\ttotal: 28.3s\tremaining: 1m 25s\n",
      "124: learn: 0.9553035\ttest: 0.9315045\tbestTest: 0.9315045 (124)\ttotal: 28.5s\tremaining: 1m 25s\n",
      "125: learn: 0.9553821\ttest: 0.9315045\tbestTest: 0.9315045 (125)\ttotal: 28.8s\tremaining: 1m 25s\n",
      "126: learn: 0.9554043\ttest: 0.9316126\tbestTest: 0.9316126 (126)\ttotal: 29s\tremaining: 1m 25s\n",
      "127: learn: 0.9555434\ttest: 0.931552\tbestTest: 0.9316126 (126)\ttotal: 29.3s\tremaining: 1m 25s\n",
      "128: learn: 0.955916\ttest: 0.9315088\tbestTest: 0.9316126 (126)\ttotal: 29.5s\tremaining: 1m 24s\n",
      "129: learn: 0.9562794\ttest: 0.9321401\tbestTest: 0.9321401 (129)\ttotal: 29.7s\tremaining: 1m 24s\n",
      "130: learn: 0.9565271\ttest: 0.9320061\tbestTest: 0.9321401 (129)\ttotal: 30.1s\tremaining: 1m 24s\n",
      "131: learn: 0.9568122\ttest: 0.9319542\tbestTest: 0.9321401 (129)\ttotal: 30.3s\tremaining: 1m 24s\n",
      "132: learn: 0.9570628\ttest: 0.9321142\tbestTest: 0.9321401 (129)\ttotal: 30.5s\tremaining: 1m 24s\n",
      "133: learn: 0.9571644\ttest: 0.9321834\tbestTest: 0.9321834 (133)\ttotal: 30.7s\tremaining: 1m 23s\n",
      "134: learn: 0.9572513\ttest: 0.932058\tbestTest: 0.9321834 (133)\ttotal: 30.9s\tremaining: 1m 23s\n",
      "135: learn: 0.9572873\ttest: 0.9322137\tbestTest: 0.9322137 (135)\ttotal: 31.3s\tremaining: 1m 23s\n",
      "136: learn: 0.9574732\ttest: 0.9322266\tbestTest: 0.9322266 (136)\ttotal: 31.5s\tremaining: 1m 23s\n",
      "137: learn: 0.9576599\ttest: 0.9321315\tbestTest: 0.9322266 (136)\ttotal: 31.7s\tremaining: 1m 23s\n",
      "138: learn: 0.9580405\ttest: 0.9319585\tbestTest: 0.9322266 (136)\ttotal: 31.9s\tremaining: 1m 22s\n",
      "139: learn: 0.9581405\ttest: 0.9320277\tbestTest: 0.9322266 (136)\ttotal: 32.1s\tremaining: 1m 22s\n",
      "140: learn: 0.9582966\ttest: 0.9320364\tbestTest: 0.9322266 (136)\ttotal: 32.5s\tremaining: 1m 22s\n",
      "141: learn: 0.9586495\ttest: 0.9321704\tbestTest: 0.9322266 (136)\ttotal: 32.7s\tremaining: 1m 22s\n",
      "142: learn: 0.9589406\ttest: 0.9320364\tbestTest: 0.9322266 (136)\ttotal: 32.9s\tremaining: 1m 22s\n",
      "143: learn: 0.9590975\ttest: 0.9319542\tbestTest: 0.9322266 (136)\ttotal: 33.1s\tremaining: 1m 21s\n",
      "144: learn: 0.9591573\ttest: 0.9319801\tbestTest: 0.9322266 (136)\ttotal: 33.3s\tremaining: 1m 21s\n",
      "145: learn: 0.9592816\ttest: 0.932071\tbestTest: 0.9322266 (136)\ttotal: 33.7s\tremaining: 1m 21s\n",
      "146: learn: 0.9593797\ttest: 0.9321747\tbestTest: 0.9322266 (136)\ttotal: 33.9s\tremaining: 1m 21s\n",
      "147: learn: 0.9597635\ttest: 0.9322828\tbestTest: 0.9322828 (147)\ttotal: 34.1s\tremaining: 1m 21s\n",
      "148: learn: 0.960129\ttest: 0.9322482\tbestTest: 0.9322828 (147)\ttotal: 34.2s\tremaining: 1m 20s\n",
      "149: learn: 0.9604563\ttest: 0.9324082\tbestTest: 0.9324082 (149)\ttotal: 34.4s\tremaining: 1m 20s\n",
      "150: learn: 0.9606187\ttest: 0.9322958\tbestTest: 0.9324082 (149)\ttotal: 34.8s\tremaining: 1m 20s\n",
      "151: learn: 0.9607816\ttest: 0.9323174\tbestTest: 0.9324082 (149)\ttotal: 35s\tremaining: 1m 20s\n",
      "152: learn: 0.9609169\ttest: 0.9324688\tbestTest: 0.9324688 (152)\ttotal: 35.2s\tremaining: 1m 19s\n",
      "153: learn: 0.9611053\ttest: 0.9324947\tbestTest: 0.9324947 (153)\ttotal: 35.4s\tremaining: 1m 19s\n",
      "154: learn: 0.9613366\ttest: 0.9327628\tbestTest: 0.9327628 (154)\ttotal: 35.6s\tremaining: 1m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155: learn: 0.9614439\ttest: 0.9327585\tbestTest: 0.9327628 (154)\ttotal: 36s\tremaining: 1m 19s\n",
      "156: learn: 0.9615831\ttest: 0.9328969\tbestTest: 0.9328969 (156)\ttotal: 36.2s\tremaining: 1m 19s\n",
      "157: learn: 0.9617413\ttest: 0.9328147\tbestTest: 0.9328969 (156)\ttotal: 36.3s\tremaining: 1m 18s\n",
      "158: learn: 0.961847\ttest: 0.9329012\tbestTest: 0.9329012 (158)\ttotal: 36.5s\tremaining: 1m 18s\n",
      "159: learn: 0.9620086\ttest: 0.9327628\tbestTest: 0.9329012 (158)\ttotal: 36.7s\tremaining: 1m 18s\n",
      "160: learn: 0.9623715\ttest: 0.9324731\tbestTest: 0.9329012 (158)\ttotal: 37.1s\tremaining: 1m 18s\n",
      "161: learn: 0.9625861\ttest: 0.9324774\tbestTest: 0.9329012 (158)\ttotal: 37.3s\tremaining: 1m 17s\n",
      "162: learn: 0.9627806\ttest: 0.9325682\tbestTest: 0.9329012 (158)\ttotal: 37.5s\tremaining: 1m 17s\n",
      "163: learn: 0.9629474\ttest: 0.932499\tbestTest: 0.9329012 (158)\ttotal: 37.7s\tremaining: 1m 17s\n",
      "164: learn: 0.9630482\ttest: 0.9325682\tbestTest: 0.9329012 (158)\ttotal: 37.9s\tremaining: 1m 17s\n",
      "165: learn: 0.963216\ttest: 0.9327196\tbestTest: 0.9329012 (158)\ttotal: 38.3s\tremaining: 1m 17s\n",
      "166: learn: 0.9634071\ttest: 0.9329834\tbestTest: 0.9329834 (166)\ttotal: 38.5s\tremaining: 1m 16s\n",
      "167: learn: 0.9635113\ttest: 0.9329747\tbestTest: 0.9329834 (166)\ttotal: 38.7s\tremaining: 1m 16s\n",
      "168: learn: 0.9636384\ttest: 0.9331217\tbestTest: 0.9331217 (168)\ttotal: 39s\tremaining: 1m 16s\n",
      "169: learn: 0.9638935\ttest: 0.933005\tbestTest: 0.9331217 (168)\ttotal: 39.4s\tremaining: 1m 16s\n",
      "170: learn: 0.9639781\ttest: 0.9330525\tbestTest: 0.9331217 (168)\ttotal: 39.6s\tremaining: 1m 16s\n",
      "171: learn: 0.9641754\ttest: 0.9330007\tbestTest: 0.9331217 (168)\ttotal: 39.8s\tremaining: 1m 15s\n",
      "172: learn: 0.9643918\ttest: 0.9329661\tbestTest: 0.9331217 (168)\ttotal: 40s\tremaining: 1m 15s\n",
      "173: learn: 0.9644882\ttest: 0.9329963\tbestTest: 0.9331217 (168)\ttotal: 40.1s\tremaining: 1m 15s\n",
      "174: learn: 0.9646579\ttest: 0.9330785\tbestTest: 0.9331217 (168)\ttotal: 40.5s\tremaining: 1m 15s\n",
      "175: learn: 0.965021\ttest: 0.9330612\tbestTest: 0.9331217 (168)\ttotal: 40.7s\tremaining: 1m 14s\n",
      "176: learn: 0.965203\ttest: 0.9330525\tbestTest: 0.9331217 (168)\ttotal: 40.9s\tremaining: 1m 14s\n",
      "177: learn: 0.9654606\ttest: 0.9331607\tbestTest: 0.9331607 (177)\ttotal: 41.1s\tremaining: 1m 14s\n",
      "178: learn: 0.9657214\ttest: 0.9329877\tbestTest: 0.9331607 (177)\ttotal: 41.3s\tremaining: 1m 14s\n",
      "179: learn: 0.9658817\ttest: 0.9329358\tbestTest: 0.9331607 (177)\ttotal: 41.7s\tremaining: 1m 14s\n",
      "180: learn: 0.9661219\ttest: 0.9330569\tbestTest: 0.9331607 (177)\ttotal: 41.9s\tremaining: 1m 13s\n",
      "181: learn: 0.9664688\ttest: 0.932992\tbestTest: 0.9331607 (177)\ttotal: 42.1s\tremaining: 1m 13s\n",
      "182: learn: 0.9666837\ttest: 0.9330266\tbestTest: 0.9331607 (177)\ttotal: 42.4s\tremaining: 1m 13s\n",
      "183: learn: 0.9668354\ttest: 0.9330698\tbestTest: 0.9331607 (177)\ttotal: 42.6s\tremaining: 1m 13s\n",
      "184: learn: 0.9669437\ttest: 0.9330742\tbestTest: 0.9331607 (177)\ttotal: 42.9s\tremaining: 1m 13s\n",
      "185: learn: 0.9670014\ttest: 0.9330958\tbestTest: 0.9331607 (177)\ttotal: 43.2s\tremaining: 1m 12s\n",
      "186: learn: 0.9672071\ttest: 0.9330828\tbestTest: 0.9331607 (177)\ttotal: 43.4s\tremaining: 1m 12s\n",
      "187: learn: 0.9674256\ttest: 0.9331477\tbestTest: 0.9331607 (177)\ttotal: 43.6s\tremaining: 1m 12s\n",
      "188: learn: 0.9675559\ttest: 0.9331823\tbestTest: 0.9331823 (188)\ttotal: 43.8s\tremaining: 1m 12s\n",
      "189: learn: 0.9677313\ttest: 0.9330612\tbestTest: 0.9331823 (188)\ttotal: 44.2s\tremaining: 1m 12s\n",
      "190: learn: 0.9679976\ttest: 0.9330353\tbestTest: 0.9331823 (188)\ttotal: 44.4s\tremaining: 1m 11s\n",
      "191: learn: 0.9682203\ttest: 0.9331347\tbestTest: 0.9331823 (188)\ttotal: 44.6s\tremaining: 1m 11s\n",
      "192: learn: 0.968468\ttest: 0.9331607\tbestTest: 0.9331823 (188)\ttotal: 44.9s\tremaining: 1m 11s\n",
      "193: learn: 0.9687612\ttest: 0.9332817\tbestTest: 0.9332817 (193)\ttotal: 45.2s\tremaining: 1m 11s\n",
      "194: learn: 0.968892\ttest: 0.9334374\tbestTest: 0.9334374 (194)\ttotal: 45.5s\tremaining: 1m 11s\n",
      "195: learn: 0.9690304\ttest: 0.9332082\tbestTest: 0.9334374 (194)\ttotal: 45.7s\tremaining: 1m 10s\n",
      "196: learn: 0.9692343\ttest: 0.9331217\tbestTest: 0.9334374 (194)\ttotal: 45.9s\tremaining: 1m 10s\n",
      "197: learn: 0.9692899\ttest: 0.9330223\tbestTest: 0.9334374 (194)\ttotal: 46s\tremaining: 1m 10s\n",
      "198: learn: 0.9693588\ttest: 0.9330482\tbestTest: 0.9334374 (194)\ttotal: 46.4s\tremaining: 1m 10s\n",
      "199: learn: 0.9695118\ttest: 0.9332385\tbestTest: 0.9334374 (194)\ttotal: 46.6s\tremaining: 1m 9s\n",
      "200: learn: 0.9696872\ttest: 0.9331477\tbestTest: 0.9334374 (194)\ttotal: 46.8s\tremaining: 1m 9s\n",
      "201: learn: 0.9699822\ttest: 0.9332428\tbestTest: 0.9334374 (194)\ttotal: 47s\tremaining: 1m 9s\n",
      "202: learn: 0.9702088\ttest: 0.9331131\tbestTest: 0.9334374 (194)\ttotal: 47.2s\tremaining: 1m 9s\n",
      "203: learn: 0.9703894\ttest: 0.9330742\tbestTest: 0.9334374 (194)\ttotal: 47.5s\tremaining: 1m 8s\n",
      "204: learn: 0.9705615\ttest: 0.9329963\tbestTest: 0.9334374 (194)\ttotal: 47.7s\tremaining: 1m 8s\n",
      "205: learn: 0.9707628\ttest: 0.9330569\tbestTest: 0.9334374 (194)\ttotal: 48s\tremaining: 1m 8s\n",
      "206: learn: 0.970921\ttest: 0.932979\tbestTest: 0.9334374 (194)\ttotal: 48.2s\tremaining: 1m 8s\n",
      "207: learn: 0.9709758\ttest: 0.9329747\tbestTest: 0.9334374 (194)\ttotal: 48.4s\tremaining: 1m 7s\n",
      "208: learn: 0.9711841\ttest: 0.9331563\tbestTest: 0.9334374 (194)\ttotal: 48.6s\tremaining: 1m 7s\n",
      "209: learn: 0.9715337\ttest: 0.9333769\tbestTest: 0.9334374 (194)\ttotal: 48.9s\tremaining: 1m 7s\n",
      "210: learn: 0.9719182\ttest: 0.933472\tbestTest: 0.933472 (210)\ttotal: 49.2s\tremaining: 1m 7s\n",
      "211: learn: 0.972091\ttest: 0.9334547\tbestTest: 0.933472 (210)\ttotal: 49.4s\tremaining: 1m 7s\n",
      "212: learn: 0.9721649\ttest: 0.9333725\tbestTest: 0.933472 (210)\ttotal: 49.6s\tremaining: 1m 6s\n",
      "213: learn: 0.9722174\ttest: 0.9333034\tbestTest: 0.933472 (210)\ttotal: 50s\tremaining: 1m 6s\n",
      "214: learn: 0.9724576\ttest: 0.9334806\tbestTest: 0.9334806 (214)\ttotal: 50.2s\tremaining: 1m 6s\n",
      "215: learn: 0.9727035\ttest: 0.9333682\tbestTest: 0.9334806 (214)\ttotal: 50.4s\tremaining: 1m 6s\n",
      "216: learn: 0.9728353\ttest: 0.9334288\tbestTest: 0.9334806 (214)\ttotal: 50.6s\tremaining: 1m 5s\n",
      "217: learn: 0.9730797\ttest: 0.933459\tbestTest: 0.9334806 (214)\ttotal: 50.8s\tremaining: 1m 5s\n",
      "218: learn: 0.9732676\ttest: 0.9334331\tbestTest: 0.9334806 (214)\ttotal: 51.1s\tremaining: 1m 5s\n",
      "219: learn: 0.9733674\ttest: 0.9334244\tbestTest: 0.9334806 (214)\ttotal: 51.3s\tremaining: 1m 5s\n",
      "220: learn: 0.9735313\ttest: 0.9335715\tbestTest: 0.9335715 (220)\ttotal: 51.6s\tremaining: 1m 5s\n",
      "221: learn: 0.9737133\ttest: 0.9336709\tbestTest: 0.9336709 (221)\ttotal: 51.8s\tremaining: 1m 4s\n",
      "222: learn: 0.9738425\ttest: 0.9336666\tbestTest: 0.9336709 (221)\ttotal: 52s\tremaining: 1m 4s\n",
      "223: learn: 0.974019\ttest: 0.9338006\tbestTest: 0.9338006 (223)\ttotal: 52.3s\tremaining: 1m 4s\n",
      "224: learn: 0.9741774\ttest: 0.9338136\tbestTest: 0.9338136 (224)\ttotal: 52.5s\tremaining: 1m 4s\n",
      "225: learn: 0.9744852\ttest: 0.9335412\tbestTest: 0.9338136 (224)\ttotal: 52.8s\tremaining: 1m 3s\n",
      "226: learn: 0.9746667\ttest: 0.9334677\tbestTest: 0.9338136 (224)\ttotal: 53s\tremaining: 1m 3s\n",
      "227: learn: 0.9748189\ttest: 0.9334158\tbestTest: 0.9338136 (224)\ttotal: 53.2s\tremaining: 1m 3s\n",
      "228: learn: 0.9750029\ttest: 0.933472\tbestTest: 0.9338136 (224)\ttotal: 53.6s\tremaining: 1m 3s\n",
      "229: learn: 0.9750833\ttest: 0.9333293\tbestTest: 0.9338136 (224)\ttotal: 53.8s\tremaining: 1m 3s\n",
      "230: learn: 0.9752956\ttest: 0.9334201\tbestTest: 0.9338136 (224)\ttotal: 54s\tremaining: 1m 2s\n",
      "231: learn: 0.9755193\ttest: 0.9329877\tbestTest: 0.9338136 (224)\ttotal: 54.2s\tremaining: 1m 2s\n",
      "232: learn: 0.9756574\ttest: 0.9330958\tbestTest: 0.9338136 (224)\ttotal: 54.4s\tremaining: 1m 2s\n",
      "233: learn: 0.9758542\ttest: 0.9333336\tbestTest: 0.9338136 (224)\ttotal: 54.8s\tremaining: 1m 2s\n",
      "234: learn: 0.9760375\ttest: 0.9333466\tbestTest: 0.9338136 (224)\ttotal: 55s\tremaining: 1m 2s\n",
      "235: learn: 0.9762458\ttest: 0.9332644\tbestTest: 0.9338136 (224)\ttotal: 55.2s\tremaining: 1m 1s\n",
      "236: learn: 0.9763881\ttest: 0.9334633\tbestTest: 0.9338136 (224)\ttotal: 55.4s\tremaining: 1m 1s\n",
      "237: learn: 0.9765969\ttest: 0.9333769\tbestTest: 0.9338136 (224)\ttotal: 55.6s\tremaining: 1m 1s\n",
      "238: learn: 0.9767956\ttest: 0.9334071\tbestTest: 0.9338136 (224)\ttotal: 56s\tremaining: 1m 1s\n",
      "239: learn: 0.9768465\ttest: 0.9335066\tbestTest: 0.9338136 (224)\ttotal: 56.2s\tremaining: 1m\n",
      "240: learn: 0.9769619\ttest: 0.9332688\tbestTest: 0.9338136 (224)\ttotal: 56.4s\tremaining: 1m\n",
      "241: learn: 0.9771123\ttest: 0.9333509\tbestTest: 0.9338136 (224)\ttotal: 56.6s\tremaining: 1m\n",
      "242: learn: 0.9772512\ttest: 0.9335023\tbestTest: 0.9338136 (224)\ttotal: 56.8s\tremaining: 1m\n",
      "243: learn: 0.9773329\ttest: 0.9333336\tbestTest: 0.9338136 (224)\ttotal: 57.1s\tremaining: 60s\n",
      "244: learn: 0.97749\ttest: 0.9334417\tbestTest: 0.9338136 (224)\ttotal: 57.4s\tremaining: 59.7s\n",
      "245: learn: 0.9777085\ttest: 0.9331434\tbestTest: 0.9338136 (224)\ttotal: 57.6s\tremaining: 59.4s\n",
      "246: learn: 0.9778915\ttest: 0.9332428\tbestTest: 0.9338136 (224)\ttotal: 57.8s\tremaining: 59.2s\n",
      "247: learn: 0.9780072\ttest: 0.9331866\tbestTest: 0.9338136 (224)\ttotal: 58s\tremaining: 58.9s\n",
      "248: learn: 0.9780654\ttest: 0.9332688\tbestTest: 0.9338136 (224)\ttotal: 58.3s\tremaining: 58.8s\n",
      "249: learn: 0.9782643\ttest: 0.9332644\tbestTest: 0.9338136 (224)\ttotal: 58.5s\tremaining: 58.5s\n",
      "250: learn: 0.9784693\ttest: 0.9333596\tbestTest: 0.9338136 (224)\ttotal: 58.8s\tremaining: 58.3s\n",
      "251: learn: 0.9786301\ttest: 0.9333769\tbestTest: 0.9338136 (224)\ttotal: 59s\tremaining: 58s\n",
      "252: learn: 0.9788175\ttest: 0.9333985\tbestTest: 0.9338136 (224)\ttotal: 59.2s\tremaining: 57.8s\n",
      "253: learn: 0.9788906\ttest: 0.9333985\tbestTest: 0.9338136 (224)\ttotal: 59.6s\tremaining: 57.7s\n",
      "254: learn: 0.9789063\ttest: 0.9336536\tbestTest: 0.9338136 (224)\ttotal: 59.8s\tremaining: 57.4s\n",
      "255: learn: 0.9789992\ttest: 0.9336493\tbestTest: 0.9338136 (224)\ttotal: 60s\tremaining: 57.2s\n",
      "256: learn: 0.9791804\ttest: 0.9336406\tbestTest: 0.9338136 (224)\ttotal: 1m\tremaining: 57.1s\n",
      "257: learn: 0.9793517\ttest: 0.9337271\tbestTest: 0.9338136 (224)\ttotal: 1m\tremaining: 57s\n",
      "258: learn: 0.9794169\ttest: 0.9338914\tbestTest: 0.9338914 (258)\ttotal: 1m\tremaining: 56.7s\n",
      "259: learn: 0.9796179\ttest: 0.9338871\tbestTest: 0.9338914 (258)\ttotal: 1m 1s\tremaining: 56.5s\n",
      "260: learn: 0.979714\ttest: 0.9338914\tbestTest: 0.9338914 (260)\ttotal: 1m 1s\tremaining: 56.2s\n",
      "261: learn: 0.9798592\ttest: 0.9338569\tbestTest: 0.9338914 (260)\ttotal: 1m 1s\tremaining: 55.9s\n",
      "262: learn: 0.9800356\ttest: 0.9336709\tbestTest: 0.9338914 (260)\ttotal: 1m 1s\tremaining: 55.8s\n",
      "263: learn: 0.9801578\ttest: 0.9336623\tbestTest: 0.9338914 (260)\ttotal: 1m 2s\tremaining: 55.5s\n",
      "264: learn: 0.9803142\ttest: 0.933632\tbestTest: 0.9338914 (260)\ttotal: 1m 2s\tremaining: 55.3s\n",
      "265: learn: 0.9805606\ttest: 0.9335196\tbestTest: 0.9338914 (260)\ttotal: 1m 2s\tremaining: 55s\n",
      "266: learn: 0.980693\ttest: 0.933472\tbestTest: 0.9338914 (260)\ttotal: 1m 2s\tremaining: 54.8s\n",
      "267: learn: 0.9807298\ttest: 0.9334071\tbestTest: 0.9338914 (260)\ttotal: 1m 3s\tremaining: 54.7s\n",
      "268: learn: 0.9808789\ttest: 0.9334677\tbestTest: 0.9338914 (260)\ttotal: 1m 3s\tremaining: 54.4s\n",
      "269: learn: 0.9810193\ttest: 0.9335542\tbestTest: 0.9338914 (260)\ttotal: 1m 3s\tremaining: 54.1s\n",
      "270: learn: 0.9812282\ttest: 0.9335758\tbestTest: 0.9338914 (260)\ttotal: 1m 3s\tremaining: 53.9s\n",
      "271: learn: 0.9813091\ttest: 0.9335931\tbestTest: 0.9338914 (260)\ttotal: 1m 3s\tremaining: 53.6s\n",
      "272: learn: 0.9813582\ttest: 0.933606\tbestTest: 0.9338914 (260)\ttotal: 1m 4s\tremaining: 53.6s\n",
      "273: learn: 0.9815333\ttest: 0.9336017\tbestTest: 0.9338914 (260)\ttotal: 1m 4s\tremaining: 53.3s\n",
      "274: learn: 0.9817174\ttest: 0.9335239\tbestTest: 0.9338914 (260)\ttotal: 1m 4s\tremaining: 53.1s\n",
      "275: learn: 0.9819393\ttest: 0.9334071\tbestTest: 0.9338914 (260)\ttotal: 1m 5s\tremaining: 52.9s\n",
      "276: learn: 0.9821126\ttest: 0.9332731\tbestTest: 0.9338914 (260)\ttotal: 1m 5s\tremaining: 52.7s\n",
      "277: learn: 0.9822975\ttest: 0.9332731\tbestTest: 0.9338914 (260)\ttotal: 1m 5s\tremaining: 52.5s\n",
      "278: learn: 0.9823669\ttest: 0.9332817\tbestTest: 0.9338914 (260)\ttotal: 1m 5s\tremaining: 52.2s\n",
      "279: learn: 0.9824805\ttest: 0.9331736\tbestTest: 0.9338914 (260)\ttotal: 1m 6s\tremaining: 51.9s\n",
      "280: learn: 0.9827037\ttest: 0.9333163\tbestTest: 0.9338914 (260)\ttotal: 1m 6s\tremaining: 51.7s\n",
      "281: learn: 0.9828585\ttest: 0.9331044\tbestTest: 0.9338914 (260)\ttotal: 1m 6s\tremaining: 51.5s\n",
      "282: learn: 0.9830478\ttest: 0.9330742\tbestTest: 0.9338914 (260)\ttotal: 1m 6s\tremaining: 51.3s\n",
      "283: learn: 0.9831227\ttest: 0.9332688\tbestTest: 0.9338914 (260)\ttotal: 1m 7s\tremaining: 51s\n",
      "284: learn: 0.9832509\ttest: 0.9333077\tbestTest: 0.9338914 (260)\ttotal: 1m 7s\tremaining: 50.8s\n",
      "285: learn: 0.9833352\ttest: 0.9332342\tbestTest: 0.9338914 (260)\ttotal: 1m 7s\tremaining: 50.5s\n",
      "286: learn: 0.9834386\ttest: 0.9333552\tbestTest: 0.9338914 (260)\ttotal: 1m 7s\tremaining: 50.3s\n",
      "287: learn: 0.9835383\ttest: 0.933312\tbestTest: 0.9338914 (260)\ttotal: 1m 8s\tremaining: 50.1s\n",
      "288: learn: 0.9837351\ttest: 0.9331909\tbestTest: 0.9338914 (260)\ttotal: 1m 8s\tremaining: 49.8s\n",
      "289: learn: 0.9838236\ttest: 0.933018\tbestTest: 0.9338914 (260)\ttotal: 1m 8s\tremaining: 49.5s\n",
      "290: learn: 0.9838724\ttest: 0.9330958\tbestTest: 0.9338914 (260)\ttotal: 1m 8s\tremaining: 49.3s\n",
      "291: learn: 0.9839925\ttest: 0.9330482\tbestTest: 0.9338914 (260)\ttotal: 1m 8s\tremaining: 49s\n",
      "292: learn: 0.9840795\ttest: 0.9331304\tbestTest: 0.9338914 (260)\ttotal: 1m 9s\tremaining: 48.8s\n",
      "293: learn: 0.9842144\ttest: 0.9331261\tbestTest: 0.9338914 (260)\ttotal: 1m 9s\tremaining: 48.5s\n",
      "294: learn: 0.9842374\ttest: 0.9331607\tbestTest: 0.9338914 (260)\ttotal: 1m 9s\tremaining: 48.3s\n",
      "295: learn: 0.9843097\ttest: 0.933152\tbestTest: 0.9338914 (260)\ttotal: 1m 9s\tremaining: 48s\n",
      "296: learn: 0.984352\ttest: 0.9329617\tbestTest: 0.9338914 (260)\ttotal: 1m 9s\tremaining: 47.8s\n",
      "297: learn: 0.9845363\ttest: 0.9328536\tbestTest: 0.9338914 (260)\ttotal: 1m 10s\tremaining: 47.5s\n",
      "298: learn: 0.9846287\ttest: 0.9327585\tbestTest: 0.9338914 (260)\ttotal: 1m 10s\tremaining: 47.3s\n",
      "299: learn: 0.9847499\ttest: 0.9329271\tbestTest: 0.9338914 (260)\ttotal: 1m 10s\tremaining: 47s\n",
      "300: learn: 0.9848634\ttest: 0.9327974\tbestTest: 0.9338914 (260)\ttotal: 1m 10s\tremaining: 46.8s\n",
      "301: learn: 0.9849637\ttest: 0.932845\tbestTest: 0.9338914 (260)\ttotal: 1m 10s\tremaining: 46.5s\n",
      "302: learn: 0.9850814\ttest: 0.9329444\tbestTest: 0.9338914 (260)\ttotal: 1m 11s\tremaining: 46.2s\n",
      "303: learn: 0.9851725\ttest: 0.9329271\tbestTest: 0.9338914 (260)\ttotal: 1m 11s\tremaining: 46s\n",
      "304: learn: 0.9852532\ttest: 0.932992\tbestTest: 0.9338914 (260)\ttotal: 1m 11s\tremaining: 45.7s\n",
      "305: learn: 0.9853743\ttest: 0.9328969\tbestTest: 0.9338914 (260)\ttotal: 1m 11s\tremaining: 45.5s\n",
      "306: learn: 0.9855391\ttest: 0.9327974\tbestTest: 0.9338914 (260)\ttotal: 1m 11s\tremaining: 45.2s\n",
      "307: learn: 0.985585\ttest: 0.932858\tbestTest: 0.9338914 (260)\ttotal: 1m 12s\tremaining: 45s\n",
      "308: learn: 0.9857367\ttest: 0.9329661\tbestTest: 0.9338914 (260)\ttotal: 1m 12s\tremaining: 44.7s\n",
      "309: learn: 0.9858038\ttest: 0.9329488\tbestTest: 0.9338914 (260)\ttotal: 1m 12s\tremaining: 44.5s\n",
      "310: learn: 0.9858531\ttest: 0.9329315\tbestTest: 0.9338914 (260)\ttotal: 1m 12s\tremaining: 44.3s\n",
      "311: learn: 0.9859354\ttest: 0.9329098\tbestTest: 0.9338914 (260)\ttotal: 1m 13s\tremaining: 44s\n",
      "312: learn: 0.9860199\ttest: 0.9328536\tbestTest: 0.9338914 (260)\ttotal: 1m 13s\tremaining: 43.8s\n",
      "313: learn: 0.9860646\ttest: 0.9329963\tbestTest: 0.9338914 (260)\ttotal: 1m 13s\tremaining: 43.5s\n",
      "314: learn: 0.9861351\ttest: 0.9328536\tbestTest: 0.9338914 (260)\ttotal: 1m 13s\tremaining: 43.3s\n",
      "315: learn: 0.9862405\ttest: 0.9330396\tbestTest: 0.9338914 (260)\ttotal: 1m 14s\tremaining: 43.1s\n",
      "316: learn: 0.9862771\ttest: 0.9330223\tbestTest: 0.9338914 (260)\ttotal: 1m 14s\tremaining: 42.9s\n",
      "317: learn: 0.9863403\ttest: 0.9329531\tbestTest: 0.9338914 (260)\ttotal: 1m 14s\tremaining: 42.6s\n",
      "318: learn: 0.9864228\ttest: 0.9330093\tbestTest: 0.9338914 (260)\ttotal: 1m 14s\tremaining: 42.4s\n",
      "319: learn: 0.9864974\ttest: 0.9330482\tbestTest: 0.9338914 (260)\ttotal: 1m 15s\tremaining: 42.2s\n",
      "320: learn: 0.9866371\ttest: 0.9330525\tbestTest: 0.9338914 (260)\ttotal: 1m 15s\tremaining: 42s\n",
      "321: learn: 0.9867076\ttest: 0.9330915\tbestTest: 0.9338914 (260)\ttotal: 1m 15s\tremaining: 41.7s\n",
      "322: learn: 0.986776\ttest: 0.9330742\tbestTest: 0.9338914 (260)\ttotal: 1m 15s\tremaining: 41.5s\n",
      "323: learn: 0.9868295\ttest: 0.9330569\tbestTest: 0.9338914 (260)\ttotal: 1m 15s\tremaining: 41.2s\n",
      "324: learn: 0.9869383\ttest: 0.9331607\tbestTest: 0.9338914 (260)\ttotal: 1m 16s\tremaining: 41.1s\n",
      "325: learn: 0.9869874\ttest: 0.9333509\tbestTest: 0.9338914 (260)\ttotal: 1m 16s\tremaining: 40.8s\n",
      "326: learn: 0.9870574\ttest: 0.9333509\tbestTest: 0.9338914 (260)\ttotal: 1m 16s\tremaining: 40.5s\n",
      "327: learn: 0.9871026\ttest: 0.9333336\tbestTest: 0.9338914 (260)\ttotal: 1m 16s\tremaining: 40.3s\n",
      "328: learn: 0.9872002\ttest: 0.9331693\tbestTest: 0.9338914 (260)\ttotal: 1m 17s\tremaining: 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329: learn: 0.9872895\ttest: 0.9331693\tbestTest: 0.9338914 (260)\ttotal: 1m 17s\tremaining: 39.9s\n",
      "330: learn: 0.9873607\ttest: 0.9332861\tbestTest: 0.9338914 (260)\ttotal: 1m 17s\tremaining: 39.6s\n",
      "331: learn: 0.9874195\ttest: 0.9334158\tbestTest: 0.9338914 (260)\ttotal: 1m 17s\tremaining: 39.4s\n",
      "332: learn: 0.9875931\ttest: 0.9334244\tbestTest: 0.9338914 (260)\ttotal: 1m 18s\tremaining: 39.1s\n",
      "333: learn: 0.9877941\ttest: 0.9334288\tbestTest: 0.9338914 (260)\ttotal: 1m 18s\tremaining: 38.9s\n",
      "334: learn: 0.9879847\ttest: 0.9334461\tbestTest: 0.9338914 (260)\ttotal: 1m 18s\tremaining: 38.7s\n",
      "335: learn: 0.9880518\ttest: 0.9335585\tbestTest: 0.9338914 (260)\ttotal: 1m 18s\tremaining: 38.5s\n",
      "336: learn: 0.9882032\ttest: 0.9336104\tbestTest: 0.9338914 (260)\ttotal: 1m 19s\tremaining: 38.2s\n",
      "337: learn: 0.9883089\ttest: 0.9335239\tbestTest: 0.9338914 (260)\ttotal: 1m 19s\tremaining: 38s\n",
      "338: learn: 0.9883687\ttest: 0.9334504\tbestTest: 0.9338914 (260)\ttotal: 1m 19s\tremaining: 37.7s\n",
      "339: learn: 0.9884499\ttest: 0.9334763\tbestTest: 0.9338914 (260)\ttotal: 1m 19s\tremaining: 37.6s\n",
      "340: learn: 0.9885864\ttest: 0.9332774\tbestTest: 0.9338914 (260)\ttotal: 1m 20s\tremaining: 37.3s\n",
      "341: learn: 0.9887517\ttest: 0.9330612\tbestTest: 0.9338914 (260)\ttotal: 1m 20s\tremaining: 37.1s\n",
      "342: learn: 0.9888342\ttest: 0.9330525\tbestTest: 0.9338914 (260)\ttotal: 1m 20s\tremaining: 36.8s\n",
      "343: learn: 0.9888846\ttest: 0.9330353\tbestTest: 0.9338914 (260)\ttotal: 1m 20s\tremaining: 36.6s\n",
      "344: learn: 0.9889981\ttest: 0.933165\tbestTest: 0.9338914 (260)\ttotal: 1m 21s\tremaining: 36.4s\n",
      "345: learn: 0.9890723\ttest: 0.9331044\tbestTest: 0.9338914 (260)\ttotal: 1m 21s\tremaining: 36.2s\n",
      "346: learn: 0.9891626\ttest: 0.9331347\tbestTest: 0.9338914 (260)\ttotal: 1m 21s\tremaining: 35.9s\n",
      "347: learn: 0.9892459\ttest: 0.9331866\tbestTest: 0.9338914 (260)\ttotal: 1m 21s\tremaining: 35.7s\n",
      "348: learn: 0.9893036\ttest: 0.9331779\tbestTest: 0.9338914 (260)\ttotal: 1m 21s\tremaining: 35.4s\n",
      "349: learn: 0.9894195\ttest: 0.9330871\tbestTest: 0.9338914 (260)\ttotal: 1m 22s\tremaining: 35.2s\n",
      "350: learn: 0.9895456\ttest: 0.9332039\tbestTest: 0.9338914 (260)\ttotal: 1m 22s\tremaining: 35s\n",
      "351: learn: 0.9896038\ttest: 0.933165\tbestTest: 0.9338914 (260)\ttotal: 1m 22s\tremaining: 34.8s\n",
      "352: learn: 0.9897017\ttest: 0.9331347\tbestTest: 0.9338914 (260)\ttotal: 1m 22s\tremaining: 34.5s\n",
      "353: learn: 0.9897145\ttest: 0.9331174\tbestTest: 0.9338914 (260)\ttotal: 1m 23s\tremaining: 34.3s\n",
      "354: learn: 0.9897782\ttest: 0.9331952\tbestTest: 0.9338914 (260)\ttotal: 1m 23s\tremaining: 34.1s\n",
      "355: learn: 0.9899032\ttest: 0.9331563\tbestTest: 0.9338914 (260)\ttotal: 1m 23s\tremaining: 33.8s\n",
      "356: learn: 0.9900648\ttest: 0.9331347\tbestTest: 0.9338914 (260)\ttotal: 1m 23s\tremaining: 33.6s\n",
      "357: learn: 0.9901457\ttest: 0.9331261\tbestTest: 0.9338914 (260)\ttotal: 1m 24s\tremaining: 33.3s\n",
      "358: learn: 0.9902053\ttest: 0.9332082\tbestTest: 0.9338914 (260)\ttotal: 1m 24s\tremaining: 33.1s\n",
      "359: learn: 0.9902567\ttest: 0.9331996\tbestTest: 0.9338914 (260)\ttotal: 1m 24s\tremaining: 32.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.933891445\n",
      "bestIteration = 260\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.990256690595 0.933199571038\n",
      "[0.9359533325259376, 0.93319957103815687]\n",
      "0: learn: 0.8151819\ttest: 0.8353608\tbestTest: 0.8353608 (0)\ttotal: 251ms\tremaining: 2m 5s\n",
      "1: learn: 0.8756147\ttest: 0.8846675\tbestTest: 0.8846675 (1)\ttotal: 439ms\tremaining: 1m 49s\n",
      "2: learn: 0.8767664\ttest: 0.8842338\tbestTest: 0.8846675 (1)\ttotal: 627ms\tremaining: 1m 43s\n",
      "3: learn: 0.8786388\ttest: 0.8867902\tbestTest: 0.8867902 (3)\ttotal: 838ms\tremaining: 1m 43s\n",
      "4: learn: 0.879621\ttest: 0.8862752\tbestTest: 0.8867902 (3)\ttotal: 1.04s\tremaining: 1m 42s\n",
      "5: learn: 0.8825958\ttest: 0.8905561\tbestTest: 0.8905561 (5)\ttotal: 1.39s\tremaining: 1m 54s\n",
      "6: learn: 0.8905395\ttest: 0.8961257\tbestTest: 0.8961257 (6)\ttotal: 1.61s\tremaining: 1m 53s\n",
      "7: learn: 0.8976356\ttest: 0.8979732\tbestTest: 0.8979732 (7)\ttotal: 1.81s\tremaining: 1m 51s\n",
      "8: learn: 0.900523\ttest: 0.9008925\tbestTest: 0.9008925 (8)\ttotal: 2.02s\tremaining: 1m 50s\n",
      "9: learn: 0.9071111\ttest: 0.9032613\tbestTest: 0.9032613 (9)\ttotal: 2.22s\tremaining: 1m 48s\n",
      "10: learn: 0.9098276\ttest: 0.9073712\tbestTest: 0.9073712 (10)\ttotal: 2.59s\tremaining: 1m 55s\n",
      "11: learn: 0.9118569\ttest: 0.909986\tbestTest: 0.909986 (11)\ttotal: 2.77s\tremaining: 1m 52s\n",
      "12: learn: 0.9126148\ttest: 0.9106178\tbestTest: 0.9106178 (12)\ttotal: 2.97s\tremaining: 1m 51s\n",
      "13: learn: 0.9122303\ttest: 0.9097108\tbestTest: 0.9106178 (12)\ttotal: 3.18s\tremaining: 1m 50s\n",
      "14: learn: 0.912851\ttest: 0.9102425\tbestTest: 0.9106178 (12)\ttotal: 3.39s\tremaining: 1m 49s\n",
      "15: learn: 0.9134879\ttest: 0.9125925\tbestTest: 0.9125925 (15)\ttotal: 3.75s\tremaining: 1m 53s\n",
      "16: learn: 0.9130059\ttest: 0.9122714\tbestTest: 0.9125925 (15)\ttotal: 3.97s\tremaining: 1m 52s\n",
      "17: learn: 0.9135823\ttest: 0.9134245\tbestTest: 0.9134245 (17)\ttotal: 4.18s\tremaining: 1m 51s\n",
      "18: learn: 0.9140756\ttest: 0.9141377\tbestTest: 0.9141377 (18)\ttotal: 4.39s\tremaining: 1m 51s\n",
      "19: learn: 0.916115\ttest: 0.9159184\tbestTest: 0.9159184 (19)\ttotal: 4.6s\tremaining: 1m 50s\n",
      "20: learn: 0.9168748\ttest: 0.9170736\tbestTest: 0.9170736 (20)\ttotal: 4.89s\tremaining: 1m 51s\n",
      "21: learn: 0.9180571\ttest: 0.9178556\tbestTest: 0.9178556 (21)\ttotal: 5.29s\tremaining: 1m 54s\n",
      "22: learn: 0.9193182\ttest: 0.9211836\tbestTest: 0.9211836 (22)\ttotal: 5.51s\tremaining: 1m 54s\n",
      "23: learn: 0.9195865\ttest: 0.9203537\tbestTest: 0.9211836 (22)\ttotal: 5.7s\tremaining: 1m 53s\n",
      "24: learn: 0.9211606\ttest: 0.9239319\tbestTest: 0.9239319 (24)\ttotal: 6.05s\tremaining: 1m 55s\n",
      "25: learn: 0.9232664\ttest: 0.9261463\tbestTest: 0.9261463 (25)\ttotal: 6.25s\tremaining: 1m 53s\n",
      "26: learn: 0.9235713\ttest: 0.9256793\tbestTest: 0.9261463 (25)\ttotal: 6.43s\tremaining: 1m 52s\n",
      "27: learn: 0.9245234\ttest: 0.9262464\tbestTest: 0.9262464 (27)\ttotal: 6.62s\tremaining: 1m 51s\n",
      "28: learn: 0.9250333\ttest: 0.9271723\tbestTest: 0.9271723 (28)\ttotal: 6.83s\tremaining: 1m 50s\n",
      "29: learn: 0.9253107\ttest: 0.926359\tbestTest: 0.9271723 (28)\ttotal: 7.21s\tremaining: 1m 52s\n",
      "30: learn: 0.9260956\ttest: 0.9277519\tbestTest: 0.9277519 (30)\ttotal: 7.41s\tremaining: 1m 52s\n",
      "31: learn: 0.9267001\ttest: 0.9292616\tbestTest: 0.9292616 (31)\ttotal: 7.6s\tremaining: 1m 51s\n",
      "32: learn: 0.9265678\ttest: 0.9289614\tbestTest: 0.9292616 (31)\ttotal: 7.81s\tremaining: 1m 50s\n",
      "33: learn: 0.9267754\ttest: 0.9291699\tbestTest: 0.9292616 (31)\ttotal: 8.2s\tremaining: 1m 52s\n",
      "34: learn: 0.9267922\ttest: 0.9286152\tbestTest: 0.9292616 (31)\ttotal: 8.56s\tremaining: 1m 53s\n",
      "35: learn: 0.9280254\ttest: 0.9299122\tbestTest: 0.9299122 (35)\ttotal: 8.86s\tremaining: 1m 54s\n",
      "36: learn: 0.9283375\ttest: 0.929908\tbestTest: 0.9299122 (35)\ttotal: 9.24s\tremaining: 1m 55s\n",
      "37: learn: 0.9289317\ttest: 0.9301958\tbestTest: 0.9301958 (37)\ttotal: 9.63s\tremaining: 1m 57s\n",
      "38: learn: 0.9291053\ttest: 0.9305753\tbestTest: 0.9305753 (38)\ttotal: 10s\tremaining: 1m 58s\n",
      "39: learn: 0.9296121\ttest: 0.9310883\tbestTest: 0.9310883 (39)\ttotal: 10.4s\tremaining: 1m 59s\n",
      "40: learn: 0.9303783\ttest: 0.9309298\tbestTest: 0.9310883 (39)\ttotal: 10.7s\tremaining: 2m\n",
      "41: learn: 0.9306064\ttest: 0.930813\tbestTest: 0.9310883 (39)\ttotal: 11.1s\tremaining: 2m 1s\n",
      "42: learn: 0.9313668\ttest: 0.9313885\tbestTest: 0.9313885 (42)\ttotal: 11.4s\tremaining: 2m 1s\n",
      "43: learn: 0.9315216\ttest: 0.9315095\tbestTest: 0.9315095 (43)\ttotal: 11.7s\tremaining: 2m\n",
      "44: learn: 0.9320592\ttest: 0.9320058\tbestTest: 0.9320058 (44)\ttotal: 11.9s\tremaining: 2m\n",
      "45: learn: 0.9322783\ttest: 0.9321517\tbestTest: 0.9321517 (45)\ttotal: 12.1s\tremaining: 1m 59s\n",
      "46: learn: 0.9329639\ttest: 0.9327856\tbestTest: 0.9327856 (46)\ttotal: 12.3s\tremaining: 1m 58s\n",
      "47: learn: 0.9336946\ttest: 0.9331193\tbestTest: 0.9331193 (47)\ttotal: 12.4s\tremaining: 1m 57s\n",
      "48: learn: 0.9337862\ttest: 0.9328357\tbestTest: 0.9331193 (47)\ttotal: 12.6s\tremaining: 1m 56s\n",
      "49: learn: 0.9341041\ttest: 0.9328232\tbestTest: 0.9331193 (47)\ttotal: 12.8s\tremaining: 1m 55s\n",
      "50: learn: 0.9344147\ttest: 0.9328565\tbestTest: 0.9331193 (47)\ttotal: 13s\tremaining: 1m 54s\n",
      "51: learn: 0.9347257\ttest: 0.9331193\tbestTest: 0.9331193 (51)\ttotal: 13.2s\tremaining: 1m 53s\n",
      "52: learn: 0.9349301\ttest: 0.9330108\tbestTest: 0.9331193 (51)\ttotal: 13.4s\tremaining: 1m 53s\n",
      "53: learn: 0.9350805\ttest: 0.9331818\tbestTest: 0.9331818 (53)\ttotal: 13.6s\tremaining: 1m 52s\n",
      "54: learn: 0.9352907\ttest: 0.9332861\tbestTest: 0.9332861 (54)\ttotal: 13.9s\tremaining: 1m 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55: learn: 0.9356846\ttest: 0.9335405\tbestTest: 0.9335405 (55)\ttotal: 14.1s\tremaining: 1m 51s\n",
      "56: learn: 0.9362951\ttest: 0.9338074\tbestTest: 0.9338074 (56)\ttotal: 14.3s\tremaining: 1m 50s\n",
      "57: learn: 0.9366344\ttest: 0.9342119\tbestTest: 0.9342119 (57)\ttotal: 14.5s\tremaining: 1m 50s\n",
      "58: learn: 0.9371172\ttest: 0.9343495\tbestTest: 0.9343495 (58)\ttotal: 14.7s\tremaining: 1m 49s\n",
      "59: learn: 0.937104\ttest: 0.9343454\tbestTest: 0.9343495 (58)\ttotal: 14.9s\tremaining: 1m 49s\n",
      "60: learn: 0.9375755\ttest: 0.9343495\tbestTest: 0.9343495 (60)\ttotal: 15.1s\tremaining: 1m 48s\n",
      "61: learn: 0.938029\ttest: 0.9348333\tbestTest: 0.9348333 (61)\ttotal: 15.3s\tremaining: 1m 48s\n",
      "62: learn: 0.9380764\ttest: 0.9344955\tbestTest: 0.9348333 (61)\ttotal: 15.5s\tremaining: 1m 47s\n",
      "63: learn: 0.9384352\ttest: 0.9344037\tbestTest: 0.9348333 (61)\ttotal: 15.8s\tremaining: 1m 47s\n",
      "64: learn: 0.938732\ttest: 0.934679\tbestTest: 0.9348333 (61)\ttotal: 16s\tremaining: 1m 46s\n",
      "65: learn: 0.9390241\ttest: 0.9346957\tbestTest: 0.9348333 (61)\ttotal: 16.2s\tremaining: 1m 46s\n",
      "66: learn: 0.9393141\ttest: 0.9348416\tbestTest: 0.9348416 (66)\ttotal: 16.4s\tremaining: 1m 45s\n",
      "67: learn: 0.9396831\ttest: 0.9353004\tbestTest: 0.9353004 (67)\ttotal: 16.6s\tremaining: 1m 45s\n",
      "68: learn: 0.9397284\ttest: 0.9352086\tbestTest: 0.9353004 (67)\ttotal: 16.8s\tremaining: 1m 45s\n",
      "69: learn: 0.9398682\ttest: 0.9350543\tbestTest: 0.9353004 (67)\ttotal: 17s\tremaining: 1m 44s\n",
      "70: learn: 0.9401448\ttest: 0.9353713\tbestTest: 0.9353713 (70)\ttotal: 17.2s\tremaining: 1m 44s\n",
      "71: learn: 0.9403776\ttest: 0.9355506\tbestTest: 0.9355506 (71)\ttotal: 17.4s\tremaining: 1m 43s\n",
      "72: learn: 0.9408049\ttest: 0.9356465\tbestTest: 0.9356465 (72)\ttotal: 17.6s\tremaining: 1m 43s\n",
      "73: learn: 0.940961\ttest: 0.9355381\tbestTest: 0.9356465 (72)\ttotal: 17.8s\tremaining: 1m 42s\n",
      "74: learn: 0.9410806\ttest: 0.9355089\tbestTest: 0.9356465 (72)\ttotal: 18.1s\tremaining: 1m 42s\n",
      "75: learn: 0.9415423\ttest: 0.9356006\tbestTest: 0.9356465 (72)\ttotal: 18.3s\tremaining: 1m 41s\n",
      "76: learn: 0.9418194\ttest: 0.9357258\tbestTest: 0.9357258 (76)\ttotal: 18.5s\tremaining: 1m 41s\n",
      "77: learn: 0.9419332\ttest: 0.9358092\tbestTest: 0.9358092 (77)\ttotal: 18.7s\tremaining: 1m 41s\n",
      "78: learn: 0.9420744\ttest: 0.9358092\tbestTest: 0.9358092 (78)\ttotal: 18.9s\tremaining: 1m 40s\n",
      "79: learn: 0.9423225\ttest: 0.9360427\tbestTest: 0.9360427 (79)\ttotal: 19.1s\tremaining: 1m 40s\n",
      "80: learn: 0.9426027\ttest: 0.9360302\tbestTest: 0.9360427 (79)\ttotal: 19.3s\tremaining: 1m 39s\n",
      "81: learn: 0.942977\ttest: 0.9362304\tbestTest: 0.9362304 (81)\ttotal: 19.5s\tremaining: 1m 39s\n",
      "82: learn: 0.942987\ttest: 0.9362554\tbestTest: 0.9362554 (82)\ttotal: 19.7s\tremaining: 1m 39s\n",
      "83: learn: 0.9432069\ttest: 0.9363263\tbestTest: 0.9363263 (83)\ttotal: 19.9s\tremaining: 1m 38s\n",
      "84: learn: 0.943459\ttest: 0.9363763\tbestTest: 0.9363763 (84)\ttotal: 20.1s\tremaining: 1m 38s\n",
      "85: learn: 0.9436945\ttest: 0.936539\tbestTest: 0.936539 (85)\ttotal: 20.4s\tremaining: 1m 38s\n",
      "86: learn: 0.9439555\ttest: 0.9364973\tbestTest: 0.936539 (85)\ttotal: 20.6s\tremaining: 1m 37s\n",
      "87: learn: 0.9441559\ttest: 0.9366057\tbestTest: 0.9366057 (87)\ttotal: 20.8s\tremaining: 1m 37s\n",
      "88: learn: 0.9444744\ttest: 0.9366057\tbestTest: 0.9366057 (88)\ttotal: 21s\tremaining: 1m 36s\n",
      "89: learn: 0.9445431\ttest: 0.9366975\tbestTest: 0.9366975 (89)\ttotal: 21.2s\tremaining: 1m 36s\n",
      "90: learn: 0.9447306\ttest: 0.9367642\tbestTest: 0.9367642 (90)\ttotal: 21.5s\tremaining: 1m 36s\n",
      "91: learn: 0.9450267\ttest: 0.9369143\tbestTest: 0.9369143 (91)\ttotal: 21.7s\tremaining: 1m 36s\n",
      "92: learn: 0.9450838\ttest: 0.9369352\tbestTest: 0.9369352 (92)\ttotal: 21.9s\tremaining: 1m 35s\n",
      "93: learn: 0.9450902\ttest: 0.9369352\tbestTest: 0.9369352 (93)\ttotal: 22.1s\tremaining: 1m 35s\n",
      "94: learn: 0.9452782\ttest: 0.9371562\tbestTest: 0.9371562 (94)\ttotal: 22.3s\tremaining: 1m 34s\n",
      "95: learn: 0.9454033\ttest: 0.9369685\tbestTest: 0.9371562 (94)\ttotal: 22.4s\tremaining: 1m 34s\n",
      "96: learn: 0.9456256\ttest: 0.9371437\tbestTest: 0.9371562 (94)\ttotal: 22.6s\tremaining: 1m 34s\n",
      "97: learn: 0.945776\ttest: 0.9372062\tbestTest: 0.9372062 (97)\ttotal: 22.8s\tremaining: 1m 33s\n",
      "98: learn: 0.9460294\ttest: 0.9373772\tbestTest: 0.9373772 (98)\ttotal: 23s\tremaining: 1m 33s\n",
      "99: learn: 0.9460492\ttest: 0.9374023\tbestTest: 0.9374023 (99)\ttotal: 23.2s\tremaining: 1m 32s\n",
      "100: learn: 0.9461532\ttest: 0.9375774\tbestTest: 0.9375774 (100)\ttotal: 23.4s\tremaining: 1m 32s\n",
      "101: learn: 0.9463718\ttest: 0.9376191\tbestTest: 0.9376191 (101)\ttotal: 23.6s\tremaining: 1m 32s\n",
      "102: learn: 0.9467005\ttest: 0.9376733\tbestTest: 0.9376733 (102)\ttotal: 23.9s\tremaining: 1m 31s\n",
      "103: learn: 0.9469478\ttest: 0.93769\tbestTest: 0.93769 (103)\ttotal: 24.1s\tremaining: 1m 31s\n",
      "104: learn: 0.9472468\ttest: 0.9377776\tbestTest: 0.9377776 (104)\ttotal: 24.3s\tremaining: 1m 31s\n",
      "105: learn: 0.9474101\ttest: 0.9377109\tbestTest: 0.9377776 (104)\ttotal: 24.5s\tremaining: 1m 31s\n",
      "106: learn: 0.9476461\ttest: 0.9376525\tbestTest: 0.9377776 (104)\ttotal: 24.7s\tremaining: 1m 30s\n",
      "107: learn: 0.9479582\ttest: 0.9375941\tbestTest: 0.9377776 (104)\ttotal: 24.9s\tremaining: 1m 30s\n",
      "108: learn: 0.9481244\ttest: 0.9376275\tbestTest: 0.9377776 (104)\ttotal: 25.2s\tremaining: 1m 30s\n",
      "109: learn: 0.948249\ttest: 0.937665\tbestTest: 0.9377776 (104)\ttotal: 25.4s\tremaining: 1m 29s\n",
      "110: learn: 0.9485063\ttest: 0.9375149\tbestTest: 0.9377776 (104)\ttotal: 25.7s\tremaining: 1m 29s\n",
      "111: learn: 0.9486556\ttest: 0.9376108\tbestTest: 0.9377776 (104)\ttotal: 25.9s\tremaining: 1m 29s\n",
      "112: learn: 0.9487847\ttest: 0.9376608\tbestTest: 0.9377776 (104)\ttotal: 26.1s\tremaining: 1m 29s\n",
      "113: learn: 0.949208\ttest: 0.9378068\tbestTest: 0.9378068 (113)\ttotal: 26.3s\tremaining: 1m 29s\n",
      "114: learn: 0.9493131\ttest: 0.9378151\tbestTest: 0.9378151 (114)\ttotal: 26.6s\tremaining: 1m 28s\n",
      "115: learn: 0.94946\ttest: 0.9379736\tbestTest: 0.9379736 (115)\ttotal: 26.9s\tremaining: 1m 29s\n",
      "116: learn: 0.949735\ttest: 0.9382238\tbestTest: 0.9382238 (116)\ttotal: 27.1s\tremaining: 1m 28s\n",
      "117: learn: 0.9500571\ttest: 0.9381988\tbestTest: 0.9382238 (116)\ttotal: 27.3s\tremaining: 1m 28s\n",
      "118: learn: 0.9502365\ttest: 0.9380945\tbestTest: 0.9382238 (116)\ttotal: 27.5s\tremaining: 1m 28s\n",
      "119: learn: 0.9505934\ttest: 0.9379945\tbestTest: 0.9382238 (116)\ttotal: 27.7s\tremaining: 1m 27s\n",
      "120: learn: 0.9506042\ttest: 0.9380028\tbestTest: 0.9382238 (116)\ttotal: 28s\tremaining: 1m 27s\n",
      "121: learn: 0.9509482\ttest: 0.9380737\tbestTest: 0.9382238 (116)\ttotal: 28.2s\tremaining: 1m 27s\n",
      "122: learn: 0.9509811\ttest: 0.9379486\tbestTest: 0.9382238 (116)\ttotal: 28.4s\tremaining: 1m 27s\n",
      "123: learn: 0.9513614\ttest: 0.9380236\tbestTest: 0.9382238 (116)\ttotal: 28.6s\tremaining: 1m 26s\n",
      "124: learn: 0.9517117\ttest: 0.938032\tbestTest: 0.9382238 (116)\ttotal: 28.8s\tremaining: 1m 26s\n",
      "125: learn: 0.9521245\ttest: 0.9381112\tbestTest: 0.9382238 (116)\ttotal: 29.2s\tremaining: 1m 26s\n",
      "126: learn: 0.9523133\ttest: 0.9381654\tbestTest: 0.9382238 (116)\ttotal: 29.4s\tremaining: 1m 26s\n",
      "127: learn: 0.9525459\ttest: 0.9380278\tbestTest: 0.9382238 (116)\ttotal: 29.6s\tremaining: 1m 26s\n",
      "128: learn: 0.952622\ttest: 0.9379945\tbestTest: 0.9382238 (116)\ttotal: 29.8s\tremaining: 1m 25s\n",
      "129: learn: 0.9528143\ttest: 0.9379319\tbestTest: 0.9382238 (116)\ttotal: 30.1s\tremaining: 1m 25s\n",
      "130: learn: 0.9530608\ttest: 0.9378944\tbestTest: 0.9382238 (116)\ttotal: 30.4s\tremaining: 1m 25s\n",
      "131: learn: 0.9532394\ttest: 0.937861\tbestTest: 0.9382238 (116)\ttotal: 30.7s\tremaining: 1m 25s\n",
      "132: learn: 0.9535697\ttest: 0.9379152\tbestTest: 0.9382238 (116)\ttotal: 30.9s\tremaining: 1m 25s\n",
      "133: learn: 0.9537543\ttest: 0.9379986\tbestTest: 0.9382238 (116)\ttotal: 31.1s\tremaining: 1m 24s\n",
      "134: learn: 0.9541457\ttest: 0.9379277\tbestTest: 0.9382238 (116)\ttotal: 31.3s\tremaining: 1m 24s\n",
      "135: learn: 0.9544049\ttest: 0.9379402\tbestTest: 0.9382238 (116)\ttotal: 31.7s\tremaining: 1m 24s\n",
      "136: learn: 0.9545912\ttest: 0.938178\tbestTest: 0.9382238 (116)\ttotal: 31.8s\tremaining: 1m 24s\n",
      "137: learn: 0.9546902\ttest: 0.9381863\tbestTest: 0.9382238 (116)\ttotal: 32s\tremaining: 1m 23s\n",
      "138: learn: 0.9551183\ttest: 0.9383948\tbestTest: 0.9383948 (138)\ttotal: 32.2s\tremaining: 1m 23s\n",
      "139: learn: 0.9553753\ttest: 0.9382822\tbestTest: 0.9383948 (138)\ttotal: 32.3s\tremaining: 1m 23s\n",
      "140: learn: 0.9556948\ttest: 0.9381446\tbestTest: 0.9383948 (138)\ttotal: 32.5s\tremaining: 1m 22s\n",
      "141: learn: 0.9558528\ttest: 0.9381029\tbestTest: 0.9383948 (138)\ttotal: 32.8s\tremaining: 1m 22s\n",
      "142: learn: 0.956122\ttest: 0.9380612\tbestTest: 0.9383948 (138)\ttotal: 32.9s\tremaining: 1m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143: learn: 0.9563446\ttest: 0.937836\tbestTest: 0.9383948 (138)\ttotal: 33.2s\tremaining: 1m 21s\n",
      "144: learn: 0.9565305\ttest: 0.9377234\tbestTest: 0.9383948 (138)\ttotal: 33.4s\tremaining: 1m 21s\n",
      "145: learn: 0.9568318\ttest: 0.9379027\tbestTest: 0.9383948 (138)\ttotal: 33.6s\tremaining: 1m 21s\n",
      "146: learn: 0.9572098\ttest: 0.9377651\tbestTest: 0.9383948 (138)\ttotal: 33.9s\tremaining: 1m 21s\n",
      "147: learn: 0.9574166\ttest: 0.9379152\tbestTest: 0.9383948 (138)\ttotal: 34.1s\tremaining: 1m 21s\n",
      "148: learn: 0.9575059\ttest: 0.9378443\tbestTest: 0.9383948 (138)\ttotal: 34.3s\tremaining: 1m 20s\n",
      "149: learn: 0.9577345\ttest: 0.9379611\tbestTest: 0.9383948 (138)\ttotal: 34.4s\tremaining: 1m 20s\n",
      "150: learn: 0.9579049\ttest: 0.9378652\tbestTest: 0.9383948 (138)\ttotal: 34.6s\tremaining: 1m 19s\n",
      "151: learn: 0.9579734\ttest: 0.937861\tbestTest: 0.9383948 (138)\ttotal: 34.7s\tremaining: 1m 19s\n",
      "152: learn: 0.9582549\ttest: 0.9377984\tbestTest: 0.9383948 (138)\ttotal: 35.1s\tremaining: 1m 19s\n",
      "153: learn: 0.9584417\ttest: 0.93769\tbestTest: 0.9383948 (138)\ttotal: 35.3s\tremaining: 1m 19s\n",
      "154: learn: 0.9587122\ttest: 0.9377901\tbestTest: 0.9383948 (138)\ttotal: 35.5s\tremaining: 1m 19s\n",
      "155: learn: 0.9589519\ttest: 0.9377943\tbestTest: 0.9383948 (138)\ttotal: 35.8s\tremaining: 1m 18s\n",
      "156: learn: 0.9592092\ttest: 0.9375691\tbestTest: 0.9383948 (138)\ttotal: 36s\tremaining: 1m 18s\n",
      "157: learn: 0.9594154\ttest: 0.9374815\tbestTest: 0.9383948 (138)\ttotal: 36.3s\tremaining: 1m 18s\n",
      "158: learn: 0.9597323\ttest: 0.9374857\tbestTest: 0.9383948 (138)\ttotal: 36.5s\tremaining: 1m 18s\n",
      "159: learn: 0.9599035\ttest: 0.9374481\tbestTest: 0.9383948 (138)\ttotal: 36.6s\tremaining: 1m 17s\n",
      "160: learn: 0.9601023\ttest: 0.9374189\tbestTest: 0.9383948 (138)\ttotal: 36.8s\tremaining: 1m 17s\n",
      "161: learn: 0.9602169\ttest: 0.9374023\tbestTest: 0.9383948 (138)\ttotal: 37s\tremaining: 1m 17s\n",
      "162: learn: 0.960533\ttest: 0.937519\tbestTest: 0.9383948 (138)\ttotal: 37.1s\tremaining: 1m 16s\n",
      "163: learn: 0.9607426\ttest: 0.9375232\tbestTest: 0.9383948 (138)\ttotal: 37.3s\tremaining: 1m 16s\n",
      "164: learn: 0.9608975\ttest: 0.9374023\tbestTest: 0.9383948 (138)\ttotal: 37.5s\tremaining: 1m 16s\n",
      "165: learn: 0.9611893\ttest: 0.9374565\tbestTest: 0.9383948 (138)\ttotal: 37.7s\tremaining: 1m 15s\n",
      "166: learn: 0.9613811\ttest: 0.9374523\tbestTest: 0.9383948 (138)\ttotal: 37.8s\tremaining: 1m 15s\n",
      "167: learn: 0.9615726\ttest: 0.9374481\tbestTest: 0.9383948 (138)\ttotal: 38s\tremaining: 1m 15s\n",
      "168: learn: 0.9616105\ttest: 0.937444\tbestTest: 0.9383948 (138)\ttotal: 38.1s\tremaining: 1m 14s\n",
      "169: learn: 0.9618317\ttest: 0.9375566\tbestTest: 0.9383948 (138)\ttotal: 38.3s\tremaining: 1m 14s\n",
      "170: learn: 0.9620164\ttest: 0.9375899\tbestTest: 0.9383948 (138)\ttotal: 38.6s\tremaining: 1m 14s\n",
      "171: learn: 0.9623445\ttest: 0.9373772\tbestTest: 0.9383948 (138)\ttotal: 38.8s\tremaining: 1m 14s\n",
      "172: learn: 0.9626206\ttest: 0.9373355\tbestTest: 0.9383948 (138)\ttotal: 39s\tremaining: 1m 13s\n",
      "173: learn: 0.9627478\ttest: 0.9373647\tbestTest: 0.9383948 (138)\ttotal: 39.3s\tremaining: 1m 13s\n",
      "174: learn: 0.9630294\ttest: 0.9373022\tbestTest: 0.9383948 (138)\ttotal: 39.5s\tremaining: 1m 13s\n",
      "175: learn: 0.9632567\ttest: 0.9370728\tbestTest: 0.9383948 (138)\ttotal: 39.8s\tremaining: 1m 13s\n",
      "176: learn: 0.9633304\ttest: 0.9369435\tbestTest: 0.9383948 (138)\ttotal: 40s\tremaining: 1m 13s\n",
      "177: learn: 0.9635427\ttest: 0.9368976\tbestTest: 0.9383948 (138)\ttotal: 40.2s\tremaining: 1m 12s\n",
      "178: learn: 0.9637292\ttest: 0.9366432\tbestTest: 0.9383948 (138)\ttotal: 40.4s\tremaining: 1m 12s\n",
      "179: learn: 0.9640273\ttest: 0.9366099\tbestTest: 0.9383948 (138)\ttotal: 40.6s\tremaining: 1m 12s\n",
      "180: learn: 0.9640832\ttest: 0.9366057\tbestTest: 0.9383948 (138)\ttotal: 41s\tremaining: 1m 12s\n",
      "181: learn: 0.9642141\ttest: 0.9366849\tbestTest: 0.9383948 (138)\ttotal: 41.2s\tremaining: 1m 11s\n",
      "182: learn: 0.9642757\ttest: 0.9367517\tbestTest: 0.9383948 (138)\ttotal: 41.3s\tremaining: 1m 11s\n",
      "183: learn: 0.9645196\ttest: 0.9367058\tbestTest: 0.9383948 (138)\ttotal: 41.6s\tremaining: 1m 11s\n",
      "184: learn: 0.9649508\ttest: 0.9366641\tbestTest: 0.9383948 (138)\ttotal: 41.8s\tremaining: 1m 11s\n",
      "185: learn: 0.9650909\ttest: 0.9366808\tbestTest: 0.9383948 (138)\ttotal: 42.1s\tremaining: 1m 11s\n",
      "186: learn: 0.9653846\ttest: 0.9367475\tbestTest: 0.9383948 (138)\ttotal: 42.3s\tremaining: 1m 10s\n",
      "187: learn: 0.965545\ttest: 0.9366558\tbestTest: 0.9383948 (138)\ttotal: 42.6s\tremaining: 1m 10s\n",
      "188: learn: 0.9658194\ttest: 0.9366849\tbestTest: 0.9383948 (138)\ttotal: 42.8s\tremaining: 1m 10s\n",
      "189: learn: 0.9659203\ttest: 0.936589\tbestTest: 0.9383948 (138)\ttotal: 43s\tremaining: 1m 10s\n",
      "190: learn: 0.9661099\ttest: 0.9368101\tbestTest: 0.9383948 (138)\ttotal: 43.3s\tremaining: 1m 10s\n",
      "191: learn: 0.9664631\ttest: 0.9370144\tbestTest: 0.9383948 (138)\ttotal: 43.5s\tremaining: 1m 9s\n",
      "192: learn: 0.9665274\ttest: 0.9369477\tbestTest: 0.9383948 (138)\ttotal: 43.7s\tremaining: 1m 9s\n",
      "193: learn: 0.9666285\ttest: 0.9370811\tbestTest: 0.9383948 (138)\ttotal: 43.9s\tremaining: 1m 9s\n",
      "194: learn: 0.9668461\ttest: 0.9369977\tbestTest: 0.9383948 (138)\ttotal: 44.1s\tremaining: 1m 8s\n",
      "195: learn: 0.9668843\ttest: 0.9370269\tbestTest: 0.9383948 (138)\ttotal: 44.5s\tremaining: 1m 9s\n",
      "196: learn: 0.9672199\ttest: 0.9373022\tbestTest: 0.9383948 (138)\ttotal: 44.7s\tremaining: 1m 8s\n",
      "197: learn: 0.9673378\ttest: 0.9375149\tbestTest: 0.9383948 (138)\ttotal: 44.9s\tremaining: 1m 8s\n",
      "198: learn: 0.9674882\ttest: 0.9375732\tbestTest: 0.9383948 (138)\ttotal: 45.1s\tremaining: 1m 8s\n",
      "199: learn: 0.9676457\ttest: 0.9377067\tbestTest: 0.9383948 (138)\ttotal: 45.3s\tremaining: 1m 7s\n",
      "200: learn: 0.9677693\ttest: 0.9375482\tbestTest: 0.9383948 (138)\ttotal: 45.6s\tremaining: 1m 7s\n",
      "201: learn: 0.9678991\ttest: 0.9374857\tbestTest: 0.9383948 (138)\ttotal: 45.8s\tremaining: 1m 7s\n",
      "202: learn: 0.9681038\ttest: 0.9374231\tbestTest: 0.9383948 (138)\ttotal: 46s\tremaining: 1m 7s\n",
      "203: learn: 0.9682916\ttest: 0.9372938\tbestTest: 0.9383948 (138)\ttotal: 46.2s\tremaining: 1m 7s\n",
      "204: learn: 0.9684994\ttest: 0.9374606\tbestTest: 0.9383948 (138)\ttotal: 46.4s\tremaining: 1m 6s\n",
      "205: learn: 0.9687475\ttest: 0.9375691\tbestTest: 0.9383948 (138)\ttotal: 46.8s\tremaining: 1m 6s\n",
      "206: learn: 0.9688594\ttest: 0.9375232\tbestTest: 0.9383948 (138)\ttotal: 47s\tremaining: 1m 6s\n",
      "207: learn: 0.9690317\ttest: 0.9374732\tbestTest: 0.9383948 (138)\ttotal: 47.2s\tremaining: 1m 6s\n",
      "208: learn: 0.96918\ttest: 0.9373022\tbestTest: 0.9383948 (138)\ttotal: 47.4s\tremaining: 1m 5s\n",
      "209: learn: 0.9694273\ttest: 0.9371562\tbestTest: 0.9383948 (138)\ttotal: 47.6s\tremaining: 1m 5s\n",
      "210: learn: 0.9696643\ttest: 0.937248\tbestTest: 0.9383948 (138)\ttotal: 47.9s\tremaining: 1m 5s\n",
      "211: learn: 0.9696643\ttest: 0.9372897\tbestTest: 0.9383948 (138)\ttotal: 48.2s\tremaining: 1m 5s\n",
      "212: learn: 0.9699749\ttest: 0.9372521\tbestTest: 0.9383948 (138)\ttotal: 48.3s\tremaining: 1m 5s\n",
      "213: learn: 0.9700162\ttest: 0.9373063\tbestTest: 0.9383948 (138)\ttotal: 48.5s\tremaining: 1m 4s\n",
      "214: learn: 0.970086\ttest: 0.9373522\tbestTest: 0.9383948 (138)\ttotal: 48.7s\tremaining: 1m 4s\n",
      "215: learn: 0.9704039\ttest: 0.9372438\tbestTest: 0.9383948 (138)\ttotal: 49s\tremaining: 1m 4s\n",
      "216: learn: 0.9704672\ttest: 0.9372646\tbestTest: 0.9383948 (138)\ttotal: 49.2s\tremaining: 1m 4s\n",
      "217: learn: 0.9706407\ttest: 0.9373147\tbestTest: 0.9383948 (138)\ttotal: 49.4s\tremaining: 1m 3s\n",
      "218: learn: 0.9709276\ttest: 0.9373689\tbestTest: 0.9383948 (138)\ttotal: 49.6s\tremaining: 1m 3s\n",
      "219: learn: 0.9712212\ttest: 0.9372146\tbestTest: 0.9383948 (138)\ttotal: 49.8s\tremaining: 1m 3s\n",
      "220: learn: 0.9714024\ttest: 0.9370811\tbestTest: 0.9383948 (138)\ttotal: 50s\tremaining: 1m 3s\n",
      "221: learn: 0.9715734\ttest: 0.9371812\tbestTest: 0.9383948 (138)\ttotal: 50.3s\tremaining: 1m 2s\n",
      "222: learn: 0.9716845\ttest: 0.9371645\tbestTest: 0.9383948 (138)\ttotal: 50.5s\tremaining: 1m 2s\n",
      "223: learn: 0.9719108\ttest: 0.9372062\tbestTest: 0.9383948 (138)\ttotal: 50.7s\tremaining: 1m 2s\n",
      "224: learn: 0.9720222\ttest: 0.9371645\tbestTest: 0.9383948 (138)\ttotal: 50.9s\tremaining: 1m 2s\n",
      "225: learn: 0.9722882\ttest: 0.937102\tbestTest: 0.9383948 (138)\ttotal: 51.1s\tremaining: 1m 1s\n",
      "226: learn: 0.9725479\ttest: 0.9370645\tbestTest: 0.9383948 (138)\ttotal: 51.5s\tremaining: 1m 1s\n",
      "227: learn: 0.9728527\ttest: 0.9370019\tbestTest: 0.9383948 (138)\ttotal: 51.7s\tremaining: 1m 1s\n",
      "228: learn: 0.9730902\ttest: 0.9368101\tbestTest: 0.9383948 (138)\ttotal: 51.9s\tremaining: 1m 1s\n",
      "229: learn: 0.9731819\ttest: 0.9368976\tbestTest: 0.9383948 (138)\ttotal: 52.1s\tremaining: 1m 1s\n",
      "230: learn: 0.9732641\ttest: 0.936785\tbestTest: 0.9383948 (138)\ttotal: 52.3s\tremaining: 1m\n",
      "231: learn: 0.9733689\ttest: 0.9368559\tbestTest: 0.9383948 (138)\ttotal: 52.7s\tremaining: 1m\n",
      "232: learn: 0.9735014\ttest: 0.936735\tbestTest: 0.9383948 (138)\ttotal: 52.8s\tremaining: 1m\n",
      "233: learn: 0.9736365\ttest: 0.9366766\tbestTest: 0.9383948 (138)\ttotal: 53.1s\tremaining: 1m\n",
      "234: learn: 0.9738983\ttest: 0.9367016\tbestTest: 0.9383948 (138)\ttotal: 53.3s\tremaining: 1m\n",
      "235: learn: 0.9738959\ttest: 0.9367183\tbestTest: 0.9383948 (138)\ttotal: 53.5s\tremaining: 59.8s\n",
      "236: learn: 0.9739813\ttest: 0.9366683\tbestTest: 0.9383948 (138)\ttotal: 53.8s\tremaining: 59.7s\n",
      "237: learn: 0.9740445\ttest: 0.9367809\tbestTest: 0.9383948 (138)\ttotal: 54.1s\tremaining: 59.5s\n",
      "238: learn: 0.9741016\ttest: 0.9367058\tbestTest: 0.9383948 (138)\ttotal: 54.3s\tremaining: 59.3s\n",
      "239: learn: 0.9742265\ttest: 0.9368309\tbestTest: 0.9383948 (138)\ttotal: 54.5s\tremaining: 59s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.938394812\n",
      "bestIteration = 138\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.974226483714 0.936830911024\n",
      "[0.9359533325259376, 0.93319957103815687, 0.93683091102445948]\n",
      "0: learn: 0.8520854\ttest: 0.8355089\tbestTest: 0.8355089 (0)\ttotal: 179ms\tremaining: 1m 29s\n",
      "1: learn: 0.8786916\ttest: 0.8653811\tbestTest: 0.8653811 (1)\ttotal: 401ms\tremaining: 1m 39s\n",
      "2: learn: 0.8822763\ttest: 0.8699363\tbestTest: 0.8699363 (2)\ttotal: 778ms\tremaining: 2m 8s\n",
      "3: learn: 0.8820251\ttest: 0.8692641\tbestTest: 0.8699363 (2)\ttotal: 988ms\tremaining: 2m 2s\n",
      "4: learn: 0.8840293\ttest: 0.8714354\tbestTest: 0.8714354 (4)\ttotal: 1.19s\tremaining: 1m 57s\n",
      "5: learn: 0.8990196\ttest: 0.8862222\tbestTest: 0.8862222 (5)\ttotal: 1.36s\tremaining: 1m 52s\n",
      "6: learn: 0.8987963\ttest: 0.8865594\tbestTest: 0.8865594 (6)\ttotal: 1.56s\tremaining: 1m 50s\n",
      "7: learn: 0.9015057\ttest: 0.8888552\tbestTest: 0.8888552 (7)\ttotal: 1.95s\tremaining: 2m\n",
      "8: learn: 0.9024369\ttest: 0.8901718\tbestTest: 0.8901718 (8)\ttotal: 2.16s\tremaining: 1m 57s\n",
      "9: learn: 0.9058445\ttest: 0.8954272\tbestTest: 0.8954272 (9)\ttotal: 2.36s\tremaining: 1m 55s\n",
      "10: learn: 0.9070106\ttest: 0.8958309\tbestTest: 0.8958309 (10)\ttotal: 2.56s\tremaining: 1m 53s\n",
      "11: learn: 0.910752\ttest: 0.8993682\tbestTest: 0.8993682 (11)\ttotal: 2.76s\tremaining: 1m 52s\n",
      "12: learn: 0.9120069\ttest: 0.9017607\tbestTest: 0.9017607 (12)\ttotal: 3.13s\tremaining: 1m 57s\n",
      "13: learn: 0.9132192\ttest: 0.9034445\tbestTest: 0.9034445 (13)\ttotal: 3.33s\tremaining: 1m 55s\n",
      "14: learn: 0.9146334\ttest: 0.9045784\tbestTest: 0.9045784 (14)\ttotal: 3.52s\tremaining: 1m 53s\n",
      "15: learn: 0.915818\ttest: 0.9057274\tbestTest: 0.9057274 (15)\ttotal: 3.7s\tremaining: 1m 51s\n",
      "16: learn: 0.9167832\ttest: 0.9065973\tbestTest: 0.9065973 (16)\ttotal: 3.9s\tremaining: 1m 50s\n",
      "17: learn: 0.9187363\ttest: 0.9099348\tbestTest: 0.9099348 (17)\ttotal: 4.25s\tremaining: 1m 53s\n",
      "18: learn: 0.9195131\ttest: 0.9119536\tbestTest: 0.9119536 (18)\ttotal: 4.46s\tremaining: 1m 52s\n",
      "19: learn: 0.9203765\ttest: 0.9122628\tbestTest: 0.9122628 (19)\ttotal: 4.64s\tremaining: 1m 51s\n",
      "20: learn: 0.9210618\ttest: 0.9124862\tbestTest: 0.9124862 (20)\ttotal: 4.86s\tremaining: 1m 50s\n",
      "21: learn: 0.9215123\ttest: 0.9125034\tbestTest: 0.9125034 (21)\ttotal: 5.08s\tremaining: 1m 50s\n",
      "22: learn: 0.9218997\ttest: 0.9131778\tbestTest: 0.9131778 (22)\ttotal: 5.47s\tremaining: 1m 53s\n",
      "23: learn: 0.9226769\ttest: 0.9140454\tbestTest: 0.9140454 (23)\ttotal: 5.68s\tremaining: 1m 52s\n",
      "24: learn: 0.9230851\ttest: 0.9143461\tbestTest: 0.9143461 (24)\ttotal: 5.89s\tremaining: 1m 51s\n",
      "25: learn: 0.9231136\ttest: 0.9145093\tbestTest: 0.9145093 (25)\ttotal: 6.09s\tremaining: 1m 51s\n",
      "26: learn: 0.9234265\ttest: 0.9153168\tbestTest: 0.9153168 (26)\ttotal: 6.29s\tremaining: 1m 50s\n",
      "27: learn: 0.9241424\ttest: 0.9158194\tbestTest: 0.9158194 (27)\ttotal: 6.66s\tremaining: 1m 52s\n",
      "28: learn: 0.9248384\ttest: 0.9166527\tbestTest: 0.9166527 (28)\ttotal: 6.88s\tremaining: 1m 51s\n",
      "29: learn: 0.9255514\ttest: 0.9177695\tbestTest: 0.9177695 (29)\ttotal: 7.08s\tremaining: 1m 50s\n",
      "30: learn: 0.9254103\ttest: 0.9180272\tbestTest: 0.9180272 (30)\ttotal: 7.27s\tremaining: 1m 49s\n",
      "31: learn: 0.9270466\ttest: 0.9188863\tbestTest: 0.9188863 (31)\ttotal: 7.48s\tremaining: 1m 49s\n",
      "32: learn: 0.9283163\ttest: 0.9200718\tbestTest: 0.9200718 (32)\ttotal: 7.84s\tremaining: 1m 50s\n",
      "33: learn: 0.9288426\ttest: 0.9203682\tbestTest: 0.9203682 (33)\ttotal: 8.04s\tremaining: 1m 50s\n",
      "34: learn: 0.9298386\ttest: 0.921339\tbestTest: 0.921339 (34)\ttotal: 8.2s\tremaining: 1m 48s\n",
      "35: learn: 0.9295345\ttest: 0.9214292\tbestTest: 0.9214292 (35)\ttotal: 8.4s\tremaining: 1m 48s\n",
      "36: learn: 0.9295313\ttest: 0.9213819\tbestTest: 0.9214292 (35)\ttotal: 8.58s\tremaining: 1m 47s\n",
      "37: learn: 0.9301319\ttest: 0.9223183\tbestTest: 0.9223183 (37)\ttotal: 8.94s\tremaining: 1m 48s\n",
      "38: learn: 0.9306986\ttest: 0.9225717\tbestTest: 0.9225717 (38)\ttotal: 9.14s\tremaining: 1m 48s\n",
      "39: learn: 0.9315638\ttest: 0.9229841\tbestTest: 0.9229841 (39)\ttotal: 9.35s\tremaining: 1m 47s\n",
      "40: learn: 0.9329093\ttest: 0.924234\tbestTest: 0.924234 (40)\ttotal: 9.56s\tremaining: 1m 47s\n",
      "41: learn: 0.9334066\ttest: 0.9245089\tbestTest: 0.9245089 (41)\ttotal: 9.76s\tremaining: 1m 46s\n",
      "42: learn: 0.933779\ttest: 0.924655\tbestTest: 0.924655 (42)\ttotal: 10.1s\tremaining: 1m 47s\n",
      "43: learn: 0.9339212\ttest: 0.9244445\tbestTest: 0.924655 (42)\ttotal: 10.4s\tremaining: 1m 47s\n",
      "44: learn: 0.9342039\ttest: 0.9248311\tbestTest: 0.9248311 (44)\ttotal: 10.6s\tremaining: 1m 46s\n",
      "45: learn: 0.9351628\ttest: 0.9254024\tbestTest: 0.9254024 (45)\ttotal: 10.8s\tremaining: 1m 46s\n",
      "46: learn: 0.9359187\ttest: 0.9257632\tbestTest: 0.9257632 (46)\ttotal: 11s\tremaining: 1m 46s\n",
      "47: learn: 0.935846\ttest: 0.925789\tbestTest: 0.925789 (47)\ttotal: 11.4s\tremaining: 1m 47s\n",
      "48: learn: 0.9367267\ttest: 0.9263087\tbestTest: 0.9263087 (48)\ttotal: 11.6s\tremaining: 1m 47s\n",
      "49: learn: 0.9373978\ttest: 0.9269831\tbestTest: 0.9269831 (49)\ttotal: 11.8s\tremaining: 1m 46s\n",
      "50: learn: 0.9380813\ttest: 0.9273654\tbestTest: 0.9273654 (50)\ttotal: 12s\tremaining: 1m 46s\n",
      "51: learn: 0.938879\ttest: 0.9277476\tbestTest: 0.9277476 (51)\ttotal: 12.2s\tremaining: 1m 44s\n",
      "52: learn: 0.9390145\ttest: 0.9274813\tbestTest: 0.9277476 (51)\ttotal: 12.5s\tremaining: 1m 45s\n",
      "53: learn: 0.9395256\ttest: 0.9274384\tbestTest: 0.9277476 (51)\ttotal: 12.7s\tremaining: 1m 44s\n",
      "54: learn: 0.9398099\ttest: 0.927331\tbestTest: 0.9277476 (51)\ttotal: 12.9s\tremaining: 1m 44s\n",
      "55: learn: 0.9398106\ttest: 0.9273525\tbestTest: 0.9277476 (51)\ttotal: 13.1s\tremaining: 1m 43s\n",
      "56: learn: 0.9398917\ttest: 0.9275286\tbestTest: 0.9277476 (51)\ttotal: 13.3s\tremaining: 1m 43s\n",
      "57: learn: 0.940343\ttest: 0.9272494\tbestTest: 0.9277476 (51)\ttotal: 13.6s\tremaining: 1m 43s\n",
      "58: learn: 0.9407637\ttest: 0.9274427\tbestTest: 0.9277476 (51)\ttotal: 13.8s\tremaining: 1m 43s\n",
      "59: learn: 0.9408513\ttest: 0.9275672\tbestTest: 0.9277476 (51)\ttotal: 14s\tremaining: 1m 42s\n",
      "60: learn: 0.9412053\ttest: 0.9278293\tbestTest: 0.9278293 (60)\ttotal: 14.3s\tremaining: 1m 42s\n",
      "61: learn: 0.9414898\ttest: 0.9279109\tbestTest: 0.9279109 (61)\ttotal: 14.4s\tremaining: 1m 42s\n",
      "62: learn: 0.9420648\ttest: 0.9283533\tbestTest: 0.9283533 (62)\ttotal: 14.6s\tremaining: 1m 41s\n",
      "63: learn: 0.9422677\ttest: 0.9282588\tbestTest: 0.9283533 (62)\ttotal: 14.8s\tremaining: 1m 41s\n",
      "64: learn: 0.9425347\ttest: 0.9284564\tbestTest: 0.9284564 (64)\ttotal: 15.1s\tremaining: 1m 40s\n",
      "65: learn: 0.9431902\ttest: 0.9288301\tbestTest: 0.9288301 (65)\ttotal: 15.3s\tremaining: 1m 40s\n",
      "66: learn: 0.943278\ttest: 0.9286067\tbestTest: 0.9288301 (65)\ttotal: 15.5s\tremaining: 1m 39s\n",
      "67: learn: 0.9434307\ttest: 0.928654\tbestTest: 0.9288301 (65)\ttotal: 15.7s\tremaining: 1m 39s\n",
      "68: learn: 0.9436739\ttest: 0.9284736\tbestTest: 0.9288301 (65)\ttotal: 15.9s\tremaining: 1m 39s\n",
      "69: learn: 0.9437016\ttest: 0.9285208\tbestTest: 0.9288301 (65)\ttotal: 16.1s\tremaining: 1m 38s\n",
      "70: learn: 0.9442005\ttest: 0.9288644\tbestTest: 0.9288644 (70)\ttotal: 16.3s\tremaining: 1m 38s\n",
      "71: learn: 0.9444531\ttest: 0.9290019\tbestTest: 0.9290019 (71)\ttotal: 16.5s\tremaining: 1m 37s\n",
      "72: learn: 0.9447792\ttest: 0.9291436\tbestTest: 0.9291436 (72)\ttotal: 16.6s\tremaining: 1m 37s\n",
      "73: learn: 0.9450626\ttest: 0.9295216\tbestTest: 0.9295216 (73)\ttotal: 16.8s\tremaining: 1m 36s\n",
      "74: learn: 0.9453238\ttest: 0.9296419\tbestTest: 0.9296419 (74)\ttotal: 17s\tremaining: 1m 36s\n",
      "75: learn: 0.945386\ttest: 0.9295732\tbestTest: 0.9296419 (74)\ttotal: 17.2s\tremaining: 1m 36s\n",
      "76: learn: 0.9456156\ttest: 0.9295904\tbestTest: 0.9296419 (74)\ttotal: 17.4s\tremaining: 1m 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77: learn: 0.9457728\ttest: 0.9295904\tbestTest: 0.9296419 (74)\ttotal: 17.6s\tremaining: 1m 35s\n",
      "78: learn: 0.9460687\ttest: 0.9296462\tbestTest: 0.9296462 (78)\ttotal: 17.8s\tremaining: 1m 35s\n",
      "79: learn: 0.9462259\ttest: 0.9298008\tbestTest: 0.9298008 (79)\ttotal: 18.1s\tremaining: 1m 34s\n",
      "80: learn: 0.9463409\ttest: 0.9297321\tbestTest: 0.9298008 (79)\ttotal: 18.3s\tremaining: 1m 34s\n",
      "81: learn: 0.9465977\ttest: 0.9296118\tbestTest: 0.9298008 (79)\ttotal: 18.5s\tremaining: 1m 34s\n",
      "82: learn: 0.9467433\ttest: 0.9294873\tbestTest: 0.9298008 (79)\ttotal: 18.7s\tremaining: 1m 33s\n",
      "83: learn: 0.9469376\ttest: 0.929629\tbestTest: 0.9298008 (79)\ttotal: 18.9s\tremaining: 1m 33s\n",
      "84: learn: 0.947117\ttest: 0.9297364\tbestTest: 0.9298008 (79)\ttotal: 19.1s\tremaining: 1m 33s\n",
      "85: learn: 0.9471382\ttest: 0.9297793\tbestTest: 0.9298008 (79)\ttotal: 19.3s\tremaining: 1m 32s\n",
      "86: learn: 0.947151\ttest: 0.9298781\tbestTest: 0.9298781 (86)\ttotal: 19.5s\tremaining: 1m 32s\n",
      "87: learn: 0.9472877\ttest: 0.9301487\tbestTest: 0.9301487 (87)\ttotal: 19.7s\tremaining: 1m 32s\n",
      "88: learn: 0.9474336\ttest: 0.9300457\tbestTest: 0.9301487 (87)\ttotal: 19.9s\tremaining: 1m 31s\n",
      "89: learn: 0.9476745\ttest: 0.9302218\tbestTest: 0.9302218 (89)\ttotal: 20.1s\tremaining: 1m 31s\n",
      "90: learn: 0.9479014\ttest: 0.9300972\tbestTest: 0.9302218 (89)\ttotal: 20.4s\tremaining: 1m 31s\n",
      "91: learn: 0.9480144\ttest: 0.9301187\tbestTest: 0.9302218 (89)\ttotal: 20.6s\tremaining: 1m 31s\n",
      "92: learn: 0.9482322\ttest: 0.9301702\tbestTest: 0.9302218 (89)\ttotal: 20.8s\tremaining: 1m 30s\n",
      "93: learn: 0.9484238\ttest: 0.9303163\tbestTest: 0.9303163 (93)\ttotal: 21s\tremaining: 1m 30s\n",
      "94: learn: 0.9485203\ttest: 0.9303635\tbestTest: 0.9303635 (94)\ttotal: 21.2s\tremaining: 1m 30s\n",
      "95: learn: 0.948753\ttest: 0.9302862\tbestTest: 0.9303635 (94)\ttotal: 21.4s\tremaining: 1m 30s\n",
      "96: learn: 0.9489188\ttest: 0.9302862\tbestTest: 0.9303635 (94)\ttotal: 21.6s\tremaining: 1m 29s\n",
      "97: learn: 0.9493178\ttest: 0.9301788\tbestTest: 0.9303635 (94)\ttotal: 21.9s\tremaining: 1m 29s\n",
      "98: learn: 0.9495163\ttest: 0.9302261\tbestTest: 0.9303635 (94)\ttotal: 22.1s\tremaining: 1m 29s\n",
      "99: learn: 0.9501237\ttest: 0.9304881\tbestTest: 0.9304881 (99)\ttotal: 22.4s\tremaining: 1m 29s\n",
      "100: learn: 0.9502063\ttest: 0.9303721\tbestTest: 0.9304881 (99)\ttotal: 22.6s\tremaining: 1m 29s\n",
      "101: learn: 0.9503904\ttest: 0.9305482\tbestTest: 0.9305482 (101)\ttotal: 22.8s\tremaining: 1m 29s\n",
      "102: learn: 0.9506678\ttest: 0.9306427\tbestTest: 0.9306427 (102)\ttotal: 23s\tremaining: 1m 28s\n",
      "103: learn: 0.9510984\ttest: 0.9307845\tbestTest: 0.9307845 (103)\ttotal: 23.3s\tremaining: 1m 28s\n",
      "104: learn: 0.951304\ttest: 0.930836\tbestTest: 0.930836 (104)\ttotal: 23.6s\tremaining: 1m 28s\n",
      "105: learn: 0.9514941\ttest: 0.9308016\tbestTest: 0.930836 (104)\ttotal: 23.9s\tremaining: 1m 28s\n",
      "106: learn: 0.9516538\ttest: 0.9307157\tbestTest: 0.930836 (104)\ttotal: 24.1s\tremaining: 1m 28s\n",
      "107: learn: 0.9518465\ttest: 0.9306814\tbestTest: 0.930836 (104)\ttotal: 24.3s\tremaining: 1m 28s\n",
      "108: learn: 0.9520045\ttest: 0.9306126\tbestTest: 0.930836 (104)\ttotal: 24.5s\tremaining: 1m 27s\n",
      "109: learn: 0.9521237\ttest: 0.9307458\tbestTest: 0.930836 (104)\ttotal: 24.8s\tremaining: 1m 28s\n",
      "110: learn: 0.9522304\ttest: 0.9306814\tbestTest: 0.930836 (104)\ttotal: 25s\tremaining: 1m 27s\n",
      "111: learn: 0.9526343\ttest: 0.9309391\tbestTest: 0.9309391 (111)\ttotal: 25.2s\tremaining: 1m 27s\n",
      "112: learn: 0.9527745\ttest: 0.9310121\tbestTest: 0.9310121 (112)\ttotal: 25.4s\tremaining: 1m 27s\n",
      "113: learn: 0.9529724\ttest: 0.9312484\tbestTest: 0.9312484 (113)\ttotal: 25.7s\tremaining: 1m 26s\n",
      "114: learn: 0.9534237\ttest: 0.931171\tbestTest: 0.9312484 (113)\ttotal: 26s\tremaining: 1m 26s\n",
      "115: learn: 0.9536073\ttest: 0.9312226\tbestTest: 0.9312484 (113)\ttotal: 26.2s\tremaining: 1m 26s\n",
      "116: learn: 0.9539705\ttest: 0.9313858\tbestTest: 0.9313858 (116)\ttotal: 26.4s\tremaining: 1m 26s\n",
      "117: learn: 0.9543321\ttest: 0.9313429\tbestTest: 0.9313858 (116)\ttotal: 26.6s\tremaining: 1m 26s\n",
      "118: learn: 0.9544882\ttest: 0.931257\tbestTest: 0.9313858 (116)\ttotal: 26.9s\tremaining: 1m 25s\n",
      "119: learn: 0.9547643\ttest: 0.931287\tbestTest: 0.9313858 (116)\ttotal: 27.1s\tremaining: 1m 25s\n",
      "120: learn: 0.9550281\ttest: 0.931171\tbestTest: 0.9313858 (116)\ttotal: 27.3s\tremaining: 1m 25s\n",
      "121: learn: 0.9553531\ttest: 0.9312612\tbestTest: 0.9313858 (116)\ttotal: 27.6s\tremaining: 1m 25s\n",
      "122: learn: 0.9556353\ttest: 0.9310422\tbestTest: 0.9313858 (116)\ttotal: 27.9s\tremaining: 1m 25s\n",
      "123: learn: 0.9558016\ttest: 0.9311796\tbestTest: 0.9313858 (116)\ttotal: 28.1s\tremaining: 1m 25s\n",
      "124: learn: 0.9559535\ttest: 0.9312612\tbestTest: 0.9313858 (116)\ttotal: 28.3s\tremaining: 1m 24s\n",
      "125: learn: 0.9561326\ttest: 0.9313214\tbestTest: 0.9313858 (116)\ttotal: 28.5s\tremaining: 1m 24s\n",
      "126: learn: 0.956341\ttest: 0.9313042\tbestTest: 0.9313858 (116)\ttotal: 28.7s\tremaining: 1m 24s\n",
      "127: learn: 0.9564736\ttest: 0.9313643\tbestTest: 0.9313858 (116)\ttotal: 29.1s\tremaining: 1m 24s\n",
      "128: learn: 0.9567659\ttest: 0.9312999\tbestTest: 0.9313858 (116)\ttotal: 29.3s\tremaining: 1m 24s\n",
      "129: learn: 0.9568885\ttest: 0.9313901\tbestTest: 0.9313901 (129)\ttotal: 29.4s\tremaining: 1m 23s\n",
      "130: learn: 0.9570292\ttest: 0.931476\tbestTest: 0.931476 (130)\ttotal: 29.6s\tremaining: 1m 23s\n",
      "131: learn: 0.9574355\ttest: 0.9315276\tbestTest: 0.9315276 (131)\ttotal: 29.8s\tremaining: 1m 23s\n",
      "132: learn: 0.9576408\ttest: 0.9313944\tbestTest: 0.9315276 (131)\ttotal: 30.2s\tremaining: 1m 23s\n",
      "133: learn: 0.9577017\ttest: 0.9314889\tbestTest: 0.9315276 (131)\ttotal: 30.4s\tremaining: 1m 23s\n",
      "134: learn: 0.9578207\ttest: 0.9314588\tbestTest: 0.9315276 (131)\ttotal: 30.6s\tremaining: 1m 22s\n",
      "135: learn: 0.9579477\ttest: 0.9314846\tbestTest: 0.9315276 (131)\ttotal: 30.8s\tremaining: 1m 22s\n",
      "136: learn: 0.9580675\ttest: 0.9314674\tbestTest: 0.9315276 (131)\ttotal: 31.1s\tremaining: 1m 22s\n",
      "137: learn: 0.9582738\ttest: 0.9315147\tbestTest: 0.9315276 (131)\ttotal: 31.4s\tremaining: 1m 22s\n",
      "138: learn: 0.9585842\ttest: 0.9314159\tbestTest: 0.9315276 (131)\ttotal: 31.6s\tremaining: 1m 22s\n",
      "139: learn: 0.9587518\ttest: 0.9314631\tbestTest: 0.9315276 (131)\ttotal: 31.8s\tremaining: 1m 21s\n",
      "140: learn: 0.9591197\ttest: 0.9314159\tbestTest: 0.9315276 (131)\ttotal: 32.1s\tremaining: 1m 21s\n",
      "141: learn: 0.9593686\ttest: 0.931476\tbestTest: 0.9315276 (131)\ttotal: 32.3s\tremaining: 1m 21s\n",
      "142: learn: 0.9594787\ttest: 0.9315104\tbestTest: 0.9315276 (131)\ttotal: 32.6s\tremaining: 1m 21s\n",
      "143: learn: 0.9597056\ttest: 0.9316092\tbestTest: 0.9316092 (143)\ttotal: 32.9s\tremaining: 1m 21s\n",
      "144: learn: 0.959959\ttest: 0.9314846\tbestTest: 0.9316092 (143)\ttotal: 33.1s\tremaining: 1m 20s\n",
      "145: learn: 0.960397\ttest: 0.9314674\tbestTest: 0.9316092 (143)\ttotal: 33.3s\tremaining: 1m 20s\n",
      "146: learn: 0.9607005\ttest: 0.9313515\tbestTest: 0.9316092 (143)\ttotal: 33.5s\tremaining: 1m 20s\n",
      "147: learn: 0.9608318\ttest: 0.9313429\tbestTest: 0.9316092 (143)\ttotal: 33.8s\tremaining: 1m 20s\n",
      "148: learn: 0.9611741\ttest: 0.9312612\tbestTest: 0.9316092 (143)\ttotal: 34s\tremaining: 1m 20s\n",
      "149: learn: 0.9612494\ttest: 0.9313257\tbestTest: 0.9316092 (143)\ttotal: 34.1s\tremaining: 1m 19s\n",
      "150: learn: 0.9615618\ttest: 0.9314417\tbestTest: 0.9316092 (143)\ttotal: 34.4s\tremaining: 1m 19s\n",
      "151: learn: 0.9616617\ttest: 0.9316178\tbestTest: 0.9316178 (151)\ttotal: 34.5s\tremaining: 1m 19s\n",
      "152: learn: 0.9618178\ttest: 0.931708\tbestTest: 0.931708 (152)\ttotal: 34.9s\tremaining: 1m 19s\n",
      "153: learn: 0.9620861\ttest: 0.9317251\tbestTest: 0.9317251 (153)\ttotal: 35.1s\tremaining: 1m 18s\n",
      "154: learn: 0.9622743\ttest: 0.9316221\tbestTest: 0.9317251 (153)\ttotal: 35.3s\tremaining: 1m 18s\n",
      "155: learn: 0.9624053\ttest: 0.9316564\tbestTest: 0.9317251 (153)\ttotal: 35.5s\tremaining: 1m 18s\n",
      "156: learn: 0.9624689\ttest: 0.9315533\tbestTest: 0.9317251 (153)\ttotal: 35.7s\tremaining: 1m 18s\n",
      "157: learn: 0.9627709\ttest: 0.9315963\tbestTest: 0.9317251 (153)\ttotal: 36.1s\tremaining: 1m 18s\n",
      "158: learn: 0.9628946\ttest: 0.9315447\tbestTest: 0.9317251 (153)\ttotal: 36.3s\tremaining: 1m 17s\n",
      "159: learn: 0.9630052\ttest: 0.9314459\tbestTest: 0.9317251 (153)\ttotal: 36.6s\tremaining: 1m 17s\n",
      "160: learn: 0.963184\ttest: 0.931549\tbestTest: 0.9317251 (153)\ttotal: 36.8s\tremaining: 1m 17s\n",
      "161: learn: 0.9632729\ttest: 0.9314374\tbestTest: 0.9317251 (153)\ttotal: 37s\tremaining: 1m 17s\n",
      "162: learn: 0.9635174\ttest: 0.9315533\tbestTest: 0.9317251 (153)\ttotal: 37.4s\tremaining: 1m 17s\n",
      "163: learn: 0.9637864\ttest: 0.9315963\tbestTest: 0.9317251 (153)\ttotal: 37.6s\tremaining: 1m 17s\n",
      "164: learn: 0.9640725\ttest: 0.9316006\tbestTest: 0.9317251 (153)\ttotal: 37.8s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165: learn: 0.9644226\ttest: 0.9313772\tbestTest: 0.9317251 (153)\ttotal: 38s\tremaining: 1m 16s\n",
      "166: learn: 0.9645936\ttest: 0.9312527\tbestTest: 0.9317251 (153)\ttotal: 38.2s\tremaining: 1m 16s\n",
      "167: learn: 0.9648255\ttest: 0.9311625\tbestTest: 0.9317251 (153)\ttotal: 38.6s\tremaining: 1m 16s\n",
      "168: learn: 0.9649777\ttest: 0.9312527\tbestTest: 0.9317251 (153)\ttotal: 38.9s\tremaining: 1m 16s\n",
      "169: learn: 0.9652829\ttest: 0.93136\tbestTest: 0.9317251 (153)\ttotal: 39.3s\tremaining: 1m 16s\n",
      "170: learn: 0.9653451\ttest: 0.9312913\tbestTest: 0.9317251 (153)\ttotal: 39.6s\tremaining: 1m 16s\n",
      "171: learn: 0.9653969\ttest: 0.9313429\tbestTest: 0.9317251 (153)\ttotal: 40s\tremaining: 1m 16s\n",
      "172: learn: 0.9657318\ttest: 0.9313515\tbestTest: 0.9317251 (153)\ttotal: 40.4s\tremaining: 1m 16s\n",
      "173: learn: 0.9659951\ttest: 0.9314417\tbestTest: 0.9317251 (153)\ttotal: 40.7s\tremaining: 1m 16s\n",
      "174: learn: 0.9663627\ttest: 0.9314545\tbestTest: 0.9317251 (153)\ttotal: 40.9s\tremaining: 1m 15s\n",
      "175: learn: 0.9664645\ttest: 0.9312784\tbestTest: 0.9317251 (153)\ttotal: 41.1s\tremaining: 1m 15s\n",
      "176: learn: 0.9666773\ttest: 0.9313944\tbestTest: 0.9317251 (153)\ttotal: 41.5s\tremaining: 1m 15s\n",
      "177: learn: 0.9669513\ttest: 0.9315233\tbestTest: 0.9317251 (153)\ttotal: 41.7s\tremaining: 1m 15s\n",
      "178: learn: 0.9672633\ttest: 0.9315877\tbestTest: 0.9317251 (153)\ttotal: 41.9s\tremaining: 1m 15s\n",
      "179: learn: 0.9675229\ttest: 0.9316349\tbestTest: 0.9317251 (153)\ttotal: 42.1s\tremaining: 1m 14s\n",
      "180: learn: 0.9676879\ttest: 0.9315619\tbestTest: 0.9317251 (153)\ttotal: 42.3s\tremaining: 1m 14s\n",
      "181: learn: 0.9678529\ttest: 0.9315533\tbestTest: 0.9317251 (153)\ttotal: 42.6s\tremaining: 1m 14s\n",
      "182: learn: 0.9681455\ttest: 0.9314116\tbestTest: 0.9317251 (153)\ttotal: 42.8s\tremaining: 1m 14s\n",
      "183: learn: 0.9683876\ttest: 0.9312441\tbestTest: 0.9317251 (153)\ttotal: 43s\tremaining: 1m 13s\n",
      "184: learn: 0.9685403\ttest: 0.9313987\tbestTest: 0.9317251 (153)\ttotal: 43.2s\tremaining: 1m 13s\n",
      "185: learn: 0.9687678\ttest: 0.9313987\tbestTest: 0.9317251 (153)\ttotal: 43.4s\tremaining: 1m 13s\n",
      "186: learn: 0.9691124\ttest: 0.9312484\tbestTest: 0.9317251 (153)\ttotal: 43.6s\tremaining: 1m 13s\n",
      "187: learn: 0.9693315\ttest: 0.9311668\tbestTest: 0.9317251 (153)\ttotal: 43.8s\tremaining: 1m 12s\n",
      "188: learn: 0.9696976\ttest: 0.9312312\tbestTest: 0.9317251 (153)\ttotal: 44s\tremaining: 1m 12s\n",
      "189: learn: 0.9698665\ttest: 0.9311839\tbestTest: 0.9317251 (153)\ttotal: 44.2s\tremaining: 1m 12s\n",
      "190: learn: 0.9699546\ttest: 0.9313085\tbestTest: 0.9317251 (153)\ttotal: 44.4s\tremaining: 1m 11s\n",
      "191: learn: 0.9701795\ttest: 0.9313042\tbestTest: 0.9317251 (153)\ttotal: 44.6s\tremaining: 1m 11s\n",
      "192: learn: 0.9705466\ttest: 0.9310851\tbestTest: 0.9317251 (153)\ttotal: 44.8s\tremaining: 1m 11s\n",
      "193: learn: 0.9706611\ttest: 0.9310594\tbestTest: 0.9317251 (153)\ttotal: 45.1s\tremaining: 1m 11s\n",
      "194: learn: 0.970989\ttest: 0.9313643\tbestTest: 0.9317251 (153)\ttotal: 45.4s\tremaining: 1m 10s\n",
      "195: learn: 0.9712672\ttest: 0.9312226\tbestTest: 0.9317251 (153)\ttotal: 45.6s\tremaining: 1m 10s\n",
      "196: learn: 0.9716463\ttest: 0.9312484\tbestTest: 0.9317251 (153)\ttotal: 45.8s\tremaining: 1m 10s\n",
      "197: learn: 0.9718077\ttest: 0.9312355\tbestTest: 0.9317251 (153)\ttotal: 46s\tremaining: 1m 10s\n",
      "198: learn: 0.9718257\ttest: 0.9312612\tbestTest: 0.9317251 (153)\ttotal: 46.5s\tremaining: 1m 10s\n",
      "199: learn: 0.971958\ttest: 0.9313515\tbestTest: 0.9317251 (153)\ttotal: 46.7s\tremaining: 1m 10s\n",
      "200: learn: 0.9721981\ttest: 0.9314374\tbestTest: 0.9317251 (153)\ttotal: 46.9s\tremaining: 1m 9s\n",
      "201: learn: 0.9724038\ttest: 0.9314545\tbestTest: 0.9317251 (153)\ttotal: 47.1s\tremaining: 1m 9s\n",
      "202: learn: 0.972573\ttest: 0.9315276\tbestTest: 0.9317251 (153)\ttotal: 47.5s\tremaining: 1m 9s\n",
      "203: learn: 0.9728136\ttest: 0.931665\tbestTest: 0.9317251 (153)\ttotal: 47.7s\tremaining: 1m 9s\n",
      "204: learn: 0.9729814\ttest: 0.9318411\tbestTest: 0.9318411 (204)\ttotal: 47.9s\tremaining: 1m 8s\n",
      "205: learn: 0.9731571\ttest: 0.932043\tbestTest: 0.932043 (205)\ttotal: 48.1s\tremaining: 1m 8s\n",
      "206: learn: 0.9734395\ttest: 0.9319915\tbestTest: 0.932043 (205)\ttotal: 48.3s\tremaining: 1m 8s\n",
      "207: learn: 0.9736495\ttest: 0.9320688\tbestTest: 0.9320688 (207)\ttotal: 48.7s\tremaining: 1m 8s\n",
      "208: learn: 0.9739172\ttest: 0.9321289\tbestTest: 0.9321289 (208)\ttotal: 48.9s\tremaining: 1m 8s\n",
      "209: learn: 0.9740848\ttest: 0.9321074\tbestTest: 0.9321289 (208)\ttotal: 49.1s\tremaining: 1m 7s\n",
      "210: learn: 0.9742543\ttest: 0.9321375\tbestTest: 0.9321375 (210)\ttotal: 49.3s\tremaining: 1m 7s\n",
      "211: learn: 0.9745205\ttest: 0.9319141\tbestTest: 0.9321375 (210)\ttotal: 49.5s\tremaining: 1m 7s\n",
      "212: learn: 0.9747309\ttest: 0.93197\tbestTest: 0.9321375 (210)\ttotal: 49.9s\tremaining: 1m 7s\n",
      "213: learn: 0.9750055\ttest: 0.9320172\tbestTest: 0.9321375 (210)\ttotal: 50.1s\tremaining: 1m 6s\n",
      "214: learn: 0.9752921\ttest: 0.932086\tbestTest: 0.9321375 (210)\ttotal: 50.3s\tremaining: 1m 6s\n",
      "215: learn: 0.9755525\ttest: 0.9320172\tbestTest: 0.9321375 (210)\ttotal: 50.5s\tremaining: 1m 6s\n",
      "216: learn: 0.9757936\ttest: 0.9319399\tbestTest: 0.9321375 (210)\ttotal: 50.7s\tremaining: 1m 6s\n",
      "217: learn: 0.9758929\ttest: 0.9318196\tbestTest: 0.9321375 (210)\ttotal: 51.1s\tremaining: 1m 6s\n",
      "218: learn: 0.9760501\ttest: 0.9318025\tbestTest: 0.9321375 (210)\ttotal: 51.3s\tremaining: 1m 5s\n",
      "219: learn: 0.97622\ttest: 0.9319786\tbestTest: 0.9321375 (210)\ttotal: 51.5s\tremaining: 1m 5s\n",
      "220: learn: 0.9763699\ttest: 0.9318325\tbestTest: 0.9321375 (210)\ttotal: 51.7s\tremaining: 1m 5s\n",
      "221: learn: 0.9766149\ttest: 0.9319356\tbestTest: 0.9321375 (210)\ttotal: 51.9s\tremaining: 1m 5s\n",
      "222: learn: 0.9768593\ttest: 0.9318927\tbestTest: 0.9321375 (210)\ttotal: 52.3s\tremaining: 1m 4s\n",
      "223: learn: 0.9769156\ttest: 0.9318755\tbestTest: 0.9321375 (210)\ttotal: 52.5s\tremaining: 1m 4s\n",
      "224: learn: 0.9770625\ttest: 0.9318196\tbestTest: 0.9321375 (210)\ttotal: 52.7s\tremaining: 1m 4s\n",
      "225: learn: 0.9772599\ttest: 0.9318111\tbestTest: 0.9321375 (210)\ttotal: 53s\tremaining: 1m 4s\n",
      "226: learn: 0.9774385\ttest: 0.9318068\tbestTest: 0.9321375 (210)\ttotal: 53.2s\tremaining: 1m 3s\n",
      "227: learn: 0.9777055\ttest: 0.9317337\tbestTest: 0.9321375 (210)\ttotal: 53.5s\tremaining: 1m 3s\n",
      "228: learn: 0.9778053\ttest: 0.9316908\tbestTest: 0.9321375 (210)\ttotal: 53.7s\tremaining: 1m 3s\n",
      "229: learn: 0.9779298\ttest: 0.9316392\tbestTest: 0.9321375 (210)\ttotal: 53.9s\tremaining: 1m 3s\n",
      "230: learn: 0.9780263\ttest: 0.9317294\tbestTest: 0.9321375 (210)\ttotal: 54.1s\tremaining: 1m 2s\n",
      "231: learn: 0.978259\ttest: 0.9315576\tbestTest: 0.9321375 (210)\ttotal: 54.3s\tremaining: 1m 2s\n",
      "232: learn: 0.9785003\ttest: 0.9314245\tbestTest: 0.9321375 (210)\ttotal: 54.7s\tremaining: 1m 2s\n",
      "233: learn: 0.9785921\ttest: 0.9315276\tbestTest: 0.9321375 (210)\ttotal: 54.8s\tremaining: 1m 2s\n",
      "234: learn: 0.9787064\ttest: 0.9315576\tbestTest: 0.9321375 (210)\ttotal: 55.1s\tremaining: 1m 2s\n",
      "235: learn: 0.9788233\ttest: 0.9315791\tbestTest: 0.9321375 (210)\ttotal: 55.3s\tremaining: 1m 1s\n",
      "236: learn: 0.9788999\ttest: 0.9315018\tbestTest: 0.9321375 (210)\ttotal: 55.5s\tremaining: 1m 1s\n",
      "237: learn: 0.9791608\ttest: 0.9314331\tbestTest: 0.9321375 (210)\ttotal: 55.9s\tremaining: 1m 1s\n",
      "238: learn: 0.9794364\ttest: 0.9313729\tbestTest: 0.9321375 (210)\ttotal: 56.1s\tremaining: 1m 1s\n",
      "239: learn: 0.9796783\ttest: 0.9316994\tbestTest: 0.9321375 (210)\ttotal: 56.3s\tremaining: 1m 1s\n",
      "240: learn: 0.9798854\ttest: 0.9315319\tbestTest: 0.9321375 (210)\ttotal: 56.5s\tremaining: 1m\n",
      "241: learn: 0.9800883\ttest: 0.9315533\tbestTest: 0.9321375 (210)\ttotal: 56.7s\tremaining: 1m\n",
      "242: learn: 0.9801578\ttest: 0.9315705\tbestTest: 0.9321375 (210)\ttotal: 57.1s\tremaining: 1m\n",
      "243: learn: 0.980208\ttest: 0.9315619\tbestTest: 0.9321375 (210)\ttotal: 57.3s\tremaining: 1m\n",
      "244: learn: 0.9803673\ttest: 0.9313472\tbestTest: 0.9321375 (210)\ttotal: 57.5s\tremaining: 59.9s\n",
      "245: learn: 0.9803973\ttest: 0.9314545\tbestTest: 0.9321375 (210)\ttotal: 57.8s\tremaining: 59.6s\n",
      "246: learn: 0.9805231\ttest: 0.9315533\tbestTest: 0.9321375 (210)\ttotal: 58s\tremaining: 59.4s\n",
      "247: learn: 0.9806468\ttest: 0.931549\tbestTest: 0.9321375 (210)\ttotal: 58.3s\tremaining: 59.3s\n",
      "248: learn: 0.9809192\ttest: 0.9316521\tbestTest: 0.9321375 (210)\ttotal: 58.6s\tremaining: 59s\n",
      "249: learn: 0.9810466\ttest: 0.9314717\tbestTest: 0.9321375 (210)\ttotal: 58.8s\tremaining: 58.8s\n",
      "250: learn: 0.9811841\ttest: 0.9314459\tbestTest: 0.9321375 (210)\ttotal: 58.9s\tremaining: 58.5s\n",
      "251: learn: 0.9813781\ttest: 0.9314331\tbestTest: 0.9321375 (210)\ttotal: 59.2s\tremaining: 58.2s\n",
      "252: learn: 0.9815125\ttest: 0.9314631\tbestTest: 0.9321375 (210)\ttotal: 59.5s\tremaining: 58.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253: learn: 0.9817651\ttest: 0.9313815\tbestTest: 0.9321375 (210)\ttotal: 59.7s\tremaining: 57.9s\n",
      "254: learn: 0.9819019\ttest: 0.9315233\tbestTest: 0.9321375 (210)\ttotal: 59.9s\tremaining: 57.6s\n",
      "255: learn: 0.9819332\ttest: 0.9314116\tbestTest: 0.9321375 (210)\ttotal: 1m\tremaining: 57.3s\n",
      "256: learn: 0.9820595\ttest: 0.9314116\tbestTest: 0.9321375 (210)\ttotal: 1m\tremaining: 57.1s\n",
      "257: learn: 0.9822331\ttest: 0.9312999\tbestTest: 0.9321375 (210)\ttotal: 1m\tremaining: 57s\n",
      "258: learn: 0.9823291\ttest: 0.9312999\tbestTest: 0.9321375 (210)\ttotal: 1m\tremaining: 56.7s\n",
      "259: learn: 0.9824585\ttest: 0.9311582\tbestTest: 0.9321375 (210)\ttotal: 1m 1s\tremaining: 56.4s\n",
      "260: learn: 0.9826183\ttest: 0.9310465\tbestTest: 0.9321375 (210)\ttotal: 1m 1s\tremaining: 56.2s\n",
      "261: learn: 0.9827072\ttest: 0.9310379\tbestTest: 0.9321375 (210)\ttotal: 1m 1s\tremaining: 55.9s\n",
      "262: learn: 0.9827728\ttest: 0.9310637\tbestTest: 0.9321375 (210)\ttotal: 1m 1s\tremaining: 55.8s\n",
      "263: learn: 0.9828552\ttest: 0.9311066\tbestTest: 0.9321375 (210)\ttotal: 1m 2s\tremaining: 55.5s\n",
      "264: learn: 0.9829177\ttest: 0.9311324\tbestTest: 0.9321375 (210)\ttotal: 1m 2s\tremaining: 55.3s\n",
      "265: learn: 0.9830848\ttest: 0.9310894\tbestTest: 0.9321375 (210)\ttotal: 1m 2s\tremaining: 55.1s\n",
      "266: learn: 0.9831912\ttest: 0.9309735\tbestTest: 0.9321375 (210)\ttotal: 1m 2s\tremaining: 54.8s\n",
      "267: learn: 0.9833049\ttest: 0.9308876\tbestTest: 0.9321375 (210)\ttotal: 1m 3s\tremaining: 54.6s\n",
      "268: learn: 0.9834527\ttest: 0.9308704\tbestTest: 0.9321375 (210)\ttotal: 1m 3s\tremaining: 54.5s\n",
      "269: learn: 0.9834987\ttest: 0.930836\tbestTest: 0.9321375 (210)\ttotal: 1m 3s\tremaining: 54.4s\n",
      "270: learn: 0.9836069\ttest: 0.9306642\tbestTest: 0.9321375 (210)\ttotal: 1m 4s\tremaining: 54.2s\n",
      "271: learn: 0.983643\ttest: 0.93072\tbestTest: 0.9321375 (210)\ttotal: 1m 4s\tremaining: 53.9s\n",
      "272: learn: 0.9837183\ttest: 0.9308102\tbestTest: 0.9321375 (210)\ttotal: 1m 4s\tremaining: 53.6s\n",
      "273: learn: 0.983814\ttest: 0.9307157\tbestTest: 0.9321375 (210)\ttotal: 1m 4s\tremaining: 53.3s\n",
      "274: learn: 0.9839047\ttest: 0.9306384\tbestTest: 0.9321375 (210)\ttotal: 1m 4s\tremaining: 53.1s\n",
      "275: learn: 0.9839675\ttest: 0.9305912\tbestTest: 0.9321375 (210)\ttotal: 1m 5s\tremaining: 52.9s\n",
      "276: learn: 0.9840943\ttest: 0.9306384\tbestTest: 0.9321375 (210)\ttotal: 1m 5s\tremaining: 52.7s\n",
      "277: learn: 0.9841257\ttest: 0.9306857\tbestTest: 0.9321375 (210)\ttotal: 1m 5s\tremaining: 52.4s\n",
      "278: learn: 0.9842439\ttest: 0.9306513\tbestTest: 0.9321375 (210)\ttotal: 1m 5s\tremaining: 52.1s\n",
      "279: learn: 0.9843275\ttest: 0.930647\tbestTest: 0.9321375 (210)\ttotal: 1m 6s\tremaining: 51.9s\n",
      "280: learn: 0.9843942\ttest: 0.9305869\tbestTest: 0.9321375 (210)\ttotal: 1m 6s\tremaining: 51.7s\n",
      "281: learn: 0.9845281\ttest: 0.9304322\tbestTest: 0.9321375 (210)\ttotal: 1m 6s\tremaining: 51.5s\n",
      "282: learn: 0.9847012\ttest: 0.9304795\tbestTest: 0.9321375 (210)\ttotal: 1m 6s\tremaining: 51.2s\n",
      "283: learn: 0.984879\ttest: 0.9305267\tbestTest: 0.9321375 (210)\ttotal: 1m 7s\tremaining: 51s\n",
      "284: learn: 0.9850696\ttest: 0.930458\tbestTest: 0.9321375 (210)\ttotal: 1m 7s\tremaining: 50.7s\n",
      "285: learn: 0.9851917\ttest: 0.9305611\tbestTest: 0.9321375 (210)\ttotal: 1m 7s\tremaining: 50.6s\n",
      "286: learn: 0.9853964\ttest: 0.9306685\tbestTest: 0.9321375 (210)\ttotal: 1m 7s\tremaining: 50.3s\n",
      "287: learn: 0.9854945\ttest: 0.9305697\tbestTest: 0.9321375 (210)\ttotal: 1m 8s\tremaining: 50.1s\n",
      "288: learn: 0.9855654\ttest: 0.9305267\tbestTest: 0.9321375 (210)\ttotal: 1m 8s\tremaining: 49.8s\n",
      "289: learn: 0.9857168\ttest: 0.9305826\tbestTest: 0.9321375 (210)\ttotal: 1m 8s\tremaining: 49.5s\n",
      "290: learn: 0.9857685\ttest: 0.9306384\tbestTest: 0.9321375 (210)\ttotal: 1m 8s\tremaining: 49.4s\n",
      "291: learn: 0.9858624\ttest: 0.9305998\tbestTest: 0.9321375 (210)\ttotal: 1m 8s\tremaining: 49.1s\n",
      "292: learn: 0.9859429\ttest: 0.9305439\tbestTest: 0.9321375 (210)\ttotal: 1m 9s\tremaining: 48.8s\n",
      "293: learn: 0.9860846\ttest: 0.9305139\tbestTest: 0.9321375 (210)\ttotal: 1m 9s\tremaining: 48.6s\n",
      "294: learn: 0.9861558\ttest: 0.9304795\tbestTest: 0.9321375 (210)\ttotal: 1m 9s\tremaining: 48.3s\n",
      "295: learn: 0.9862664\ttest: 0.9305998\tbestTest: 0.9321375 (210)\ttotal: 1m 9s\tremaining: 48.2s\n",
      "296: learn: 0.9863827\ttest: 0.9305224\tbestTest: 0.9321375 (210)\ttotal: 1m 10s\tremaining: 47.9s\n",
      "297: learn: 0.9865532\ttest: 0.93069\tbestTest: 0.9321375 (210)\ttotal: 1m 10s\tremaining: 47.7s\n",
      "298: learn: 0.9867436\ttest: 0.9307157\tbestTest: 0.9321375 (210)\ttotal: 1m 10s\tremaining: 47.4s\n",
      "299: learn: 0.9868539\ttest: 0.9307587\tbestTest: 0.9321375 (210)\ttotal: 1m 10s\tremaining: 47.2s\n",
      "300: learn: 0.9869263\ttest: 0.9307372\tbestTest: 0.9321375 (210)\ttotal: 1m 11s\tremaining: 47s\n",
      "301: learn: 0.9870555\ttest: 0.9309176\tbestTest: 0.9321375 (210)\ttotal: 1m 11s\tremaining: 46.8s\n",
      "302: learn: 0.9871115\ttest: 0.9308102\tbestTest: 0.9321375 (210)\ttotal: 1m 11s\tremaining: 46.5s\n",
      "303: learn: 0.9871734\ttest: 0.93072\tbestTest: 0.9321375 (210)\ttotal: 1m 11s\tremaining: 46.4s\n",
      "304: learn: 0.9873083\ttest: 0.9308102\tbestTest: 0.9321375 (210)\ttotal: 1m 12s\tremaining: 46.2s\n",
      "305: learn: 0.9874312\ttest: 0.9308489\tbestTest: 0.9321375 (210)\ttotal: 1m 12s\tremaining: 46s\n",
      "306: learn: 0.9874851\ttest: 0.9309004\tbestTest: 0.9321375 (210)\ttotal: 1m 12s\tremaining: 45.7s\n",
      "307: learn: 0.9875426\ttest: 0.9309176\tbestTest: 0.9321375 (210)\ttotal: 1m 12s\tremaining: 45.5s\n",
      "308: learn: 0.9876812\ttest: 0.9309606\tbestTest: 0.9321375 (210)\ttotal: 1m 13s\tremaining: 45.2s\n",
      "309: learn: 0.9877769\ttest: 0.9310336\tbestTest: 0.9321375 (210)\ttotal: 1m 13s\tremaining: 45s\n",
      "310: learn: 0.9878755\ttest: 0.9309434\tbestTest: 0.9321375 (210)\ttotal: 1m 13s\tremaining: 44.8s\n",
      "311: learn: 0.9879233\ttest: 0.9308575\tbestTest: 0.9321375 (210)\ttotal: 1m 13s\tremaining: 44.5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9321375033\n",
      "bestIteration = 210\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.987923325524 0.930857484032\n",
      "[0.9359533325259376, 0.93319957103815687, 0.93683091102445948, 0.93085748403197477]\n",
      "0: learn: 0.8512103\ttest: 0.8435603\tbestTest: 0.8435603 (0)\ttotal: 266ms\tremaining: 2m 12s\n",
      "1: learn: 0.8792781\ttest: 0.8614472\tbestTest: 0.8614472 (1)\ttotal: 476ms\tremaining: 1m 58s\n",
      "2: learn: 0.8795558\ttest: 0.8619742\tbestTest: 0.8619742 (2)\ttotal: 687ms\tremaining: 1m 53s\n",
      "3: learn: 0.8828921\ttest: 0.8670652\tbestTest: 0.8670652 (3)\ttotal: 887ms\tremaining: 1m 49s\n",
      "4: learn: 0.8831542\ttest: 0.8661208\tbestTest: 0.8670652 (3)\ttotal: 1.08s\tremaining: 1m 47s\n",
      "5: learn: 0.8931636\ttest: 0.8776351\tbestTest: 0.8776351 (5)\ttotal: 1.44s\tremaining: 1m 58s\n",
      "6: learn: 0.8954684\ttest: 0.8834997\tbestTest: 0.8834997 (6)\ttotal: 1.65s\tremaining: 1m 56s\n",
      "7: learn: 0.8982943\ttest: 0.8875114\tbestTest: 0.8875114 (7)\ttotal: 1.86s\tremaining: 1m 54s\n",
      "8: learn: 0.900272\ttest: 0.8881522\tbestTest: 0.8881522 (8)\ttotal: 2.11s\tremaining: 1m 54s\n",
      "9: learn: 0.9031165\ttest: 0.8925581\tbestTest: 0.8925581 (9)\ttotal: 2.33s\tremaining: 1m 54s\n",
      "10: learn: 0.9065859\ttest: 0.8959352\tbestTest: 0.8959352 (10)\ttotal: 2.69s\tremaining: 1m 59s\n",
      "11: learn: 0.9130746\ttest: 0.9008386\tbestTest: 0.9008386 (11)\ttotal: 2.89s\tremaining: 1m 57s\n",
      "12: learn: 0.9145681\ttest: 0.9020254\tbestTest: 0.9020254 (12)\ttotal: 3.07s\tremaining: 1m 55s\n",
      "13: learn: 0.9179411\ttest: 0.9036318\tbestTest: 0.9036318 (13)\ttotal: 3.28s\tremaining: 1m 53s\n",
      "14: learn: 0.9183833\ttest: 0.9034758\tbestTest: 0.9036318 (13)\ttotal: 3.49s\tremaining: 1m 52s\n",
      "15: learn: 0.9196886\ttest: 0.9056007\tbestTest: 0.9056007 (15)\ttotal: 3.83s\tremaining: 1m 56s\n",
      "16: learn: 0.9200787\ttest: 0.9053794\tbestTest: 0.9056007 (15)\ttotal: 4.05s\tremaining: 1m 54s\n",
      "17: learn: 0.9215978\ttest: 0.906231\tbestTest: 0.906231 (17)\ttotal: 4.25s\tremaining: 1m 53s\n",
      "18: learn: 0.92215\ttest: 0.9062605\tbestTest: 0.9062605 (18)\ttotal: 4.46s\tremaining: 1m 52s\n",
      "19: learn: 0.9218779\ttest: 0.9064503\tbestTest: 0.9064503 (19)\ttotal: 4.67s\tremaining: 1m 51s\n",
      "20: learn: 0.922466\ttest: 0.9074284\tbestTest: 0.9074284 (20)\ttotal: 4.96s\tremaining: 1m 53s\n",
      "21: learn: 0.9229122\ttest: 0.9077889\tbestTest: 0.9077889 (21)\ttotal: 5.18s\tremaining: 1m 52s\n",
      "22: learn: 0.923868\ttest: 0.9070511\tbestTest: 0.9077889 (21)\ttotal: 5.36s\tremaining: 1m 51s\n",
      "23: learn: 0.9241467\ttest: 0.9068529\tbestTest: 0.9077889 (21)\ttotal: 5.56s\tremaining: 1m 50s\n",
      "24: learn: 0.9244499\ttest: 0.9057483\tbestTest: 0.9077889 (21)\ttotal: 5.79s\tremaining: 1m 49s\n",
      "25: learn: 0.9249539\ttest: 0.9061783\tbestTest: 0.9077889 (21)\ttotal: 6.08s\tremaining: 1m 50s\n",
      "26: learn: 0.9244467\ttest: 0.9059633\tbestTest: 0.9077889 (21)\ttotal: 6.32s\tremaining: 1m 50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27: learn: 0.9255795\ttest: 0.9062416\tbestTest: 0.9077889 (21)\ttotal: 6.53s\tremaining: 1m 50s\n",
      "28: learn: 0.9260037\ttest: 0.9068403\tbestTest: 0.9077889 (21)\ttotal: 6.75s\tremaining: 1m 49s\n",
      "29: learn: 0.9268386\ttest: 0.9078437\tbestTest: 0.9078437 (29)\ttotal: 6.96s\tremaining: 1m 49s\n",
      "30: learn: 0.9271987\ttest: 0.908455\tbestTest: 0.908455 (30)\ttotal: 7.21s\tremaining: 1m 49s\n",
      "31: learn: 0.9283719\ttest: 0.9087839\tbestTest: 0.9087839 (31)\ttotal: 7.42s\tremaining: 1m 48s\n",
      "32: learn: 0.9301951\ttest: 0.9099096\tbestTest: 0.9099096 (32)\ttotal: 7.62s\tremaining: 1m 47s\n",
      "33: learn: 0.9306947\ttest: 0.9099349\tbestTest: 0.9099349 (33)\ttotal: 7.82s\tremaining: 1m 47s\n",
      "34: learn: 0.9315095\ttest: 0.9110522\tbestTest: 0.9110522 (34)\ttotal: 8.02s\tremaining: 1m 46s\n",
      "35: learn: 0.9318764\ttest: 0.9108456\tbestTest: 0.9110522 (34)\ttotal: 8.21s\tremaining: 1m 45s\n",
      "36: learn: 0.931692\ttest: 0.9111407\tbestTest: 0.9111407 (36)\ttotal: 8.43s\tremaining: 1m 45s\n",
      "37: learn: 0.9321002\ttest: 0.9114485\tbestTest: 0.9114485 (37)\ttotal: 8.63s\tremaining: 1m 44s\n",
      "38: learn: 0.9325809\ttest: 0.9118279\tbestTest: 0.9118279 (38)\ttotal: 8.82s\tremaining: 1m 44s\n",
      "39: learn: 0.9326142\ttest: 0.9112461\tbestTest: 0.9118279 (38)\ttotal: 9.03s\tremaining: 1m 43s\n",
      "40: learn: 0.9334477\ttest: 0.911516\tbestTest: 0.9118279 (38)\ttotal: 9.24s\tremaining: 1m 43s\n",
      "41: learn: 0.9341524\ttest: 0.9123339\tbestTest: 0.9123339 (41)\ttotal: 9.46s\tremaining: 1m 43s\n",
      "42: learn: 0.9349236\ttest: 0.9131919\tbestTest: 0.9131919 (42)\ttotal: 9.67s\tremaining: 1m 42s\n",
      "43: learn: 0.9354035\ttest: 0.9130148\tbestTest: 0.9131919 (42)\ttotal: 9.88s\tremaining: 1m 42s\n",
      "44: learn: 0.9360173\ttest: 0.9138285\tbestTest: 0.9138285 (44)\ttotal: 10.1s\tremaining: 1m 41s\n",
      "45: learn: 0.9366937\ttest: 0.9142712\tbestTest: 0.9142712 (45)\ttotal: 10.3s\tremaining: 1m 41s\n",
      "46: learn: 0.9371849\ttest: 0.9146759\tbestTest: 0.9146759 (46)\ttotal: 10.5s\tremaining: 1m 41s\n",
      "47: learn: 0.9376579\ttest: 0.9145916\tbestTest: 0.9146759 (46)\ttotal: 10.7s\tremaining: 1m 41s\n",
      "48: learn: 0.9380328\ttest: 0.915047\tbestTest: 0.915047 (48)\ttotal: 10.9s\tremaining: 1m 40s\n",
      "49: learn: 0.9382718\ttest: 0.9153463\tbestTest: 0.9153463 (49)\ttotal: 11.1s\tremaining: 1m 40s\n",
      "50: learn: 0.9389195\ttest: 0.9160462\tbestTest: 0.9160462 (50)\ttotal: 11.4s\tremaining: 1m 40s\n",
      "51: learn: 0.9396862\ttest: 0.9160588\tbestTest: 0.9160588 (51)\ttotal: 11.6s\tremaining: 1m 39s\n",
      "52: learn: 0.9399274\ttest: 0.9157764\tbestTest: 0.9160588 (51)\ttotal: 11.8s\tremaining: 1m 39s\n",
      "53: learn: 0.9404981\ttest: 0.9161305\tbestTest: 0.9161305 (53)\ttotal: 12s\tremaining: 1m 39s\n",
      "54: learn: 0.9409617\ttest: 0.9164383\tbestTest: 0.9164383 (54)\ttotal: 12.2s\tremaining: 1m 38s\n",
      "55: learn: 0.9409896\ttest: 0.9162106\tbestTest: 0.9164383 (54)\ttotal: 12.4s\tremaining: 1m 38s\n",
      "56: learn: 0.9411448\ttest: 0.9157595\tbestTest: 0.9164383 (54)\ttotal: 12.7s\tremaining: 1m 38s\n",
      "57: learn: 0.9415764\ttest: 0.9165142\tbestTest: 0.9165142 (57)\ttotal: 12.9s\tremaining: 1m 38s\n",
      "58: learn: 0.9419089\ttest: 0.9165606\tbestTest: 0.9165606 (58)\ttotal: 13.1s\tremaining: 1m 37s\n",
      "59: learn: 0.9421414\ttest: 0.9164214\tbestTest: 0.9165606 (58)\ttotal: 13.3s\tremaining: 1m 37s\n",
      "60: learn: 0.9425393\ttest: 0.9167967\tbestTest: 0.9167967 (60)\ttotal: 13.5s\tremaining: 1m 37s\n",
      "61: learn: 0.9426097\ttest: 0.9169316\tbestTest: 0.9169316 (61)\ttotal: 13.7s\tremaining: 1m 36s\n",
      "62: learn: 0.9428377\ttest: 0.9174628\tbestTest: 0.9174628 (62)\ttotal: 13.9s\tremaining: 1m 36s\n",
      "63: learn: 0.9430439\ttest: 0.9173279\tbestTest: 0.9174628 (62)\ttotal: 14.1s\tremaining: 1m 36s\n",
      "64: learn: 0.9433289\ttest: 0.9174881\tbestTest: 0.9174881 (64)\ttotal: 14.3s\tremaining: 1m 35s\n",
      "65: learn: 0.9436588\ttest: 0.9173279\tbestTest: 0.9174881 (64)\ttotal: 14.5s\tremaining: 1m 35s\n",
      "66: learn: 0.9438595\ttest: 0.9174797\tbestTest: 0.9174881 (64)\ttotal: 14.8s\tremaining: 1m 35s\n",
      "67: learn: 0.9441316\ttest: 0.9173911\tbestTest: 0.9174881 (64)\ttotal: 15s\tremaining: 1m 35s\n",
      "68: learn: 0.9443039\ttest: 0.9171044\tbestTest: 0.9174881 (64)\ttotal: 15.2s\tremaining: 1m 34s\n",
      "69: learn: 0.9445747\ttest: 0.917096\tbestTest: 0.9174881 (64)\ttotal: 15.4s\tremaining: 1m 34s\n",
      "70: learn: 0.9446674\ttest: 0.9172478\tbestTest: 0.9174881 (64)\ttotal: 15.6s\tremaining: 1m 34s\n",
      "71: learn: 0.9450648\ttest: 0.9173532\tbestTest: 0.9174881 (64)\ttotal: 15.8s\tremaining: 1m 33s\n",
      "72: learn: 0.9453204\ttest: 0.9175387\tbestTest: 0.9175387 (72)\ttotal: 16s\tremaining: 1m 33s\n",
      "73: learn: 0.9454234\ttest: 0.9175218\tbestTest: 0.9175387 (72)\ttotal: 16.2s\tremaining: 1m 33s\n",
      "74: learn: 0.9455342\ttest: 0.9176483\tbestTest: 0.9176483 (74)\ttotal: 16.4s\tremaining: 1m 33s\n",
      "75: learn: 0.945762\ttest: 0.9173869\tbestTest: 0.9176483 (74)\ttotal: 16.6s\tremaining: 1m 32s\n",
      "76: learn: 0.9459322\ttest: 0.9173448\tbestTest: 0.9176483 (74)\ttotal: 16.8s\tremaining: 1m 32s\n",
      "77: learn: 0.9464052\ttest: 0.9172815\tbestTest: 0.9176483 (74)\ttotal: 17.1s\tremaining: 1m 32s\n",
      "78: learn: 0.9464409\ttest: 0.9172942\tbestTest: 0.9176483 (74)\ttotal: 17.3s\tremaining: 1m 32s\n",
      "79: learn: 0.9467015\ttest: 0.9175809\tbestTest: 0.9176483 (74)\ttotal: 17.5s\tremaining: 1m 32s\n",
      "80: learn: 0.9468097\ttest: 0.9176905\tbestTest: 0.9176905 (80)\ttotal: 17.7s\tremaining: 1m 31s\n",
      "81: learn: 0.9471649\ttest: 0.9178929\tbestTest: 0.9178929 (81)\ttotal: 18s\tremaining: 1m 31s\n",
      "82: learn: 0.9472329\ttest: 0.9178507\tbestTest: 0.9178929 (81)\ttotal: 18.3s\tremaining: 1m 32s\n",
      "83: learn: 0.9473629\ttest: 0.917994\tbestTest: 0.917994 (83)\ttotal: 18.6s\tremaining: 1m 31s\n",
      "84: learn: 0.9476773\ttest: 0.9181163\tbestTest: 0.9181163 (84)\ttotal: 18.8s\tremaining: 1m 31s\n",
      "85: learn: 0.9479032\ttest: 0.9183145\tbestTest: 0.9183145 (85)\ttotal: 19s\tremaining: 1m 31s\n",
      "86: learn: 0.9481661\ttest: 0.9183187\tbestTest: 0.9183187 (86)\ttotal: 19.2s\tremaining: 1m 31s\n",
      "87: learn: 0.948479\ttest: 0.917994\tbestTest: 0.9183187 (86)\ttotal: 19.6s\tremaining: 1m 31s\n",
      "88: learn: 0.9486221\ttest: 0.9181416\tbestTest: 0.9183187 (86)\ttotal: 19.8s\tremaining: 1m 31s\n",
      "89: learn: 0.9488475\ttest: 0.9185927\tbestTest: 0.9185927 (89)\ttotal: 20s\tremaining: 1m 31s\n",
      "90: learn: 0.9490429\ttest: 0.9182344\tbestTest: 0.9185927 (89)\ttotal: 20.2s\tremaining: 1m 30s\n",
      "91: learn: 0.9491774\ttest: 0.918247\tbestTest: 0.9185927 (89)\ttotal: 20.4s\tremaining: 1m 30s\n",
      "92: learn: 0.9493831\ttest: 0.9184241\tbestTest: 0.9185927 (89)\ttotal: 20.8s\tremaining: 1m 31s\n",
      "93: learn: 0.9495903\ttest: 0.9185674\tbestTest: 0.9185927 (89)\ttotal: 21s\tremaining: 1m 30s\n",
      "94: learn: 0.9497353\ttest: 0.9186981\tbestTest: 0.9186981 (94)\ttotal: 21.3s\tremaining: 1m 30s\n",
      "95: learn: 0.9499528\ttest: 0.9186391\tbestTest: 0.9186981 (94)\ttotal: 21.5s\tremaining: 1m 30s\n",
      "96: learn: 0.950201\ttest: 0.9187108\tbestTest: 0.9187108 (96)\ttotal: 21.7s\tremaining: 1m 30s\n",
      "97: learn: 0.9506071\ttest: 0.9187066\tbestTest: 0.9187108 (96)\ttotal: 22s\tremaining: 1m 30s\n",
      "98: learn: 0.9509246\ttest: 0.918656\tbestTest: 0.9187108 (96)\ttotal: 22.2s\tremaining: 1m 30s\n",
      "99: learn: 0.951206\ttest: 0.918774\tbestTest: 0.918774 (99)\ttotal: 22.3s\tremaining: 1m 29s\n",
      "100: learn: 0.9515044\ttest: 0.9190945\tbestTest: 0.9190945 (100)\ttotal: 22.5s\tremaining: 1m 29s\n",
      "101: learn: 0.9519201\ttest: 0.9197353\tbestTest: 0.9197353 (101)\ttotal: 22.7s\tremaining: 1m 28s\n",
      "102: learn: 0.9520152\ttest: 0.9198323\tbestTest: 0.9198323 (102)\ttotal: 22.9s\tremaining: 1m 28s\n",
      "103: learn: 0.9520804\ttest: 0.9201654\tbestTest: 0.9201654 (103)\ttotal: 23.3s\tremaining: 1m 28s\n",
      "104: learn: 0.9521776\ttest: 0.9201021\tbestTest: 0.9201654 (103)\ttotal: 23.5s\tremaining: 1m 28s\n",
      "105: learn: 0.9524904\ttest: 0.9202455\tbestTest: 0.9202455 (105)\ttotal: 23.7s\tremaining: 1m 28s\n",
      "106: learn: 0.952711\ttest: 0.9202665\tbestTest: 0.9202665 (106)\ttotal: 23.9s\tremaining: 1m 27s\n",
      "107: learn: 0.9530055\ttest: 0.9201654\tbestTest: 0.9202665 (106)\ttotal: 24.1s\tremaining: 1m 27s\n",
      "108: learn: 0.9533149\ttest: 0.9202412\tbestTest: 0.9202665 (106)\ttotal: 24.5s\tremaining: 1m 27s\n",
      "109: learn: 0.9536062\ttest: 0.9201401\tbestTest: 0.9202665 (106)\ttotal: 24.7s\tremaining: 1m 27s\n",
      "110: learn: 0.9538812\ttest: 0.9203214\tbestTest: 0.9203214 (110)\ttotal: 24.9s\tremaining: 1m 27s\n",
      "111: learn: 0.9540709\ttest: 0.9202075\tbestTest: 0.9203214 (110)\ttotal: 25.1s\tremaining: 1m 26s\n",
      "112: learn: 0.954173\ttest: 0.9201949\tbestTest: 0.9203214 (110)\ttotal: 25.3s\tremaining: 1m 26s\n",
      "113: learn: 0.954292\ttest: 0.9203256\tbestTest: 0.9203256 (113)\ttotal: 25.7s\tremaining: 1m 27s\n",
      "114: learn: 0.954365\ttest: 0.9202117\tbestTest: 0.9203256 (113)\ttotal: 25.9s\tremaining: 1m 26s\n",
      "115: learn: 0.9545962\ttest: 0.9202412\tbestTest: 0.9203256 (113)\ttotal: 26.1s\tremaining: 1m 26s\n",
      "116: learn: 0.9548812\ttest: 0.9202033\tbestTest: 0.9203256 (113)\ttotal: 26.3s\tremaining: 1m 26s\n",
      "117: learn: 0.955058\ttest: 0.9201864\tbestTest: 0.9203256 (113)\ttotal: 26.5s\tremaining: 1m 25s\n",
      "118: learn: 0.9552358\ttest: 0.9201401\tbestTest: 0.9203256 (113)\ttotal: 26.8s\tremaining: 1m 25s\n",
      "119: learn: 0.9554091\ttest: 0.9201822\tbestTest: 0.9203256 (113)\ttotal: 27s\tremaining: 1m 25s\n",
      "120: learn: 0.9555933\ttest: 0.9203551\tbestTest: 0.9203551 (120)\ttotal: 27.2s\tremaining: 1m 25s\n",
      "121: learn: 0.955863\ttest: 0.9202412\tbestTest: 0.9203551 (120)\ttotal: 27.4s\tremaining: 1m 25s\n",
      "122: learn: 0.9560542\ttest: 0.9205111\tbestTest: 0.9205111 (122)\ttotal: 27.7s\tremaining: 1m 24s\n",
      "123: learn: 0.9562405\ttest: 0.9205532\tbestTest: 0.9205532 (123)\ttotal: 28s\tremaining: 1m 24s\n",
      "124: learn: 0.9563742\ttest: 0.9205996\tbestTest: 0.9205996 (124)\ttotal: 28.3s\tremaining: 1m 24s\n",
      "125: learn: 0.9565549\ttest: 0.9204942\tbestTest: 0.9205996 (124)\ttotal: 28.5s\tremaining: 1m 24s\n",
      "126: learn: 0.9568191\ttest: 0.9205828\tbestTest: 0.9205996 (124)\ttotal: 28.7s\tremaining: 1m 24s\n",
      "127: learn: 0.9572234\ttest: 0.9208315\tbestTest: 0.9208315 (127)\ttotal: 28.9s\tremaining: 1m 23s\n",
      "128: learn: 0.9573647\ttest: 0.9207893\tbestTest: 0.9208315 (127)\ttotal: 29.3s\tremaining: 1m 24s\n",
      "129: learn: 0.9575084\ttest: 0.9207514\tbestTest: 0.9208315 (127)\ttotal: 29.7s\tremaining: 1m 24s\n",
      "130: learn: 0.9576331\ttest: 0.9208315\tbestTest: 0.9208315 (130)\ttotal: 30.1s\tremaining: 1m 24s\n",
      "131: learn: 0.9578288\ttest: 0.9207556\tbestTest: 0.9208315 (130)\ttotal: 30.5s\tremaining: 1m 24s\n",
      "132: learn: 0.9579084\ttest: 0.9208189\tbestTest: 0.9208315 (130)\ttotal: 30.8s\tremaining: 1m 25s\n",
      "133: learn: 0.9581498\ttest: 0.9202876\tbestTest: 0.9208315 (130)\ttotal: 31.1s\tremaining: 1m 25s\n",
      "134: learn: 0.9583996\ttest: 0.9203677\tbestTest: 0.9208315 (130)\ttotal: 31.3s\tremaining: 1m 24s\n",
      "135: learn: 0.9585656\ttest: 0.9204647\tbestTest: 0.9208315 (130)\ttotal: 31.5s\tremaining: 1m 24s\n",
      "136: learn: 0.9588062\ttest: 0.9206966\tbestTest: 0.9208315 (130)\ttotal: 31.7s\tremaining: 1m 23s\n",
      "137: learn: 0.9589869\ttest: 0.921055\tbestTest: 0.921055 (137)\ttotal: 31.9s\tremaining: 1m 23s\n",
      "138: learn: 0.9591135\ttest: 0.9208568\tbestTest: 0.921055 (137)\ttotal: 32.1s\tremaining: 1m 23s\n",
      "139: learn: 0.959441\ttest: 0.9207388\tbestTest: 0.921055 (137)\ttotal: 32.3s\tremaining: 1m 23s\n",
      "140: learn: 0.9595942\ttest: 0.9207135\tbestTest: 0.921055 (137)\ttotal: 32.5s\tremaining: 1m 22s\n",
      "141: learn: 0.9598169\ttest: 0.9208652\tbestTest: 0.921055 (137)\ttotal: 32.7s\tremaining: 1m 22s\n",
      "142: learn: 0.9599974\ttest: 0.9209285\tbestTest: 0.921055 (137)\ttotal: 32.9s\tremaining: 1m 22s\n",
      "143: learn: 0.9602015\ttest: 0.9210971\tbestTest: 0.9210971 (143)\ttotal: 33.1s\tremaining: 1m 21s\n",
      "144: learn: 0.960477\ttest: 0.9210339\tbestTest: 0.9210971 (143)\ttotal: 33.4s\tremaining: 1m 21s\n",
      "145: learn: 0.9606921\ttest: 0.9210634\tbestTest: 0.9210971 (143)\ttotal: 33.6s\tremaining: 1m 21s\n",
      "146: learn: 0.9608862\ttest: 0.9209538\tbestTest: 0.9210971 (143)\ttotal: 33.8s\tremaining: 1m 21s\n",
      "147: learn: 0.9610126\ttest: 0.9210044\tbestTest: 0.9210971 (143)\ttotal: 34s\tremaining: 1m 20s\n",
      "148: learn: 0.961285\ttest: 0.9210971\tbestTest: 0.9210971 (148)\ttotal: 34.3s\tremaining: 1m 20s\n",
      "149: learn: 0.9614145\ttest: 0.9209411\tbestTest: 0.9210971 (148)\ttotal: 34.6s\tremaining: 1m 20s\n",
      "150: learn: 0.9616038\ttest: 0.9209369\tbestTest: 0.9210971 (148)\ttotal: 34.8s\tremaining: 1m 20s\n",
      "151: learn: 0.9617155\ttest: 0.9208273\tbestTest: 0.9210971 (148)\ttotal: 35s\tremaining: 1m 20s\n",
      "152: learn: 0.9619004\ttest: 0.9208779\tbestTest: 0.9210971 (148)\ttotal: 35.2s\tremaining: 1m 19s\n",
      "153: learn: 0.9622024\ttest: 0.9208863\tbestTest: 0.9210971 (148)\ttotal: 35.4s\tremaining: 1m 19s\n",
      "154: learn: 0.9625079\ttest: 0.920861\tbestTest: 0.9210971 (148)\ttotal: 35.8s\tremaining: 1m 19s\n",
      "155: learn: 0.9627732\ttest: 0.9207683\tbestTest: 0.9210971 (148)\ttotal: 36s\tremaining: 1m 19s\n",
      "156: learn: 0.9629122\ttest: 0.9208146\tbestTest: 0.9210971 (148)\ttotal: 36.1s\tremaining: 1m 18s\n",
      "157: learn: 0.963142\ttest: 0.9208652\tbestTest: 0.9210971 (148)\ttotal: 36.3s\tremaining: 1m 18s\n",
      "158: learn: 0.9633222\ttest: 0.9209116\tbestTest: 0.9210971 (148)\ttotal: 36.4s\tremaining: 1m 18s\n",
      "159: learn: 0.9635512\ttest: 0.9210718\tbestTest: 0.9210971 (148)\ttotal: 36.6s\tremaining: 1m 17s\n",
      "160: learn: 0.9636883\ttest: 0.9209959\tbestTest: 0.9210971 (148)\ttotal: 36.7s\tremaining: 1m 17s\n",
      "161: learn: 0.9639371\ttest: 0.9210676\tbestTest: 0.9210971 (148)\ttotal: 37s\tremaining: 1m 17s\n",
      "162: learn: 0.9641228\ttest: 0.9211266\tbestTest: 0.9211266 (162)\ttotal: 37.2s\tremaining: 1m 16s\n",
      "163: learn: 0.9643166\ttest: 0.9212405\tbestTest: 0.9212405 (163)\ttotal: 37.3s\tremaining: 1m 16s\n",
      "164: learn: 0.9644627\ttest: 0.9212194\tbestTest: 0.9212405 (163)\ttotal: 37.5s\tremaining: 1m 16s\n",
      "165: learn: 0.964822\ttest: 0.9211604\tbestTest: 0.9212405 (163)\ttotal: 37.7s\tremaining: 1m 15s\n",
      "166: learn: 0.9650169\ttest: 0.9210887\tbestTest: 0.9212405 (163)\ttotal: 37.9s\tremaining: 1m 15s\n",
      "167: learn: 0.9650513\ttest: 0.9211098\tbestTest: 0.9212405 (163)\ttotal: 38.2s\tremaining: 1m 15s\n",
      "168: learn: 0.965433\ttest: 0.920861\tbestTest: 0.9212405 (163)\ttotal: 38.4s\tremaining: 1m 15s\n",
      "169: learn: 0.9655569\ttest: 0.9206165\tbestTest: 0.9212405 (163)\ttotal: 38.6s\tremaining: 1m 14s\n",
      "170: learn: 0.9656318\ttest: 0.9207008\tbestTest: 0.9212405 (163)\ttotal: 38.8s\tremaining: 1m 14s\n",
      "171: learn: 0.9658354\ttest: 0.9207893\tbestTest: 0.9212405 (163)\ttotal: 39s\tremaining: 1m 14s\n",
      "172: learn: 0.9659255\ttest: 0.9210128\tbestTest: 0.9212405 (163)\ttotal: 39.4s\tremaining: 1m 14s\n",
      "173: learn: 0.9661789\ttest: 0.9210339\tbestTest: 0.9212405 (163)\ttotal: 39.5s\tremaining: 1m 14s\n",
      "174: learn: 0.9662168\ttest: 0.9210423\tbestTest: 0.9212405 (163)\ttotal: 39.7s\tremaining: 1m 13s\n",
      "175: learn: 0.9664075\ttest: 0.9208779\tbestTest: 0.9212405 (163)\ttotal: 39.9s\tremaining: 1m 13s\n",
      "176: learn: 0.9666231\ttest: 0.9209538\tbestTest: 0.9212405 (163)\ttotal: 40.1s\tremaining: 1m 13s\n",
      "177: learn: 0.9667728\ttest: 0.92092\tbestTest: 0.9212405 (163)\ttotal: 40.3s\tremaining: 1m 12s\n",
      "178: learn: 0.9669407\ttest: 0.9209959\tbestTest: 0.9212405 (163)\ttotal: 40.6s\tremaining: 1m 12s\n",
      "179: learn: 0.9671744\ttest: 0.9210718\tbestTest: 0.9212405 (163)\ttotal: 40.8s\tremaining: 1m 12s\n",
      "180: learn: 0.9676386\ttest: 0.9209496\tbestTest: 0.9212405 (163)\ttotal: 41s\tremaining: 1m 12s\n",
      "181: learn: 0.9678697\ttest: 0.9208947\tbestTest: 0.9212405 (163)\ttotal: 41.2s\tremaining: 1m 12s\n",
      "182: learn: 0.9680517\ttest: 0.9209369\tbestTest: 0.9212405 (163)\ttotal: 41.5s\tremaining: 1m 11s\n",
      "183: learn: 0.9681481\ttest: 0.9209453\tbestTest: 0.9212405 (163)\ttotal: 41.8s\tremaining: 1m 11s\n",
      "184: learn: 0.9685931\ttest: 0.9209749\tbestTest: 0.9212405 (163)\ttotal: 42.1s\tremaining: 1m 11s\n",
      "185: learn: 0.9686385\ttest: 0.9209158\tbestTest: 0.9212405 (163)\ttotal: 42.3s\tremaining: 1m 11s\n",
      "186: learn: 0.9689558\ttest: 0.9208231\tbestTest: 0.9212405 (163)\ttotal: 42.5s\tremaining: 1m 11s\n",
      "187: learn: 0.9691376\ttest: 0.9209074\tbestTest: 0.9212405 (163)\ttotal: 43s\tremaining: 1m 11s\n",
      "188: learn: 0.9693522\ttest: 0.9211646\tbestTest: 0.9212405 (163)\ttotal: 43.2s\tremaining: 1m 11s\n",
      "189: learn: 0.9695463\ttest: 0.921114\tbestTest: 0.9212405 (163)\ttotal: 43.4s\tremaining: 1m 10s\n",
      "190: learn: 0.9696435\ttest: 0.9211056\tbestTest: 0.9212405 (163)\ttotal: 43.6s\tremaining: 1m 10s\n",
      "191: learn: 0.9698121\ttest: 0.921367\tbestTest: 0.921367 (191)\ttotal: 43.8s\tremaining: 1m 10s\n",
      "192: learn: 0.9700787\ttest: 0.9213838\tbestTest: 0.9213838 (192)\ttotal: 44.2s\tremaining: 1m 10s\n",
      "193: learn: 0.9702282\ttest: 0.9214218\tbestTest: 0.9214218 (193)\ttotal: 44.4s\tremaining: 1m 9s\n",
      "194: learn: 0.9703403\ttest: 0.921367\tbestTest: 0.9214218 (193)\ttotal: 44.5s\tremaining: 1m 9s\n",
      "195: learn: 0.9705043\ttest: 0.9214934\tbestTest: 0.9214934 (195)\ttotal: 44.7s\tremaining: 1m 9s\n",
      "196: learn: 0.9708129\ttest: 0.9210971\tbestTest: 0.9214934 (195)\ttotal: 45s\tremaining: 1m 9s\n",
      "197: learn: 0.9709647\ttest: 0.9211899\tbestTest: 0.9214934 (195)\ttotal: 45.3s\tremaining: 1m 9s\n",
      "198: learn: 0.9710989\ttest: 0.9209411\tbestTest: 0.9214934 (195)\ttotal: 45.5s\tremaining: 1m 8s\n",
      "199: learn: 0.9712134\ttest: 0.9209411\tbestTest: 0.9214934 (195)\ttotal: 45.7s\tremaining: 1m 8s\n",
      "200: learn: 0.9714131\ttest: 0.920958\tbestTest: 0.9214934 (195)\ttotal: 45.9s\tremaining: 1m 8s\n",
      "201: learn: 0.9716169\ttest: 0.9207008\tbestTest: 0.9214934 (195)\ttotal: 46.1s\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202: learn: 0.9718249\ttest: 0.9207514\tbestTest: 0.9214934 (195)\ttotal: 46.5s\tremaining: 1m 8s\n",
      "203: learn: 0.9720387\ttest: 0.9208231\tbestTest: 0.9214934 (195)\ttotal: 46.7s\tremaining: 1m 7s\n",
      "204: learn: 0.9720886\ttest: 0.9208652\tbestTest: 0.9214934 (195)\ttotal: 46.9s\tremaining: 1m 7s\n",
      "205: learn: 0.9721309\ttest: 0.9208484\tbestTest: 0.9214934 (195)\ttotal: 47.1s\tremaining: 1m 7s\n",
      "206: learn: 0.972261\ttest: 0.9207345\tbestTest: 0.9214934 (195)\ttotal: 47.3s\tremaining: 1m 6s\n",
      "207: learn: 0.9723639\ttest: 0.920958\tbestTest: 0.9214934 (195)\ttotal: 47.6s\tremaining: 1m 6s\n",
      "208: learn: 0.9725076\ttest: 0.9208526\tbestTest: 0.9214934 (195)\ttotal: 47.9s\tremaining: 1m 6s\n",
      "209: learn: 0.9726497\ttest: 0.9207936\tbestTest: 0.9214934 (195)\ttotal: 48.1s\tremaining: 1m 6s\n",
      "210: learn: 0.9727648\ttest: 0.9208399\tbestTest: 0.9214934 (195)\ttotal: 48.3s\tremaining: 1m 6s\n",
      "211: learn: 0.9729226\ttest: 0.9211372\tbestTest: 0.9214934 (195)\ttotal: 48.5s\tremaining: 1m 5s\n",
      "212: learn: 0.9731543\ttest: 0.9211498\tbestTest: 0.9214934 (195)\ttotal: 48.9s\tremaining: 1m 5s\n",
      "213: learn: 0.9733137\ttest: 0.9213733\tbestTest: 0.9214934 (195)\ttotal: 49.1s\tremaining: 1m 5s\n",
      "214: learn: 0.9735409\ttest: 0.9214534\tbestTest: 0.9214934 (195)\ttotal: 49.3s\tremaining: 1m 5s\n",
      "215: learn: 0.9736591\ttest: 0.9214618\tbestTest: 0.9214934 (195)\ttotal: 49.5s\tremaining: 1m 5s\n",
      "216: learn: 0.9738658\ttest: 0.9214703\tbestTest: 0.9214934 (195)\ttotal: 49.7s\tremaining: 1m 4s\n",
      "217: learn: 0.9740988\ttest: 0.9213564\tbestTest: 0.9214934 (195)\ttotal: 50s\tremaining: 1m 4s\n",
      "218: learn: 0.974217\ttest: 0.9214365\tbestTest: 0.9214934 (195)\ttotal: 50.2s\tremaining: 1m 4s\n",
      "219: learn: 0.9743765\ttest: 0.921407\tbestTest: 0.9214934 (195)\ttotal: 50.4s\tremaining: 1m 4s\n",
      "220: learn: 0.9744282\ttest: 0.9213817\tbestTest: 0.9214934 (195)\ttotal: 50.7s\tremaining: 1m 3s\n",
      "221: learn: 0.9747765\ttest: 0.9215082\tbestTest: 0.9215082 (221)\ttotal: 50.9s\tremaining: 1m 3s\n",
      "222: learn: 0.9748997\ttest: 0.9212046\tbestTest: 0.9215082 (221)\ttotal: 51.2s\tremaining: 1m 3s\n",
      "223: learn: 0.9751117\ttest: 0.9211077\tbestTest: 0.9215082 (221)\ttotal: 51.4s\tremaining: 1m 3s\n",
      "224: learn: 0.9752756\ttest: 0.921154\tbestTest: 0.9215082 (221)\ttotal: 51.6s\tremaining: 1m 3s\n",
      "225: learn: 0.9755474\ttest: 0.9211245\tbestTest: 0.9215082 (221)\ttotal: 51.8s\tremaining: 1m 2s\n",
      "226: learn: 0.9757189\ttest: 0.9212763\tbestTest: 0.9215082 (221)\ttotal: 52s\tremaining: 1m 2s\n",
      "227: learn: 0.9759483\ttest: 0.9211583\tbestTest: 0.9215082 (221)\ttotal: 52.3s\tremaining: 1m 2s\n",
      "228: learn: 0.9760089\ttest: 0.9211245\tbestTest: 0.9215082 (221)\ttotal: 52.5s\tremaining: 1m 2s\n",
      "229: learn: 0.9762196\ttest: 0.9210233\tbestTest: 0.9215082 (221)\ttotal: 52.6s\tremaining: 1m 1s\n",
      "230: learn: 0.9763725\ttest: 0.9208041\tbestTest: 0.9215082 (221)\ttotal: 52.8s\tremaining: 1m 1s\n",
      "231: learn: 0.9766191\ttest: 0.9208926\tbestTest: 0.9215082 (221)\ttotal: 53s\tremaining: 1m 1s\n",
      "232: learn: 0.976763\ttest: 0.9209643\tbestTest: 0.9215082 (221)\ttotal: 53.2s\tremaining: 1m 1s\n",
      "233: learn: 0.976896\ttest: 0.9210866\tbestTest: 0.9215082 (221)\ttotal: 53.6s\tremaining: 1m\n",
      "234: learn: 0.9769149\ttest: 0.920998\tbestTest: 0.9215082 (221)\ttotal: 53.8s\tremaining: 1m\n",
      "235: learn: 0.977182\ttest: 0.9211793\tbestTest: 0.9215082 (221)\ttotal: 54s\tremaining: 1m\n",
      "236: learn: 0.9773086\ttest: 0.9210866\tbestTest: 0.9215082 (221)\ttotal: 54.2s\tremaining: 1m\n",
      "237: learn: 0.9775936\ttest: 0.9211878\tbestTest: 0.9215082 (221)\ttotal: 54.4s\tremaining: 59.9s\n",
      "238: learn: 0.9778119\ttest: 0.9211456\tbestTest: 0.9215082 (221)\ttotal: 54.8s\tremaining: 59.8s\n",
      "239: learn: 0.9778718\ttest: 0.9214154\tbestTest: 0.9215082 (221)\ttotal: 55s\tremaining: 59.6s\n",
      "240: learn: 0.9780312\ttest: 0.9213859\tbestTest: 0.9215082 (221)\ttotal: 55.2s\tremaining: 59.4s\n",
      "241: learn: 0.9781959\ttest: 0.9213733\tbestTest: 0.9215082 (221)\ttotal: 55.4s\tremaining: 59.1s\n",
      "242: learn: 0.9783635\ttest: 0.921504\tbestTest: 0.9215082 (221)\ttotal: 55.7s\tremaining: 58.9s\n",
      "243: learn: 0.9784328\ttest: 0.9213859\tbestTest: 0.9215082 (221)\ttotal: 56s\tremaining: 58.8s\n",
      "244: learn: 0.9785352\ttest: 0.9213859\tbestTest: 0.9215082 (221)\ttotal: 56.2s\tremaining: 58.5s\n",
      "245: learn: 0.9787422\ttest: 0.9212932\tbestTest: 0.9215082 (221)\ttotal: 56.5s\tremaining: 58.3s\n",
      "246: learn: 0.9787911\ttest: 0.9213227\tbestTest: 0.9215082 (221)\ttotal: 56.7s\tremaining: 58.1s\n",
      "247: learn: 0.9788914\ttest: 0.921348\tbestTest: 0.9215082 (221)\ttotal: 56.8s\tremaining: 57.7s\n",
      "248: learn: 0.9789755\ttest: 0.921407\tbestTest: 0.9215082 (221)\ttotal: 57.1s\tremaining: 57.6s\n",
      "249: learn: 0.9791383\ttest: 0.9210739\tbestTest: 0.9215082 (221)\ttotal: 57.3s\tremaining: 57.3s\n",
      "250: learn: 0.9792226\ttest: 0.9212805\tbestTest: 0.9215082 (221)\ttotal: 57.5s\tremaining: 57s\n",
      "251: learn: 0.9793414\ttest: 0.9213522\tbestTest: 0.9215082 (221)\ttotal: 57.7s\tremaining: 56.8s\n",
      "252: learn: 0.9794866\ttest: 0.9212426\tbestTest: 0.9215082 (221)\ttotal: 57.9s\tremaining: 56.5s\n",
      "253: learn: 0.9797128\ttest: 0.92131\tbestTest: 0.9215082 (221)\ttotal: 58.6s\tremaining: 56.7s\n",
      "254: learn: 0.9797937\ttest: 0.9212721\tbestTest: 0.9215082 (221)\ttotal: 58.7s\tremaining: 56.4s\n",
      "255: learn: 0.9799129\ttest: 0.9212299\tbestTest: 0.9215082 (221)\ttotal: 58.9s\tremaining: 56.2s\n",
      "256: learn: 0.9801083\ttest: 0.9213859\tbestTest: 0.9215082 (221)\ttotal: 59.1s\tremaining: 55.9s\n",
      "257: learn: 0.9801982\ttest: 0.9215588\tbestTest: 0.9215588 (257)\ttotal: 59.5s\tremaining: 55.8s\n",
      "258: learn: 0.9802956\ttest: 0.9216305\tbestTest: 0.9216305 (258)\ttotal: 59.7s\tremaining: 55.6s\n",
      "259: learn: 0.9804222\ttest: 0.9216515\tbestTest: 0.9216515 (259)\ttotal: 60s\tremaining: 55.3s\n",
      "260: learn: 0.9805796\ttest: 0.9215546\tbestTest: 0.9216515 (259)\ttotal: 1m\tremaining: 55.1s\n",
      "261: learn: 0.9806946\ttest: 0.921601\tbestTest: 0.9216515 (259)\ttotal: 1m\tremaining: 54.9s\n",
      "262: learn: 0.9808766\ttest: 0.9214239\tbestTest: 0.9216515 (259)\ttotal: 1m\tremaining: 54.8s\n",
      "263: learn: 0.9809247\ttest: 0.9214787\tbestTest: 0.9216515 (259)\ttotal: 1m\tremaining: 54.5s\n",
      "264: learn: 0.980999\ttest: 0.9213817\tbestTest: 0.9216515 (259)\ttotal: 1m 1s\tremaining: 54.3s\n",
      "265: learn: 0.9811144\ttest: 0.9214365\tbestTest: 0.9216515 (259)\ttotal: 1m 1s\tremaining: 54s\n",
      "266: learn: 0.9812402\ttest: 0.9216347\tbestTest: 0.9216515 (259)\ttotal: 1m 1s\tremaining: 53.7s\n",
      "267: learn: 0.981258\ttest: 0.9216979\tbestTest: 0.9216979 (267)\ttotal: 1m 1s\tremaining: 53.6s\n",
      "268: learn: 0.9814803\ttest: 0.9217865\tbestTest: 0.9217865 (268)\ttotal: 1m 2s\tremaining: 53.4s\n",
      "269: learn: 0.9816032\ttest: 0.9216979\tbestTest: 0.9217865 (268)\ttotal: 1m 2s\tremaining: 53.1s\n",
      "270: learn: 0.9817616\ttest: 0.9217738\tbestTest: 0.9217865 (268)\ttotal: 1m 2s\tremaining: 52.9s\n",
      "271: learn: 0.9818987\ttest: 0.921719\tbestTest: 0.9217865 (268)\ttotal: 1m 2s\tremaining: 52.6s\n",
      "272: learn: 0.9819394\ttest: 0.9219087\tbestTest: 0.9219087 (272)\ttotal: 1m 3s\tremaining: 52.5s\n",
      "273: learn: 0.9820712\ttest: 0.9219425\tbestTest: 0.9219425 (273)\ttotal: 1m 3s\tremaining: 52.3s\n",
      "274: learn: 0.9822433\ttest: 0.9219973\tbestTest: 0.9219973 (274)\ttotal: 1m 3s\tremaining: 52.2s\n",
      "275: learn: 0.9822714\ttest: 0.9219298\tbestTest: 0.9219973 (274)\ttotal: 1m 4s\tremaining: 52.1s\n",
      "276: learn: 0.9824316\ttest: 0.9219804\tbestTest: 0.9219973 (274)\ttotal: 1m 4s\tremaining: 52s\n",
      "277: learn: 0.9825165\ttest: 0.92209\tbestTest: 0.92209 (277)\ttotal: 1m 4s\tremaining: 51.9s\n",
      "278: learn: 0.9826749\ttest: 0.9220689\tbestTest: 0.92209 (277)\ttotal: 1m 5s\tremaining: 51.7s\n",
      "279: learn: 0.9828971\ttest: 0.9221996\tbestTest: 0.9221996 (279)\ttotal: 1m 5s\tremaining: 51.5s\n",
      "280: learn: 0.9829977\ttest: 0.9221575\tbestTest: 0.9221996 (279)\ttotal: 1m 5s\tremaining: 51.2s\n",
      "281: learn: 0.983051\ttest: 0.9221912\tbestTest: 0.9221996 (279)\ttotal: 1m 5s\tremaining: 50.9s\n",
      "282: learn: 0.9831763\ttest: 0.9219172\tbestTest: 0.9221996 (279)\ttotal: 1m 6s\tremaining: 50.7s\n",
      "283: learn: 0.9833102\ttest: 0.9220479\tbestTest: 0.9221996 (279)\ttotal: 1m 6s\tremaining: 50.4s\n",
      "284: learn: 0.9834823\ttest: 0.9219256\tbestTest: 0.9221996 (279)\ttotal: 1m 6s\tremaining: 50.1s\n",
      "285: learn: 0.9836554\ttest: 0.9218202\tbestTest: 0.9221996 (279)\ttotal: 1m 6s\tremaining: 49.9s\n",
      "286: learn: 0.983746\ttest: 0.9218792\tbestTest: 0.9221996 (279)\ttotal: 1m 6s\tremaining: 49.6s\n",
      "287: learn: 0.9838353\ttest: 0.9218961\tbestTest: 0.9221996 (279)\ttotal: 1m 7s\tremaining: 49.3s\n",
      "288: learn: 0.9840173\ttest: 0.9216768\tbestTest: 0.9221996 (279)\ttotal: 1m 7s\tremaining: 49.1s\n",
      "289: learn: 0.9840961\ttest: 0.9215967\tbestTest: 0.9221996 (279)\ttotal: 1m 7s\tremaining: 48.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290: learn: 0.9842587\ttest: 0.9214703\tbestTest: 0.9221996 (279)\ttotal: 1m 7s\tremaining: 48.6s\n",
      "291: learn: 0.9843704\ttest: 0.9216178\tbestTest: 0.9221996 (279)\ttotal: 1m 7s\tremaining: 48.3s\n",
      "292: learn: 0.9844878\ttest: 0.9216431\tbestTest: 0.9221996 (279)\ttotal: 1m 8s\tremaining: 48.1s\n",
      "293: learn: 0.9846357\ttest: 0.9215504\tbestTest: 0.9221996 (279)\ttotal: 1m 8s\tremaining: 47.8s\n",
      "294: learn: 0.984803\ttest: 0.9215377\tbestTest: 0.9221996 (279)\ttotal: 1m 8s\tremaining: 47.6s\n",
      "295: learn: 0.9849012\ttest: 0.9215208\tbestTest: 0.9221996 (279)\ttotal: 1m 8s\tremaining: 47.4s\n",
      "296: learn: 0.9849966\ttest: 0.9215799\tbestTest: 0.9221996 (279)\ttotal: 1m 8s\tremaining: 47.1s\n",
      "297: learn: 0.9851612\ttest: 0.9214998\tbestTest: 0.9221996 (279)\ttotal: 1m 9s\tremaining: 46.9s\n",
      "298: learn: 0.9853614\ttest: 0.9213606\tbestTest: 0.9221996 (279)\ttotal: 1m 9s\tremaining: 46.6s\n",
      "299: learn: 0.98555\ttest: 0.9216684\tbestTest: 0.9221996 (279)\ttotal: 1m 9s\tremaining: 46.4s\n",
      "300: learn: 0.9856343\ttest: 0.921601\tbestTest: 0.9221996 (279)\ttotal: 1m 9s\tremaining: 46.2s\n",
      "301: learn: 0.9858544\ttest: 0.9216052\tbestTest: 0.9221996 (279)\ttotal: 1m 10s\tremaining: 45.9s\n",
      "302: learn: 0.9859634\ttest: 0.9214492\tbestTest: 0.9221996 (279)\ttotal: 1m 10s\tremaining: 45.7s\n",
      "303: learn: 0.9860546\ttest: 0.9214871\tbestTest: 0.9221996 (279)\ttotal: 1m 10s\tremaining: 45.4s\n",
      "304: learn: 0.9861673\ttest: 0.921601\tbestTest: 0.9221996 (279)\ttotal: 1m 10s\tremaining: 45.2s\n",
      "305: learn: 0.9862839\ttest: 0.9215293\tbestTest: 0.9221996 (279)\ttotal: 1m 10s\tremaining: 44.9s\n",
      "306: learn: 0.9863787\ttest: 0.9216811\tbestTest: 0.9221996 (279)\ttotal: 1m 11s\tremaining: 44.7s\n",
      "307: learn: 0.9864231\ttest: 0.9215166\tbestTest: 0.9221996 (279)\ttotal: 1m 11s\tremaining: 44.4s\n",
      "308: learn: 0.9865447\ttest: 0.9214618\tbestTest: 0.9221996 (279)\ttotal: 1m 11s\tremaining: 44.2s\n",
      "309: learn: 0.9866148\ttest: 0.9214913\tbestTest: 0.9221996 (279)\ttotal: 1m 11s\tremaining: 43.9s\n",
      "310: learn: 0.9867057\ttest: 0.9214323\tbestTest: 0.9221996 (279)\ttotal: 1m 11s\tremaining: 43.7s\n",
      "311: learn: 0.9867236\ttest: 0.9214576\tbestTest: 0.9221996 (279)\ttotal: 1m 12s\tremaining: 43.5s\n",
      "312: learn: 0.9868047\ttest: 0.9212552\tbestTest: 0.9221996 (279)\ttotal: 1m 12s\tremaining: 43.2s\n",
      "313: learn: 0.986795\ttest: 0.9212552\tbestTest: 0.9221996 (279)\ttotal: 1m 12s\tremaining: 43s\n",
      "314: learn: 0.9869185\ttest: 0.9212089\tbestTest: 0.9221996 (279)\ttotal: 1m 12s\tremaining: 42.7s\n",
      "315: learn: 0.9870564\ttest: 0.9213691\tbestTest: 0.9221996 (279)\ttotal: 1m 12s\tremaining: 42.5s\n",
      "316: learn: 0.9871113\ttest: 0.9214534\tbestTest: 0.9221996 (279)\ttotal: 1m 13s\tremaining: 42.2s\n",
      "317: learn: 0.9871958\ttest: 0.921504\tbestTest: 0.9221996 (279)\ttotal: 1m 13s\tremaining: 42s\n",
      "318: learn: 0.98725\ttest: 0.9214998\tbestTest: 0.9221996 (279)\ttotal: 1m 13s\tremaining: 41.8s\n",
      "319: learn: 0.9873464\ttest: 0.9216389\tbestTest: 0.9221996 (279)\ttotal: 1m 13s\tremaining: 41.5s\n",
      "320: learn: 0.9874829\ttest: 0.9215377\tbestTest: 0.9221996 (279)\ttotal: 1m 14s\tremaining: 41.3s\n",
      "321: learn: 0.9875163\ttest: 0.9215546\tbestTest: 0.9221996 (279)\ttotal: 1m 14s\tremaining: 41.1s\n",
      "322: learn: 0.9876119\ttest: 0.9216515\tbestTest: 0.9221996 (279)\ttotal: 1m 14s\tremaining: 40.9s\n",
      "323: learn: 0.9876518\ttest: 0.9217527\tbestTest: 0.9221996 (279)\ttotal: 1m 14s\tremaining: 40.6s\n",
      "324: learn: 0.9877682\ttest: 0.9217359\tbestTest: 0.9221996 (279)\ttotal: 1m 14s\tremaining: 40.4s\n",
      "325: learn: 0.987801\ttest: 0.9216811\tbestTest: 0.9221996 (279)\ttotal: 1m 15s\tremaining: 40.1s\n",
      "326: learn: 0.9879626\ttest: 0.921601\tbestTest: 0.9221996 (279)\ttotal: 1m 15s\tremaining: 40s\n",
      "327: learn: 0.9879986\ttest: 0.9217485\tbestTest: 0.9221996 (279)\ttotal: 1m 15s\tremaining: 39.7s\n",
      "328: learn: 0.9880301\ttest: 0.9217738\tbestTest: 0.9221996 (279)\ttotal: 1m 15s\tremaining: 39.5s\n",
      "329: learn: 0.9880443\ttest: 0.921816\tbestTest: 0.9221996 (279)\ttotal: 1m 16s\tremaining: 39.2s\n",
      "330: learn: 0.988106\ttest: 0.9217443\tbestTest: 0.9221996 (279)\ttotal: 1m 16s\tremaining: 39s\n",
      "331: learn: 0.988195\ttest: 0.9217401\tbestTest: 0.9221996 (279)\ttotal: 1m 16s\tremaining: 38.8s\n",
      "332: learn: 0.9882139\ttest: 0.9217865\tbestTest: 0.9221996 (279)\ttotal: 1m 16s\tremaining: 38.6s\n",
      "333: learn: 0.9882575\ttest: 0.9218202\tbestTest: 0.9221996 (279)\ttotal: 1m 17s\tremaining: 38.4s\n",
      "334: learn: 0.9883595\ttest: 0.9218792\tbestTest: 0.9221996 (279)\ttotal: 1m 17s\tremaining: 38.1s\n",
      "335: learn: 0.988401\ttest: 0.9217401\tbestTest: 0.9221996 (279)\ttotal: 1m 17s\tremaining: 37.9s\n",
      "336: learn: 0.9885118\ttest: 0.9218708\tbestTest: 0.9221996 (279)\ttotal: 1m 17s\tremaining: 37.7s\n",
      "337: learn: 0.9886195\ttest: 0.9217991\tbestTest: 0.9221996 (279)\ttotal: 1m 18s\tremaining: 37.5s\n",
      "338: learn: 0.9886825\ttest: 0.9217822\tbestTest: 0.9221996 (279)\ttotal: 1m 18s\tremaining: 37.2s\n",
      "339: learn: 0.9887051\ttest: 0.9218075\tbestTest: 0.9221996 (279)\ttotal: 1m 18s\tremaining: 37s\n",
      "340: learn: 0.9888927\ttest: 0.9218244\tbestTest: 0.9221996 (279)\ttotal: 1m 18s\tremaining: 36.8s\n",
      "341: learn: 0.988966\ttest: 0.9217569\tbestTest: 0.9221996 (279)\ttotal: 1m 19s\tremaining: 36.6s\n",
      "342: learn: 0.9890652\ttest: 0.9217317\tbestTest: 0.9221996 (279)\ttotal: 1m 19s\tremaining: 36.3s\n",
      "343: learn: 0.9891272\ttest: 0.9218244\tbestTest: 0.9221996 (279)\ttotal: 1m 19s\tremaining: 36.1s\n",
      "344: learn: 0.989159\ttest: 0.9217991\tbestTest: 0.9221996 (279)\ttotal: 1m 19s\tremaining: 35.8s\n",
      "345: learn: 0.989252\ttest: 0.9218033\tbestTest: 0.9221996 (279)\ttotal: 1m 19s\tremaining: 35.6s\n",
      "346: learn: 0.9893108\ttest: 0.9218539\tbestTest: 0.9221996 (279)\ttotal: 1m 20s\tremaining: 35.4s\n",
      "347: learn: 0.9894511\ttest: 0.9216684\tbestTest: 0.9221996 (279)\ttotal: 1m 20s\tremaining: 35.2s\n",
      "348: learn: 0.9895241\ttest: 0.921719\tbestTest: 0.9221996 (279)\ttotal: 1m 20s\tremaining: 34.9s\n",
      "349: learn: 0.9896231\ttest: 0.9217443\tbestTest: 0.9221996 (279)\ttotal: 1m 20s\tremaining: 34.7s\n",
      "350: learn: 0.9897256\ttest: 0.9218202\tbestTest: 0.9221996 (279)\ttotal: 1m 21s\tremaining: 34.5s\n",
      "351: learn: 0.9898401\ttest: 0.9216853\tbestTest: 0.9221996 (279)\ttotal: 1m 21s\tremaining: 34.3s\n",
      "352: learn: 0.9899184\ttest: 0.9217654\tbestTest: 0.9221996 (279)\ttotal: 1m 21s\tremaining: 34.1s\n",
      "353: learn: 0.9899735\ttest: 0.9216726\tbestTest: 0.9221996 (279)\ttotal: 1m 22s\tremaining: 33.8s\n",
      "354: learn: 0.9900405\ttest: 0.9216684\tbestTest: 0.9221996 (279)\ttotal: 1m 22s\tremaining: 33.6s\n",
      "355: learn: 0.9900776\ttest: 0.9217064\tbestTest: 0.9221996 (279)\ttotal: 1m 22s\tremaining: 33.3s\n",
      "356: learn: 0.9901889\ttest: 0.9216178\tbestTest: 0.9221996 (279)\ttotal: 1m 22s\tremaining: 33.2s\n",
      "357: learn: 0.9902422\ttest: 0.9216262\tbestTest: 0.9221996 (279)\ttotal: 1m 23s\tremaining: 32.9s\n",
      "358: learn: 0.9903213\ttest: 0.9215799\tbestTest: 0.9221996 (279)\ttotal: 1m 23s\tremaining: 32.7s\n",
      "359: learn: 0.990372\ttest: 0.9216136\tbestTest: 0.9221996 (279)\ttotal: 1m 23s\tremaining: 32.4s\n",
      "360: learn: 0.990532\ttest: 0.921622\tbestTest: 0.9221996 (279)\ttotal: 1m 23s\tremaining: 32.2s\n",
      "361: learn: 0.990564\ttest: 0.9217148\tbestTest: 0.9221996 (279)\ttotal: 1m 23s\tremaining: 32s\n",
      "362: learn: 0.990677\ttest: 0.9219931\tbestTest: 0.9221996 (279)\ttotal: 1m 24s\tremaining: 31.7s\n",
      "363: learn: 0.990766\ttest: 0.9219931\tbestTest: 0.9221996 (279)\ttotal: 1m 24s\tremaining: 31.5s\n",
      "364: learn: 0.9907849\ttest: 0.9219973\tbestTest: 0.9221996 (279)\ttotal: 1m 24s\tremaining: 31.3s\n",
      "365: learn: 0.9908109\ttest: 0.9219804\tbestTest: 0.9221996 (279)\ttotal: 1m 24s\tremaining: 31s\n",
      "366: learn: 0.9908511\ttest: 0.9220352\tbestTest: 0.9221996 (279)\ttotal: 1m 25s\tremaining: 30.8s\n",
      "367: learn: 0.9909575\ttest: 0.9220732\tbestTest: 0.9221996 (279)\ttotal: 1m 25s\tremaining: 30.6s\n",
      "368: learn: 0.9910276\ttest: 0.9221111\tbestTest: 0.9221996 (279)\ttotal: 1m 25s\tremaining: 30.3s\n",
      "369: learn: 0.9910909\ttest: 0.9222039\tbestTest: 0.9222039 (369)\ttotal: 1m 25s\tremaining: 30.1s\n",
      "370: learn: 0.991129\ttest: 0.9222334\tbestTest: 0.9222334 (370)\ttotal: 1m 25s\tremaining: 29.9s\n",
      "371: learn: 0.9911978\ttest: 0.922149\tbestTest: 0.9222334 (370)\ttotal: 1m 26s\tremaining: 29.7s\n",
      "372: learn: 0.9912222\ttest: 0.9222123\tbestTest: 0.9222334 (370)\ttotal: 1m 26s\tremaining: 29.4s\n",
      "373: learn: 0.9912819\ttest: 0.9221406\tbestTest: 0.9222334 (370)\ttotal: 1m 26s\tremaining: 29.2s\n",
      "374: learn: 0.9913457\ttest: 0.9221322\tbestTest: 0.9222334 (370)\ttotal: 1m 26s\tremaining: 29s\n",
      "375: learn: 0.9913599\ttest: 0.9222165\tbestTest: 0.9222334 (370)\ttotal: 1m 27s\tremaining: 28.7s\n",
      "376: learn: 0.9914413\ttest: 0.9223346\tbestTest: 0.9223346 (376)\ttotal: 1m 27s\tremaining: 28.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377: learn: 0.9915298\ttest: 0.9223978\tbestTest: 0.9223978 (377)\ttotal: 1m 27s\tremaining: 28.3s\n",
      "378: learn: 0.9915682\ttest: 0.9225159\tbestTest: 0.9225159 (378)\ttotal: 1m 27s\tremaining: 28.1s\n",
      "379: learn: 0.9916191\ttest: 0.9222924\tbestTest: 0.9225159 (378)\ttotal: 1m 28s\tremaining: 27.8s\n",
      "380: learn: 0.9917229\ttest: 0.9223683\tbestTest: 0.9225159 (378)\ttotal: 1m 28s\tremaining: 27.6s\n",
      "381: learn: 0.9918353\ttest: 0.9222755\tbestTest: 0.9225159 (378)\ttotal: 1m 28s\tremaining: 27.5s\n",
      "382: learn: 0.9918781\ttest: 0.9222334\tbestTest: 0.9225159 (378)\ttotal: 1m 29s\tremaining: 27.2s\n",
      "383: learn: 0.9919262\ttest: 0.9223894\tbestTest: 0.9225159 (378)\ttotal: 1m 29s\tremaining: 27s\n",
      "384: learn: 0.9919498\ttest: 0.9224484\tbestTest: 0.9225159 (378)\ttotal: 1m 29s\tremaining: 26.7s\n",
      "385: learn: 0.9919929\ttest: 0.922305\tbestTest: 0.9225159 (378)\ttotal: 1m 29s\tremaining: 26.5s\n",
      "386: learn: 0.9920714\ttest: 0.9222924\tbestTest: 0.9225159 (378)\ttotal: 1m 30s\tremaining: 26.3s\n",
      "387: learn: 0.9920948\ttest: 0.9223093\tbestTest: 0.9225159 (378)\ttotal: 1m 30s\tremaining: 26.1s\n",
      "388: learn: 0.9922017\ttest: 0.9223346\tbestTest: 0.9225159 (378)\ttotal: 1m 30s\tremaining: 25.8s\n",
      "389: learn: 0.992239\ttest: 0.9224357\tbestTest: 0.9225159 (378)\ttotal: 1m 30s\tremaining: 25.6s\n",
      "390: learn: 0.9922684\ttest: 0.9225116\tbestTest: 0.9225159 (378)\ttotal: 1m 31s\tremaining: 25.4s\n",
      "391: learn: 0.9923099\ttest: 0.9224315\tbestTest: 0.9225159 (378)\ttotal: 1m 31s\tremaining: 25.1s\n",
      "392: learn: 0.9923591\ttest: 0.9224526\tbestTest: 0.9225159 (378)\ttotal: 1m 31s\tremaining: 24.9s\n",
      "393: learn: 0.9923759\ttest: 0.9224315\tbestTest: 0.9225159 (378)\ttotal: 1m 31s\tremaining: 24.7s\n",
      "394: learn: 0.9924481\ttest: 0.9224821\tbestTest: 0.9225159 (378)\ttotal: 1m 31s\tremaining: 24.4s\n",
      "395: learn: 0.9925592\ttest: 0.9225201\tbestTest: 0.9225201 (395)\ttotal: 1m 32s\tremaining: 24.2s\n",
      "396: learn: 0.9926304\ttest: 0.9224948\tbestTest: 0.9225201 (395)\ttotal: 1m 32s\tremaining: 24s\n",
      "397: learn: 0.9926819\ttest: 0.9224779\tbestTest: 0.9225201 (395)\ttotal: 1m 32s\tremaining: 23.8s\n",
      "398: learn: 0.9926997\ttest: 0.9224821\tbestTest: 0.9225201 (395)\ttotal: 1m 33s\tremaining: 23.6s\n",
      "399: learn: 0.9927462\ttest: 0.922499\tbestTest: 0.9225201 (395)\ttotal: 1m 33s\tremaining: 23.4s\n",
      "400: learn: 0.9928258\ttest: 0.9224948\tbestTest: 0.9225201 (395)\ttotal: 1m 34s\tremaining: 23.2s\n",
      "401: learn: 0.9928896\ttest: 0.9223809\tbestTest: 0.9225201 (395)\ttotal: 1m 34s\tremaining: 23s\n",
      "402: learn: 0.9929443\ttest: 0.9223388\tbestTest: 0.9225201 (395)\ttotal: 1m 34s\tremaining: 22.8s\n",
      "403: learn: 0.9929797\ttest: 0.922305\tbestTest: 0.9225201 (395)\ttotal: 1m 35s\tremaining: 22.6s\n",
      "404: learn: 0.9930291\ttest: 0.9223135\tbestTest: 0.9225201 (395)\ttotal: 1m 35s\tremaining: 22.4s\n",
      "405: learn: 0.9930373\ttest: 0.9223683\tbestTest: 0.9225201 (395)\ttotal: 1m 35s\tremaining: 22.2s\n",
      "406: learn: 0.9930538\ttest: 0.9223472\tbestTest: 0.9225201 (395)\ttotal: 1m 36s\tremaining: 22s\n",
      "407: learn: 0.9931205\ttest: 0.9224062\tbestTest: 0.9225201 (395)\ttotal: 1m 36s\tremaining: 21.8s\n",
      "408: learn: 0.9932022\ttest: 0.9224442\tbestTest: 0.9225201 (395)\ttotal: 1m 37s\tremaining: 21.6s\n",
      "409: learn: 0.9932766\ttest: 0.9224821\tbestTest: 0.9225201 (395)\ttotal: 1m 37s\tremaining: 21.4s\n",
      "410: learn: 0.9933026\ttest: 0.9225285\tbestTest: 0.9225285 (410)\ttotal: 1m 37s\tremaining: 21.2s\n",
      "411: learn: 0.9933569\ttest: 0.9225243\tbestTest: 0.9225285 (410)\ttotal: 1m 38s\tremaining: 20.9s\n",
      "412: learn: 0.9933567\ttest: 0.9226887\tbestTest: 0.9226887 (412)\ttotal: 1m 38s\tremaining: 20.7s\n",
      "413: learn: 0.9933832\ttest: 0.9227267\tbestTest: 0.9227267 (413)\ttotal: 1m 38s\tremaining: 20.4s\n",
      "414: learn: 0.9934439\ttest: 0.9226803\tbestTest: 0.9227267 (413)\ttotal: 1m 38s\tremaining: 20.2s\n",
      "415: learn: 0.9934644\ttest: 0.9226086\tbestTest: 0.9227267 (413)\ttotal: 1m 38s\tremaining: 20s\n",
      "416: learn: 0.9935369\ttest: 0.9227224\tbestTest: 0.9227267 (413)\ttotal: 1m 39s\tremaining: 19.7s\n",
      "417: learn: 0.993591\ttest: 0.9227773\tbestTest: 0.9227773 (417)\ttotal: 1m 39s\tremaining: 19.5s\n",
      "418: learn: 0.9936317\ttest: 0.9227309\tbestTest: 0.9227773 (417)\ttotal: 1m 39s\tremaining: 19.3s\n",
      "419: learn: 0.9936269\ttest: 0.9225707\tbestTest: 0.9227773 (417)\ttotal: 1m 39s\tremaining: 19s\n",
      "420: learn: 0.9936713\ttest: 0.9225875\tbestTest: 0.9227773 (417)\ttotal: 1m 40s\tremaining: 18.8s\n",
      "421: learn: 0.9937023\ttest: 0.9225411\tbestTest: 0.9227773 (417)\ttotal: 1m 40s\tremaining: 18.6s\n",
      "422: learn: 0.9937606\ttest: 0.9225664\tbestTest: 0.9227773 (417)\ttotal: 1m 40s\tremaining: 18.3s\n",
      "423: learn: 0.9938184\ttest: 0.9227562\tbestTest: 0.9227773 (417)\ttotal: 1m 40s\tremaining: 18.1s\n",
      "424: learn: 0.9938704\ttest: 0.9227351\tbestTest: 0.9227773 (417)\ttotal: 1m 40s\tremaining: 17.8s\n",
      "425: learn: 0.9939379\ttest: 0.9227899\tbestTest: 0.9227899 (425)\ttotal: 1m 41s\tremaining: 17.6s\n",
      "426: learn: 0.9940036\ttest: 0.9227815\tbestTest: 0.9227899 (425)\ttotal: 1m 41s\tremaining: 17.4s\n",
      "427: learn: 0.9940425\ttest: 0.9226887\tbestTest: 0.9227899 (425)\ttotal: 1m 41s\tremaining: 17.1s\n",
      "428: learn: 0.9940793\ttest: 0.922596\tbestTest: 0.9227899 (425)\ttotal: 1m 41s\tremaining: 16.9s\n",
      "429: learn: 0.9941116\ttest: 0.9226634\tbestTest: 0.9227899 (425)\ttotal: 1m 42s\tremaining: 16.6s\n",
      "430: learn: 0.9941825\ttest: 0.9227435\tbestTest: 0.9227899 (425)\ttotal: 1m 42s\tremaining: 16.4s\n",
      "431: learn: 0.9942589\ttest: 0.9227815\tbestTest: 0.9227899 (425)\ttotal: 1m 42s\tremaining: 16.2s\n",
      "432: learn: 0.9942991\ttest: 0.9227983\tbestTest: 0.9227983 (432)\ttotal: 1m 42s\tremaining: 15.9s\n",
      "433: learn: 0.9943164\ttest: 0.9226676\tbestTest: 0.9227983 (432)\ttotal: 1m 43s\tremaining: 15.7s\n",
      "434: learn: 0.9943685\ttest: 0.9226761\tbestTest: 0.9227983 (432)\ttotal: 1m 43s\tremaining: 15.4s\n",
      "435: learn: 0.9944157\ttest: 0.9224526\tbestTest: 0.9227983 (432)\ttotal: 1m 43s\tremaining: 15.2s\n",
      "436: learn: 0.9944399\ttest: 0.9224568\tbestTest: 0.9227983 (432)\ttotal: 1m 43s\tremaining: 15s\n",
      "437: learn: 0.9945255\ttest: 0.9224442\tbestTest: 0.9227983 (432)\ttotal: 1m 44s\tremaining: 14.7s\n",
      "438: learn: 0.9946009\ttest: 0.9224273\tbestTest: 0.9227983 (432)\ttotal: 1m 44s\tremaining: 14.5s\n",
      "439: learn: 0.9946613\ttest: 0.9225369\tbestTest: 0.9227983 (432)\ttotal: 1m 44s\tremaining: 14.3s\n",
      "440: learn: 0.9946978\ttest: 0.9225285\tbestTest: 0.9227983 (432)\ttotal: 1m 44s\tremaining: 14s\n",
      "441: learn: 0.9947265\ttest: 0.9225622\tbestTest: 0.9227983 (432)\ttotal: 1m 45s\tremaining: 13.8s\n",
      "442: learn: 0.9947472\ttest: 0.9226339\tbestTest: 0.9227983 (432)\ttotal: 1m 45s\tremaining: 13.6s\n",
      "443: learn: 0.9947829\ttest: 0.9227056\tbestTest: 0.9227983 (432)\ttotal: 1m 45s\tremaining: 13.3s\n",
      "444: learn: 0.9948699\ttest: 0.9228236\tbestTest: 0.9228236 (444)\ttotal: 1m 45s\tremaining: 13.1s\n",
      "445: learn: 0.9949253\ttest: 0.9228068\tbestTest: 0.9228236 (444)\ttotal: 1m 46s\tremaining: 12.8s\n",
      "446: learn: 0.9949849\ttest: 0.9228194\tbestTest: 0.9228236 (444)\ttotal: 1m 46s\tremaining: 12.6s\n",
      "447: learn: 0.9950222\ttest: 0.92287\tbestTest: 0.92287 (447)\ttotal: 1m 46s\tremaining: 12.4s\n",
      "448: learn: 0.9950495\ttest: 0.9229965\tbestTest: 0.9229965 (448)\ttotal: 1m 46s\tremaining: 12.1s\n",
      "449: learn: 0.9951391\ttest: 0.9230007\tbestTest: 0.9230007 (449)\ttotal: 1m 46s\tremaining: 11.9s\n",
      "450: learn: 0.9952171\ttest: 0.9228784\tbestTest: 0.9230007 (449)\ttotal: 1m 47s\tremaining: 11.7s\n",
      "451: learn: 0.99525\ttest: 0.9229206\tbestTest: 0.9230007 (449)\ttotal: 1m 47s\tremaining: 11.4s\n",
      "452: learn: 0.9952896\ttest: 0.9229838\tbestTest: 0.9230007 (449)\ttotal: 1m 47s\tremaining: 11.2s\n",
      "453: learn: 0.9953088\ttest: 0.9228489\tbestTest: 0.9230007 (449)\ttotal: 1m 47s\tremaining: 10.9s\n",
      "454: learn: 0.9953185\ttest: 0.9228194\tbestTest: 0.9230007 (449)\ttotal: 1m 48s\tremaining: 10.7s\n",
      "455: learn: 0.9953957\ttest: 0.9228531\tbestTest: 0.9230007 (449)\ttotal: 1m 48s\tremaining: 10.5s\n",
      "456: learn: 0.9954814\ttest: 0.9228616\tbestTest: 0.9230007 (449)\ttotal: 1m 48s\tremaining: 10.2s\n",
      "457: learn: 0.995546\ttest: 0.9228194\tbestTest: 0.9230007 (449)\ttotal: 1m 48s\tremaining: 9.99s\n",
      "458: learn: 0.9955683\ttest: 0.9228236\tbestTest: 0.9230007 (449)\ttotal: 1m 49s\tremaining: 9.75s\n",
      "459: learn: 0.9955796\ttest: 0.9227604\tbestTest: 0.9230007 (449)\ttotal: 1m 49s\tremaining: 9.51s\n",
      "460: learn: 0.995609\ttest: 0.9226887\tbestTest: 0.9230007 (449)\ttotal: 1m 49s\tremaining: 9.28s\n",
      "461: learn: 0.9956723\ttest: 0.9225749\tbestTest: 0.9230007 (449)\ttotal: 1m 49s\tremaining: 9.04s\n",
      "462: learn: 0.995739\ttest: 0.9225622\tbestTest: 0.9230007 (449)\ttotal: 1m 50s\tremaining: 8.81s\n",
      "463: learn: 0.9957745\ttest: 0.9226592\tbestTest: 0.9230007 (449)\ttotal: 1m 50s\tremaining: 8.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464: learn: 0.9958283\ttest: 0.922811\tbestTest: 0.9230007 (449)\ttotal: 1m 50s\tremaining: 8.33s\n",
      "465: learn: 0.9958562\ttest: 0.9227688\tbestTest: 0.9230007 (449)\ttotal: 1m 50s\tremaining: 8.1s\n",
      "466: learn: 0.9958762\ttest: 0.92287\tbestTest: 0.9230007 (449)\ttotal: 1m 51s\tremaining: 7.86s\n",
      "467: learn: 0.9959158\ttest: 0.9227098\tbestTest: 0.9230007 (449)\ttotal: 1m 51s\tremaining: 7.62s\n",
      "468: learn: 0.9959479\ttest: 0.9227646\tbestTest: 0.9230007 (449)\ttotal: 1m 51s\tremaining: 7.38s\n",
      "469: learn: 0.9959747\ttest: 0.922908\tbestTest: 0.9230007 (449)\ttotal: 1m 51s\tremaining: 7.14s\n",
      "470: learn: 0.9960196\ttest: 0.9228152\tbestTest: 0.9230007 (449)\ttotal: 1m 52s\tremaining: 6.91s\n",
      "471: learn: 0.9960558\ttest: 0.9228321\tbestTest: 0.9230007 (449)\ttotal: 1m 52s\tremaining: 6.67s\n",
      "472: learn: 0.9960713\ttest: 0.922811\tbestTest: 0.9230007 (449)\ttotal: 1m 52s\tremaining: 6.43s\n",
      "473: learn: 0.9960957\ttest: 0.9228236\tbestTest: 0.9230007 (449)\ttotal: 1m 52s\tremaining: 6.19s\n",
      "474: learn: 0.9961076\ttest: 0.9228447\tbestTest: 0.9230007 (449)\ttotal: 1m 53s\tremaining: 5.95s\n",
      "475: learn: 0.9961732\ttest: 0.9228827\tbestTest: 0.9230007 (449)\ttotal: 1m 53s\tremaining: 5.72s\n",
      "476: learn: 0.9961829\ttest: 0.9228278\tbestTest: 0.9230007 (449)\ttotal: 1m 53s\tremaining: 5.48s\n",
      "477: learn: 0.9962171\ttest: 0.9229248\tbestTest: 0.9230007 (449)\ttotal: 1m 53s\tremaining: 5.24s\n",
      "478: learn: 0.996225\ttest: 0.9229122\tbestTest: 0.9230007 (449)\ttotal: 1m 54s\tremaining: 5s\n",
      "479: learn: 0.9962699\ttest: 0.92287\tbestTest: 0.9230007 (449)\ttotal: 1m 54s\tremaining: 4.76s\n",
      "480: learn: 0.996314\ttest: 0.9227224\tbestTest: 0.9230007 (449)\ttotal: 1m 54s\tremaining: 4.53s\n",
      "481: learn: 0.9964107\ttest: 0.9227014\tbestTest: 0.9230007 (449)\ttotal: 1m 54s\tremaining: 4.29s\n",
      "482: learn: 0.996412\ttest: 0.9226466\tbestTest: 0.9230007 (449)\ttotal: 1m 55s\tremaining: 4.05s\n",
      "483: learn: 0.996454\ttest: 0.9224779\tbestTest: 0.9230007 (449)\ttotal: 1m 55s\tremaining: 3.81s\n",
      "484: learn: 0.9964756\ttest: 0.9225159\tbestTest: 0.9230007 (449)\ttotal: 1m 55s\tremaining: 3.57s\n",
      "485: learn: 0.9965044\ttest: 0.9225074\tbestTest: 0.9230007 (449)\ttotal: 1m 55s\tremaining: 3.33s\n",
      "486: learn: 0.9965223\ttest: 0.9225411\tbestTest: 0.9230007 (449)\ttotal: 1m 55s\tremaining: 3.09s\n",
      "487: learn: 0.9965533\ttest: 0.9224779\tbestTest: 0.9230007 (449)\ttotal: 1m 56s\tremaining: 2.85s\n",
      "488: learn: 0.9965746\ttest: 0.9222629\tbestTest: 0.9230007 (449)\ttotal: 1m 56s\tremaining: 2.62s\n",
      "489: learn: 0.996578\ttest: 0.9221828\tbestTest: 0.9230007 (449)\ttotal: 1m 56s\tremaining: 2.38s\n",
      "490: learn: 0.9965853\ttest: 0.9221743\tbestTest: 0.9230007 (449)\ttotal: 1m 56s\tremaining: 2.14s\n",
      "491: learn: 0.9966027\ttest: 0.9220394\tbestTest: 0.9230007 (449)\ttotal: 1m 56s\tremaining: 1.9s\n",
      "492: learn: 0.9966192\ttest: 0.9221111\tbestTest: 0.9230007 (449)\ttotal: 1m 57s\tremaining: 1.66s\n",
      "493: learn: 0.9966618\ttest: 0.9220268\tbestTest: 0.9230007 (449)\ttotal: 1m 57s\tremaining: 1.42s\n",
      "494: learn: 0.9966838\ttest: 0.9220647\tbestTest: 0.9230007 (449)\ttotal: 1m 57s\tremaining: 1.19s\n",
      "495: learn: 0.9967214\ttest: 0.9220605\tbestTest: 0.9230007 (449)\ttotal: 1m 57s\tremaining: 950ms\n",
      "496: learn: 0.9967521\ttest: 0.9219931\tbestTest: 0.9230007 (449)\ttotal: 1m 57s\tremaining: 712ms\n",
      "497: learn: 0.9967905\ttest: 0.9219214\tbestTest: 0.9230007 (449)\ttotal: 1m 58s\tremaining: 475ms\n",
      "498: learn: 0.9968299\ttest: 0.9218876\tbestTest: 0.9230007 (449)\ttotal: 1m 58s\tremaining: 237ms\n",
      "499: learn: 0.9968732\ttest: 0.9218371\tbestTest: 0.9230007 (449)\ttotal: 1m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9230007083\n",
      "bestIteration = 449\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.996873231113 0.921837054776\n",
      "[0.9359533325259376, 0.93319957103815687, 0.93683091102445948, 0.93085748403197477, 0.92183705477603883]\n",
      "0.931086976963\n",
      "Depth :  4\n",
      "Train and Test loss :  0.940499510414 0.925281579266\n",
      "[0.92528157926607735]\n",
      "Depth :  4\n",
      "Train and Test loss :  0.946466098912 0.908865067285\n",
      "[0.92528157926607735, 0.9088650672847407]\n",
      "Depth :  4\n",
      "Train and Test loss :  0.945318393294 0.91196488521\n",
      "[0.92528157926607735, 0.9088650672847407, 0.91196488520966701]\n",
      "Depth :  4\n",
      "Train and Test loss :  0.943474406978 0.919343753893\n",
      "[0.92528157926607735, 0.9088650672847407, 0.91196488520966701, 0.91934375389267597]\n",
      "Depth :  4\n",
      "Train and Test loss :  0.939598778606 0.903686589315\n",
      "[0.92528157926607735, 0.9088650672847407, 0.91196488520966701, 0.91934375389267597, 0.90368658931462487]\n",
      "0.912807050567\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(index=range(7), columns=['Model', 'AUC Score'])\n",
    "k=0\n",
    "col=[]\n",
    "val_pred=pd.DataFrame()\n",
    "test_pred=pd.DataFrame()\n",
    "for model_name in ['XGB', 'LGM', 'RF', 'ET', 'GBM', 'CatBoost', 'ADA']:\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    cv_scores = []\n",
    "    pred_test_full = 0\n",
    "    pred_val_full = np.zeros(train_X.shape[0])\n",
    "    for dev_index, val_index in kf.split(train_X):\n",
    "        dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        if model_name=='XGB':\n",
    "            pred_val, loss, pred_test = runXGB(dev_X, dev_y, val_X, val_y, test_X, rounds=5000, feature_names=dev_X.columns.tolist())\n",
    "        elif model_name=='LGM':\n",
    "            pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X, rounds=5000)\n",
    "        elif model_name=='RF':\n",
    "            pred_val, loss, pred_test = runRF(dev_X, dev_y, val_X, val_y, test_X)\n",
    "        elif model_name=='ET':\n",
    "            pred_val, loss, pred_test = runET(dev_X, dev_y, val_X, val_y, test_X)\n",
    "        elif model_name=='GBM':\n",
    "            pred_val, loss, pred_test = runGBM(dev_X, dev_y, val_X, val_y, test_X)    \n",
    "        elif model_name=='CatBoost':\n",
    "            pred_val, loss, pred_test = runCatB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "        elif model_name=='ADA':\n",
    "            pred_val, loss, pred_test = runADA(dev_X, dev_y, val_X, val_y, test_X)\n",
    "            \n",
    "        pred_val_full[val_index] = pred_val\n",
    "        pred_test_full = pred_test_full + pred_test\n",
    "        cv_scores.append(loss)\n",
    "        print(cv_scores)\n",
    "    pred_test_full /= 5.\n",
    "    col.append(model_name)\n",
    "    val_pred=pd.concat([val_pred, pd.DataFrame(pred_val_full)], axis=1)\n",
    "    test_pred=pd.concat([test_pred, pd.DataFrame(pred_test_full)], axis=1)\n",
    "    val_pred.columns=col\n",
    "    test_pred.columns=col\n",
    "    print(metrics.roc_auc_score(train_y, pred_val_full))\n",
    "    results['Model'][k]=model_name\n",
    "    results['AUC Score'][k]=metrics.roc_auc_score(train_y, pred_val_full)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the AUC Score of different Models after 5 fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.93324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGM</td>\n",
       "      <td>0.930231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.921697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET</td>\n",
       "      <td>0.932845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.925768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.931087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.912807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model AUC Score\n",
       "0       XGB   0.93324\n",
       "1       LGM  0.930231\n",
       "2        RF  0.921697\n",
       "3        ET  0.932845\n",
       "4       GBM  0.925768\n",
       "5  CatBoost  0.931087\n",
       "6       ADA  0.912807"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbadf6d6a58>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAE4CAYAAADijcDQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKjsaZmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbadf6d6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Pearson correlation of models', y=1.05, size=15)\n",
    "sns.heatmap(val_pred.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGM</th>\n",
       "      <th>RF</th>\n",
       "      <th>ET</th>\n",
       "      <th>GBM</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>ADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832048</td>\n",
       "      <td>0.752154</td>\n",
       "      <td>0.608718</td>\n",
       "      <td>0.837137</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.907250</td>\n",
       "      <td>0.900318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.050609</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>0.077963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.354413</td>\n",
       "      <td>0.275761</td>\n",
       "      <td>0.342044</td>\n",
       "      <td>0.339766</td>\n",
       "      <td>0.255743</td>\n",
       "      <td>0.372176</td>\n",
       "      <td>0.379757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515671</td>\n",
       "      <td>0.525435</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.547226</td>\n",
       "      <td>0.505415</td>\n",
       "      <td>0.719136</td>\n",
       "      <td>0.429593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.189498</td>\n",
       "      <td>0.308999</td>\n",
       "      <td>0.413539</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.162091</td>\n",
       "      <td>0.211363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        XGB       LGM        RF        ET       GBM  CatBoost       ADA\n",
       "0  0.832048  0.752154  0.608718  0.837137  0.999919  0.907250  0.900318\n",
       "1  0.017489  0.022661  0.050609  0.055215  0.000035  0.042757  0.077963\n",
       "2  0.354413  0.275761  0.342044  0.339766  0.255743  0.372176  0.379757\n",
       "3  0.515671  0.525435  0.395509  0.547226  0.505415  0.719136  0.429593\n",
       "4  0.081383  0.189498  0.308999  0.413539  0.000155  0.162091  0.211363"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGM</th>\n",
       "      <th>RF</th>\n",
       "      <th>ET</th>\n",
       "      <th>GBM</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>ADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.092373</td>\n",
       "      <td>0.166431</td>\n",
       "      <td>0.097764</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.069220</td>\n",
       "      <td>0.117189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216935</td>\n",
       "      <td>0.178788</td>\n",
       "      <td>0.237388</td>\n",
       "      <td>0.163089</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.175610</td>\n",
       "      <td>0.276045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.785677</td>\n",
       "      <td>0.745813</td>\n",
       "      <td>0.685817</td>\n",
       "      <td>0.839882</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.905409</td>\n",
       "      <td>0.800867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.369769</td>\n",
       "      <td>0.391663</td>\n",
       "      <td>0.343349</td>\n",
       "      <td>0.262103</td>\n",
       "      <td>0.276918</td>\n",
       "      <td>0.391067</td>\n",
       "      <td>0.361976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174140</td>\n",
       "      <td>0.208168</td>\n",
       "      <td>0.334155</td>\n",
       "      <td>0.348642</td>\n",
       "      <td>0.134111</td>\n",
       "      <td>0.178297</td>\n",
       "      <td>0.276260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        XGB       LGM        RF        ET       GBM  CatBoost       ADA\n",
       "0  0.059163  0.092373  0.166431  0.097764  0.000837  0.069220  0.117189\n",
       "1  0.216935  0.178788  0.237388  0.163089  0.003734  0.175610  0.276045\n",
       "2  0.785677  0.745813  0.685817  0.839882  0.998999  0.905409  0.800867\n",
       "3  0.369769  0.391663  0.343349  0.262103  0.276918  0.391067  0.361976\n",
       "4  0.174140  0.208168  0.334155  0.348642  0.134111  0.178297  0.276260"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Now let's ensemble these Stacked features using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X=pd.concat([train_X, val_pred], 1)\n",
    "test_X=pd.concat([test_X, test_pred], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HeadLine_n</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>svd_word_3</th>\n",
       "      <th>svd_word_4</th>\n",
       "      <th>svd_word_5</th>\n",
       "      <th>svd_word_6</th>\n",
       "      <th>svd_word_7</th>\n",
       "      <th>svd_word_8</th>\n",
       "      <th>svd_word_9</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "      <th>svd_word_20</th>\n",
       "      <th>svd_word_21</th>\n",
       "      <th>svd_word_22</th>\n",
       "      <th>svd_word_23</th>\n",
       "      <th>svd_word_24</th>\n",
       "      <th>svd_word_25</th>\n",
       "      <th>svd_word_26</th>\n",
       "      <th>svd_word_27</th>\n",
       "      <th>svd_word_28</th>\n",
       "      <th>svd_word_29</th>\n",
       "      <th>svd_word_30</th>\n",
       "      <th>svd_word_31</th>\n",
       "      <th>svd_word_32</th>\n",
       "      <th>svd_word_33</th>\n",
       "      <th>svd_word_34</th>\n",
       "      <th>svd_word_35</th>\n",
       "      <th>svd_word_36</th>\n",
       "      <th>svd_word_37</th>\n",
       "      <th>svd_word_38</th>\n",
       "      <th>svd_word_39</th>\n",
       "      <th>svd_word_40</th>\n",
       "      <th>svd_word_41</th>\n",
       "      <th>svd_word_42</th>\n",
       "      <th>svd_word_43</th>\n",
       "      <th>svd_word_44</th>\n",
       "      <th>svd_word_45</th>\n",
       "      <th>svd_word_46</th>\n",
       "      <th>svd_word_47</th>\n",
       "      <th>svd_word_48</th>\n",
       "      <th>svd_word_49</th>\n",
       "      <th>big</th>\n",
       "      <th>billion</th>\n",
       "      <th>business</th>\n",
       "      <th>china</th>\n",
       "      <th>daily</th>\n",
       "      <th>day</th>\n",
       "      <th>deal</th>\n",
       "      <th>ebola</th>\n",
       "      <th>fashion</th>\n",
       "      <th>fashion_week</th>\n",
       "      <th>million</th>\n",
       "      <th>morning</th>\n",
       "      <th>new</th>\n",
       "      <th>new_york</th>\n",
       "      <th>new_york_today</th>\n",
       "      <th>news</th>\n",
       "      <th>obama</th>\n",
       "      <th>paris</th>\n",
       "      <th>pictures</th>\n",
       "      <th>politics</th>\n",
       "      <th>report</th>\n",
       "      <th>says</th>\n",
       "      <th>small</th>\n",
       "      <th>spring</th>\n",
       "      <th>spring_summer</th>\n",
       "      <th>summer</th>\n",
       "      <th>test</th>\n",
       "      <th>today</th>\n",
       "      <th>week</th>\n",
       "      <th>word</th>\n",
       "      <th>york</th>\n",
       "      <th>york_today</th>\n",
       "      <th>Business</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Magazine</th>\n",
       "      <th>Metro</th>\n",
       "      <th>OpEd</th>\n",
       "      <th>Science</th>\n",
       "      <th>Styles</th>\n",
       "      <th>TStyle</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGM</th>\n",
       "      <th>RF</th>\n",
       "      <th>ET</th>\n",
       "      <th>GBM</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>ADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>-0.0183</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0851</td>\n",
       "      <td>-0.0820</td>\n",
       "      <td>-0.0373</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>-0.0635</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.1179</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>-0.0344</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.0611</td>\n",
       "      <td>-0.0483</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>-0.0649</td>\n",
       "      <td>-0.0768</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.832048</td>\n",
       "      <td>0.752154</td>\n",
       "      <td>0.608718</td>\n",
       "      <td>0.837137</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.907250</td>\n",
       "      <td>0.900318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0423</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>-0.0362</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>-0.0968</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0821</td>\n",
       "      <td>-0.0137</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>-0.0783</td>\n",
       "      <td>-0.1023</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.1031</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0960</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>-0.0915</td>\n",
       "      <td>-0.0616</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0988</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>-0.0908</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-0.0937</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>-0.0461</td>\n",
       "      <td>-0.0377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.050609</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>0.077963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>-0.1017</td>\n",
       "      <td>-0.1037</td>\n",
       "      <td>-0.0359</td>\n",
       "      <td>-0.0205</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0863</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0149</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0123</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>-0.0716</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0638</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>-0.0588</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>-0.0374</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0775</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354413</td>\n",
       "      <td>0.275761</td>\n",
       "      <td>0.342044</td>\n",
       "      <td>0.339766</td>\n",
       "      <td>0.255743</td>\n",
       "      <td>0.372176</td>\n",
       "      <td>0.379757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1405</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.0855</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>-0.0524</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>-0.0484</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>-0.0509</td>\n",
       "      <td>-0.0787</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>-0.0761</td>\n",
       "      <td>-0.0777</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>-0.1129</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515671</td>\n",
       "      <td>0.525435</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.547226</td>\n",
       "      <td>0.505415</td>\n",
       "      <td>0.719136</td>\n",
       "      <td>0.429593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>-0.0370</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0685</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>-0.0746</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>-0.0428</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>-0.0438</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>-0.0181</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.189498</td>\n",
       "      <td>0.308999</td>\n",
       "      <td>0.413539</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.162091</td>\n",
       "      <td>0.211363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordCount  Month  Weekday  Hour  HeadLine_n  num_unique_words  num_chars  \\\n",
       "0        508      9        0    22           0                 3         16   \n",
       "1        285      9        0    21           0                 7         44   \n",
       "2       1211      9        0    21           0                 8         49   \n",
       "3       1405      9        0    20           0                 4         21   \n",
       "4        181      9        0    18           0                 6         29   \n",
       "\n",
       "   num_stopwords  num_punctuations  mean_word_len  svd_word_0  svd_word_1  \\\n",
       "0              0                 0       4.666667      0.6179     -0.0183   \n",
       "1              1                 1       5.428571      0.7489      0.0058   \n",
       "2              1                 0       5.250000      0.7755     -0.1017   \n",
       "3              1                 0       4.500000      0.7251      0.0172   \n",
       "4              1                 0       4.000000      0.8294      0.0691   \n",
       "\n",
       "   svd_word_2  svd_word_3  svd_word_4  svd_word_5  svd_word_6  svd_word_7  \\\n",
       "0     -0.0439     -0.0037      0.0245      0.0398      0.0723      0.0667   \n",
       "1     -0.0423      0.0001      0.1064      0.0159     -0.0735     -0.0085   \n",
       "2     -0.1037     -0.0359     -0.0205     -0.0621      0.0145      0.0155   \n",
       "3     -0.0855      0.0488      0.0298     -0.0177     -0.0255     -0.0524   \n",
       "4      0.0382     -0.0370      0.0033      0.0789     -0.0046     -0.0685   \n",
       "\n",
       "   svd_word_8  svd_word_9  svd_word_10  svd_word_11  svd_word_12  svd_word_13  \\\n",
       "0     -0.0225     -0.0516       0.1326      -0.0202       0.0614       0.0037   \n",
       "1      0.0660     -0.0362       0.0184      -0.0968       0.0924      -0.0020   \n",
       "2     -0.0092     -0.0863       0.0821      -0.0149      -0.0046      -0.0101   \n",
       "3      0.0064     -0.0008      -0.0021       0.1270       0.0282      -0.0194   \n",
       "4      0.0280     -0.0341      -0.0207       0.0635      -0.0142      -0.0746   \n",
       "\n",
       "   svd_word_14  svd_word_15  svd_word_16  svd_word_17  svd_word_18  \\\n",
       "0      -0.0851      -0.0820      -0.0373      -0.0244       0.0134   \n",
       "1      -0.0532      -0.0235       0.0114      -0.0821      -0.0137   \n",
       "2      -0.0020       0.0416      -0.0059      -0.0123      -0.0256   \n",
       "3       0.0387      -0.0484       0.0857      -0.0109      -0.0509   \n",
       "4       0.0230       0.0249       0.0550      -0.0428       0.0352   \n",
       "\n",
       "   svd_word_19  svd_word_20  svd_word_21  svd_word_22  svd_word_23  \\\n",
       "0      -0.0635       0.0033       0.0453      -0.0286      -0.0023   \n",
       "1       0.0454      -0.0783      -0.1023      -0.0218      -0.0113   \n",
       "2      -0.0024       0.0752       0.0532      -0.0509      -0.0487   \n",
       "3      -0.0787       0.0608       0.0194       0.0158       0.0394   \n",
       "4      -0.0516       0.0096      -0.0348       0.0547       0.0226   \n",
       "\n",
       "   svd_word_24  svd_word_25  svd_word_26  svd_word_27  svd_word_28  \\\n",
       "0       0.0553       0.0591      -0.0226       0.0919      -0.0025   \n",
       "1       0.0387      -0.1031       0.0461      -0.0548      -0.0960   \n",
       "2       0.0599      -0.0716       0.1369      -0.0027      -0.0638   \n",
       "3      -0.0761      -0.0777       0.0722       0.0312      -0.0725   \n",
       "4       0.0498      -0.0115       0.0277       0.0382       0.0683   \n",
       "\n",
       "   svd_word_29  svd_word_30  svd_word_31  svd_word_32  svd_word_33  \\\n",
       "0      -0.0226       0.0326      -0.0198      -0.0166      -0.1179   \n",
       "1       0.0560      -0.0915      -0.0616       0.0151       0.0007   \n",
       "2      -0.0694       0.1234       0.0477      -0.0084      -0.0179   \n",
       "3       0.0054       0.0303       0.0290       0.0328       0.0061   \n",
       "4      -0.0089      -0.0438      -0.0392       0.0091      -0.0255   \n",
       "\n",
       "   svd_word_34  svd_word_35  svd_word_36  svd_word_37  svd_word_38  \\\n",
       "0      -0.0402      -0.0344       0.0258       0.0741       0.0218   \n",
       "1      -0.0988       0.0318       0.0782      -0.0205      -0.0079   \n",
       "2       0.0432       0.0364       0.0197      -0.0588       0.0557   \n",
       "3       0.1023       0.1025       0.0919      -0.0259      -0.0532   \n",
       "4       0.0120      -0.0175      -0.0694      -0.0120       0.0295   \n",
       "\n",
       "   svd_word_39  svd_word_40  svd_word_41  svd_word_42  svd_word_43  \\\n",
       "0       0.1542       0.0021      -0.0611      -0.0483       0.0072   \n",
       "1       0.0928      -0.0908       0.0271       0.0492      -0.0172   \n",
       "2      -0.0374       0.0206      -0.0218       0.0523       0.0009   \n",
       "3       0.0059      -0.1129      -0.0415      -0.0014       0.0306   \n",
       "4       0.0062      -0.0090      -0.0194      -0.0379      -0.0181   \n",
       "\n",
       "   svd_word_44  svd_word_45  svd_word_46  svd_word_47  svd_word_48  \\\n",
       "0      -0.0327      -0.0027       0.1137      -0.0649      -0.0768   \n",
       "1      -0.0245       0.0238      -0.0937       0.0228      -0.0461   \n",
       "2      -0.0775      -0.0381      -0.0176       0.0339      -0.0008   \n",
       "3      -0.0135       0.0656      -0.0004      -0.0596      -0.0037   \n",
       "4       0.0222       0.0883      -0.0211       0.0097       0.0070   \n",
       "\n",
       "   svd_word_49  big  billion  business  china  daily  day  deal  ebola  \\\n",
       "0       0.0508    0        0         0      0      0    0     0      0   \n",
       "1      -0.0377    0        0         0      0      0    0     0      0   \n",
       "2       0.0742    0        0         0      0      0    0     0      0   \n",
       "3       0.0181    0        0         0      0      0    0     0      0   \n",
       "4      -0.0329    0        0         0      0      0    0     0      0   \n",
       "\n",
       "   fashion  fashion_week  million  morning  new  new_york  new_york_today  \\\n",
       "0        0             0        0        0    0         0               0   \n",
       "1        0             0        0        0    1         0               0   \n",
       "2        0             0        0        0    0         0               0   \n",
       "3        0             0        0        0    0         0               0   \n",
       "4        0             0        0        0    0         0               0   \n",
       "\n",
       "   news  obama  paris  pictures  politics  report  says  small  spring  \\\n",
       "0     0      0      0         0         0       0     0      0       0   \n",
       "1     0      0      0         0         0       0     0      0       0   \n",
       "2     0      0      0         0         0       0     0      0       0   \n",
       "3     0      0      0         0         0       0     0      0       0   \n",
       "4     0      0      0         0         0       0     0      0       0   \n",
       "\n",
       "   spring_summer  summer  test  today  week  word  york  york_today  Business  \\\n",
       "0              0       0     0      0     0     0     0           0         1   \n",
       "1              0       0     0      0     0     0     0           0         0   \n",
       "2              0       0     0      0     0     0     0           0         1   \n",
       "3              0       0     0      0     0     0     0           0         1   \n",
       "4              0       0     0      0     0     0     0           0         0   \n",
       "\n",
       "   Culture  Foreign  Magazine  Metro  OpEd  Science  Styles  TStyle  Travel  \\\n",
       "0        0        0         0      0     0        0       0       0       0   \n",
       "1        1        0         0      0     0        0       0       0       0   \n",
       "2        0        0         0      0     0        0       0       0       0   \n",
       "3        0        0         0      0     0        0       0       0       0   \n",
       "4        0        0         0      0     0        1       0       0       0   \n",
       "\n",
       "   Unknown       XGB       LGM        RF        ET       GBM  CatBoost  \\\n",
       "0        0  0.832048  0.752154  0.608718  0.837137  0.999919  0.907250   \n",
       "1        0  0.017489  0.022661  0.050609  0.055215  0.000035  0.042757   \n",
       "2        0  0.354413  0.275761  0.342044  0.339766  0.255743  0.372176   \n",
       "3        0  0.515671  0.525435  0.395509  0.547226  0.505415  0.719136   \n",
       "4        0  0.081383  0.189498  0.308999  0.413539  0.000155  0.162091   \n",
       "\n",
       "        ADA  \n",
       "0  0.900318  \n",
       "1  0.077963  \n",
       "2  0.379757  \n",
       "3  0.429593  \n",
       "4  0.211363  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/catboost/core.py:1240: FutureWarning: The 'verbose' parameter is deprecated, use 'logging_level' parameter instead (posible values: 'Silent', 'Verbose', 'Info', 'Debug').\n",
      "  super(CatBoostClassifier, self).__init__(params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: learn: 0.908123\ttest: 0.906766\tbestTest: 0.906766 (0)\ttotal: 136ms\tremaining: 1m 7s\n",
      "1: learn: 0.9162495\ttest: 0.916045\tbestTest: 0.916045 (1)\ttotal: 347ms\tremaining: 1m 26s\n",
      "2: learn: 0.918915\ttest: 0.9193795\tbestTest: 0.9193795 (2)\ttotal: 526ms\tremaining: 1m 27s\n",
      "3: learn: 0.9254325\ttest: 0.9280166\tbestTest: 0.9280166 (3)\ttotal: 715ms\tremaining: 1m 28s\n",
      "4: learn: 0.9267157\ttest: 0.9291107\tbestTest: 0.9291107 (4)\ttotal: 913ms\tremaining: 1m 30s\n",
      "5: learn: 0.9317588\ttest: 0.9366578\tbestTest: 0.9366578 (5)\ttotal: 1.13s\tremaining: 1m 33s\n",
      "6: learn: 0.9318499\ttest: 0.9369222\tbestTest: 0.9369222 (6)\ttotal: 1.34s\tremaining: 1m 34s\n",
      "7: learn: 0.9329464\ttest: 0.9387308\tbestTest: 0.9387308 (7)\ttotal: 1.55s\tremaining: 1m 35s\n",
      "8: learn: 0.9334433\ttest: 0.9399076\tbestTest: 0.9399076 (8)\ttotal: 1.76s\tremaining: 1m 36s\n",
      "9: learn: 0.9335713\ttest: 0.9392435\tbestTest: 0.9399076 (8)\ttotal: 2s\tremaining: 1m 38s\n",
      "10: learn: 0.9338374\ttest: 0.940063\tbestTest: 0.940063 (10)\ttotal: 2.21s\tremaining: 1m 38s\n",
      "11: learn: 0.9349589\ttest: 0.9398107\tbestTest: 0.940063 (10)\ttotal: 2.43s\tremaining: 1m 38s\n",
      "12: learn: 0.9349499\ttest: 0.9397824\tbestTest: 0.940063 (10)\ttotal: 2.61s\tremaining: 1m 37s\n",
      "13: learn: 0.9351396\ttest: 0.9396734\tbestTest: 0.940063 (10)\ttotal: 2.83s\tremaining: 1m 38s\n",
      "14: learn: 0.9354597\ttest: 0.9401538\tbestTest: 0.9401538 (14)\ttotal: 2.98s\tremaining: 1m 36s\n",
      "15: learn: 0.9358231\ttest: 0.9404606\tbestTest: 0.9404606 (15)\ttotal: 3.17s\tremaining: 1m 35s\n",
      "16: learn: 0.9362559\ttest: 0.9407452\tbestTest: 0.9407452 (16)\ttotal: 3.37s\tremaining: 1m 35s\n",
      "17: learn: 0.936564\ttest: 0.9407452\tbestTest: 0.9407452 (17)\ttotal: 3.73s\tremaining: 1m 40s\n",
      "18: learn: 0.9367389\ttest: 0.9411974\tbestTest: 0.9411974 (18)\ttotal: 3.91s\tremaining: 1m 39s\n",
      "19: learn: 0.9370292\ttest: 0.9421864\tbestTest: 0.9421864 (19)\ttotal: 4.11s\tremaining: 1m 38s\n",
      "20: learn: 0.9371185\ttest: 0.9422187\tbestTest: 0.9422187 (20)\ttotal: 4.32s\tremaining: 1m 38s\n",
      "21: learn: 0.9377428\ttest: 0.941916\tbestTest: 0.9422187 (20)\ttotal: 4.53s\tremaining: 1m 38s\n",
      "22: learn: 0.9380687\ttest: 0.9417222\tbestTest: 0.9422187 (20)\ttotal: 4.75s\tremaining: 1m 38s\n",
      "23: learn: 0.9380821\ttest: 0.9415445\tbestTest: 0.9422187 (20)\ttotal: 4.95s\tremaining: 1m 38s\n",
      "24: learn: 0.9385568\ttest: 0.9415042\tbestTest: 0.9422187 (20)\ttotal: 5.17s\tremaining: 1m 38s\n",
      "25: learn: 0.9387067\ttest: 0.9414113\tbestTest: 0.9422187 (20)\ttotal: 5.37s\tremaining: 1m 37s\n",
      "26: learn: 0.9388193\ttest: 0.9413669\tbestTest: 0.9422187 (20)\ttotal: 5.59s\tremaining: 1m 37s\n",
      "27: learn: 0.9388916\ttest: 0.9414517\tbestTest: 0.9422187 (20)\ttotal: 5.81s\tremaining: 1m 38s\n",
      "28: learn: 0.9390892\ttest: 0.9408946\tbestTest: 0.9422187 (20)\ttotal: 6.04s\tremaining: 1m 38s\n",
      "29: learn: 0.9394874\ttest: 0.9409269\tbestTest: 0.9422187 (20)\ttotal: 6.26s\tremaining: 1m 38s\n",
      "30: learn: 0.9397618\ttest: 0.9413023\tbestTest: 0.9422187 (20)\ttotal: 6.48s\tremaining: 1m 38s\n",
      "31: learn: 0.9397501\ttest: 0.9410682\tbestTest: 0.9422187 (20)\ttotal: 6.68s\tremaining: 1m 37s\n",
      "32: learn: 0.9400705\ttest: 0.9410924\tbestTest: 0.9422187 (20)\ttotal: 6.8s\tremaining: 1m 36s\n",
      "33: learn: 0.9404448\ttest: 0.9412539\tbestTest: 0.9422187 (20)\ttotal: 7.01s\tremaining: 1m 36s\n",
      "34: learn: 0.9405062\ttest: 0.9413629\tbestTest: 0.9422187 (20)\ttotal: 7.2s\tremaining: 1m 35s\n",
      "35: learn: 0.940677\ttest: 0.9412135\tbestTest: 0.9422187 (20)\ttotal: 7.35s\tremaining: 1m 34s\n",
      "36: learn: 0.9411217\ttest: 0.9408421\tbestTest: 0.9422187 (20)\ttotal: 7.56s\tremaining: 1m 34s\n",
      "37: learn: 0.9413366\ttest: 0.940721\tbestTest: 0.9422187 (20)\ttotal: 7.75s\tremaining: 1m 34s\n",
      "38: learn: 0.9414248\ttest: 0.9408219\tbestTest: 0.9422187 (20)\ttotal: 7.88s\tremaining: 1m 33s\n",
      "39: learn: 0.9415655\ttest: 0.9407129\tbestTest: 0.9422187 (20)\ttotal: 8.09s\tremaining: 1m 33s\n",
      "40: learn: 0.9421619\ttest: 0.9408623\tbestTest: 0.9422187 (20)\ttotal: 8.3s\tremaining: 1m 32s\n",
      "41: learn: 0.9424215\ttest: 0.9408583\tbestTest: 0.9422187 (20)\ttotal: 8.5s\tremaining: 1m 32s\n",
      "42: learn: 0.9425851\ttest: 0.9411247\tbestTest: 0.9422187 (20)\ttotal: 8.68s\tremaining: 1m 32s\n",
      "43: learn: 0.9426271\ttest: 0.9411772\tbestTest: 0.9422187 (20)\ttotal: 8.88s\tremaining: 1m 32s\n",
      "44: learn: 0.942575\ttest: 0.9412741\tbestTest: 0.9422187 (20)\ttotal: 9.1s\tremaining: 1m 31s\n",
      "45: learn: 0.9427134\ttest: 0.9411651\tbestTest: 0.9422187 (20)\ttotal: 9.31s\tremaining: 1m 31s\n",
      "46: learn: 0.9428855\ttest: 0.9411691\tbestTest: 0.9422187 (20)\ttotal: 9.53s\tremaining: 1m 31s\n",
      "47: learn: 0.9431307\ttest: 0.9411247\tbestTest: 0.9422187 (20)\ttotal: 9.74s\tremaining: 1m 31s\n",
      "48: learn: 0.9433228\ttest: 0.941153\tbestTest: 0.9422187 (20)\ttotal: 9.96s\tremaining: 1m 31s\n",
      "49: learn: 0.9435135\ttest: 0.9410964\tbestTest: 0.9422187 (20)\ttotal: 10.2s\tremaining: 1m 31s\n",
      "50: learn: 0.943628\ttest: 0.941044\tbestTest: 0.9422187 (20)\ttotal: 10.4s\tremaining: 1m 31s\n",
      "51: learn: 0.9436886\ttest: 0.9410197\tbestTest: 0.9422187 (20)\ttotal: 10.6s\tremaining: 1m 31s\n",
      "52: learn: 0.9440523\ttest: 0.9410399\tbestTest: 0.9422187 (20)\ttotal: 10.8s\tremaining: 1m 31s\n",
      "53: learn: 0.9442393\ttest: 0.9412176\tbestTest: 0.9422187 (20)\ttotal: 11s\tremaining: 1m 30s\n",
      "54: learn: 0.9445599\ttest: 0.9409269\tbestTest: 0.9422187 (20)\ttotal: 11.2s\tremaining: 1m 30s\n",
      "55: learn: 0.9448877\ttest: 0.940939\tbestTest: 0.9422187 (20)\ttotal: 11.3s\tremaining: 1m 29s\n",
      "56: learn: 0.945117\ttest: 0.9409067\tbestTest: 0.9422187 (20)\ttotal: 11.5s\tremaining: 1m 29s\n",
      "57: learn: 0.9452875\ttest: 0.9411893\tbestTest: 0.9422187 (20)\ttotal: 11.7s\tremaining: 1m 29s\n",
      "58: learn: 0.945495\ttest: 0.9415567\tbestTest: 0.9422187 (20)\ttotal: 11.9s\tremaining: 1m 29s\n",
      "59: learn: 0.94561\ttest: 0.9415082\tbestTest: 0.9422187 (20)\ttotal: 12.1s\tremaining: 1m 28s\n",
      "60: learn: 0.9457314\ttest: 0.9415163\tbestTest: 0.9422187 (20)\ttotal: 12.5s\tremaining: 1m 30s\n",
      "61: learn: 0.9458332\ttest: 0.9414598\tbestTest: 0.9422187 (20)\ttotal: 12.7s\tremaining: 1m 29s\n",
      "62: learn: 0.9460056\ttest: 0.9414073\tbestTest: 0.9422187 (20)\ttotal: 12.9s\tremaining: 1m 29s\n",
      "63: learn: 0.9461628\ttest: 0.9413548\tbestTest: 0.9422187 (20)\ttotal: 13.1s\tremaining: 1m 29s\n",
      "64: learn: 0.9464521\ttest: 0.941371\tbestTest: 0.9422187 (20)\ttotal: 13.3s\tremaining: 1m 28s\n",
      "65: learn: 0.9465735\ttest: 0.9413387\tbestTest: 0.9422187 (20)\ttotal: 13.5s\tremaining: 1m 28s\n",
      "66: learn: 0.946823\ttest: 0.9412943\tbestTest: 0.9422187 (20)\ttotal: 13.7s\tremaining: 1m 28s\n",
      "67: learn: 0.9473075\ttest: 0.9410319\tbestTest: 0.9422187 (20)\ttotal: 13.9s\tremaining: 1m 28s\n",
      "68: learn: 0.9476164\ttest: 0.9409874\tbestTest: 0.9422187 (20)\ttotal: 14.1s\tremaining: 1m 28s\n",
      "69: learn: 0.9478332\ttest: 0.9410359\tbestTest: 0.9422187 (20)\ttotal: 14.4s\tremaining: 1m 28s\n",
      "70: learn: 0.9483103\ttest: 0.9410924\tbestTest: 0.9422187 (20)\ttotal: 14.6s\tremaining: 1m 28s\n",
      "71: learn: 0.9486025\ttest: 0.9410197\tbestTest: 0.9422187 (20)\ttotal: 14.8s\tremaining: 1m 27s\n",
      "72: learn: 0.9489221\ttest: 0.9412983\tbestTest: 0.9422187 (20)\ttotal: 15s\tremaining: 1m 27s\n",
      "73: learn: 0.9491149\ttest: 0.9412902\tbestTest: 0.9422187 (20)\ttotal: 15.2s\tremaining: 1m 27s\n",
      "74: learn: 0.9492045\ttest: 0.941266\tbestTest: 0.9422187 (20)\ttotal: 15.4s\tremaining: 1m 27s\n",
      "75: learn: 0.9494837\ttest: 0.9410359\tbestTest: 0.9422187 (20)\ttotal: 15.7s\tremaining: 1m 27s\n",
      "76: learn: 0.9496632\ttest: 0.9411691\tbestTest: 0.9422187 (20)\ttotal: 15.8s\tremaining: 1m 27s\n",
      "77: learn: 0.9498423\ttest: 0.9412054\tbestTest: 0.9422187 (20)\ttotal: 16.1s\tremaining: 1m 26s\n",
      "78: learn: 0.9501555\ttest: 0.9412579\tbestTest: 0.9422187 (20)\ttotal: 16.3s\tremaining: 1m 26s\n",
      "79: learn: 0.9503823\ttest: 0.9412943\tbestTest: 0.9422187 (20)\ttotal: 16.4s\tremaining: 1m 26s\n",
      "80: learn: 0.9506323\ttest: 0.9415203\tbestTest: 0.9422187 (20)\ttotal: 16.6s\tremaining: 1m 26s\n",
      "81: learn: 0.9507309\ttest: 0.9417181\tbestTest: 0.9422187 (20)\ttotal: 16.9s\tremaining: 1m 25s\n",
      "82: learn: 0.9509466\ttest: 0.9416576\tbestTest: 0.9422187 (20)\ttotal: 17.1s\tremaining: 1m 25s\n",
      "83: learn: 0.9513249\ttest: 0.941597\tbestTest: 0.9422187 (20)\ttotal: 17.3s\tremaining: 1m 25s\n",
      "84: learn: 0.9515727\ttest: 0.9416616\tbestTest: 0.9422187 (20)\ttotal: 17.4s\tremaining: 1m 25s\n",
      "85: learn: 0.9518025\ttest: 0.9416132\tbestTest: 0.9422187 (20)\ttotal: 17.6s\tremaining: 1m 24s\n",
      "86: learn: 0.9519696\ttest: 0.941698\tbestTest: 0.9422187 (20)\ttotal: 17.8s\tremaining: 1m 24s\n",
      "87: learn: 0.9521229\ttest: 0.9417666\tbestTest: 0.9422187 (20)\ttotal: 18.1s\tremaining: 1m 24s\n",
      "88: learn: 0.952494\ttest: 0.9417827\tbestTest: 0.9422187 (20)\ttotal: 18.3s\tremaining: 1m 24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89: learn: 0.9527405\ttest: 0.9417747\tbestTest: 0.9422187 (20)\ttotal: 18.5s\tremaining: 1m 24s\n",
      "90: learn: 0.9531833\ttest: 0.9415405\tbestTest: 0.9422187 (20)\ttotal: 18.8s\tremaining: 1m 24s\n",
      "91: learn: 0.9534609\ttest: 0.9416051\tbestTest: 0.9422187 (20)\ttotal: 19s\tremaining: 1m 24s\n",
      "92: learn: 0.9536609\ttest: 0.9417343\tbestTest: 0.9422187 (20)\ttotal: 19.1s\tremaining: 1m 23s\n",
      "93: learn: 0.9537916\ttest: 0.9417262\tbestTest: 0.9422187 (20)\ttotal: 19.3s\tremaining: 1m 23s\n",
      "94: learn: 0.9539656\ttest: 0.941815\tbestTest: 0.9422187 (20)\ttotal: 19.5s\tremaining: 1m 23s\n",
      "95: learn: 0.9541675\ttest: 0.9416011\tbestTest: 0.9422187 (20)\ttotal: 19.8s\tremaining: 1m 23s\n",
      "96: learn: 0.9543479\ttest: 0.9416657\tbestTest: 0.9422187 (20)\ttotal: 20s\tremaining: 1m 22s\n",
      "97: learn: 0.9545448\ttest: 0.941702\tbestTest: 0.9422187 (20)\ttotal: 20.2s\tremaining: 1m 22s\n",
      "98: learn: 0.9546978\ttest: 0.9415688\tbestTest: 0.9422187 (20)\ttotal: 20.4s\tremaining: 1m 22s\n",
      "99: learn: 0.9550179\ttest: 0.9415688\tbestTest: 0.9422187 (20)\ttotal: 20.6s\tremaining: 1m 22s\n",
      "100: learn: 0.9553757\ttest: 0.9415768\tbestTest: 0.9422187 (20)\ttotal: 20.8s\tremaining: 1m 22s\n",
      "101: learn: 0.9556804\ttest: 0.9415082\tbestTest: 0.9422187 (20)\ttotal: 21s\tremaining: 1m 21s\n",
      "102: learn: 0.9559386\ttest: 0.9416051\tbestTest: 0.9422187 (20)\ttotal: 21.2s\tremaining: 1m 21s\n",
      "103: learn: 0.956128\ttest: 0.9415809\tbestTest: 0.9422187 (20)\ttotal: 21.4s\tremaining: 1m 21s\n",
      "104: learn: 0.9563031\ttest: 0.9416818\tbestTest: 0.9422187 (20)\ttotal: 21.6s\tremaining: 1m 21s\n",
      "105: learn: 0.9564672\ttest: 0.941698\tbestTest: 0.9422187 (20)\ttotal: 21.8s\tremaining: 1m 20s\n",
      "106: learn: 0.9566734\ttest: 0.9416818\tbestTest: 0.9422187 (20)\ttotal: 22s\tremaining: 1m 20s\n",
      "107: learn: 0.9567382\ttest: 0.9417101\tbestTest: 0.9422187 (20)\ttotal: 22.2s\tremaining: 1m 20s\n",
      "108: learn: 0.9569244\ttest: 0.9416495\tbestTest: 0.9422187 (20)\ttotal: 22.4s\tremaining: 1m 20s\n",
      "109: learn: 0.9571901\ttest: 0.941589\tbestTest: 0.9422187 (20)\ttotal: 22.6s\tremaining: 1m 20s\n",
      "110: learn: 0.9575511\ttest: 0.941706\tbestTest: 0.9422187 (20)\ttotal: 22.8s\tremaining: 1m 20s\n",
      "111: learn: 0.9578252\ttest: 0.9417262\tbestTest: 0.9422187 (20)\ttotal: 23s\tremaining: 1m 19s\n",
      "112: learn: 0.9580696\ttest: 0.9418392\tbestTest: 0.9422187 (20)\ttotal: 23.2s\tremaining: 1m 19s\n",
      "113: learn: 0.958361\ttest: 0.9418756\tbestTest: 0.9422187 (20)\ttotal: 23.5s\tremaining: 1m 19s\n",
      "114: learn: 0.9584691\ttest: 0.941916\tbestTest: 0.9422187 (20)\ttotal: 23.7s\tremaining: 1m 19s\n",
      "115: learn: 0.9586535\ttest: 0.9418756\tbestTest: 0.9422187 (20)\ttotal: 23.9s\tremaining: 1m 19s\n",
      "116: learn: 0.9588368\ttest: 0.9419563\tbestTest: 0.9422187 (20)\ttotal: 24.1s\tremaining: 1m 18s\n",
      "117: learn: 0.9589826\ttest: 0.9419604\tbestTest: 0.9422187 (20)\ttotal: 24.3s\tremaining: 1m 18s\n",
      "118: learn: 0.9591253\ttest: 0.9419967\tbestTest: 0.9422187 (20)\ttotal: 24.5s\tremaining: 1m 18s\n",
      "119: learn: 0.9592315\ttest: 0.9418877\tbestTest: 0.9422187 (20)\ttotal: 24.7s\tremaining: 1m 18s\n",
      "120: learn: 0.9594417\ttest: 0.9419927\tbestTest: 0.9422187 (20)\ttotal: 24.9s\tremaining: 1m 18s\n",
      "121: learn: 0.9596946\ttest: 0.9420169\tbestTest: 0.9422187 (20)\ttotal: 25.1s\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9422187235\n",
      "bestIteration = 20\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.959694570671 0.942016874571\n",
      "[0.94201687457107108]\n",
      "0: learn: 0.8949088\ttest: 0.8804485\tbestTest: 0.8804485 (0)\ttotal: 130ms\tremaining: 1m 4s\n",
      "1: learn: 0.9163982\ttest: 0.9202442\tbestTest: 0.9202442 (1)\ttotal: 329ms\tremaining: 1m 21s\n",
      "2: learn: 0.9238122\ttest: 0.9252128\tbestTest: 0.9252128 (2)\ttotal: 528ms\tremaining: 1m 27s\n",
      "3: learn: 0.9255683\ttest: 0.9248149\tbestTest: 0.9252128 (2)\ttotal: 728ms\tremaining: 1m 30s\n",
      "4: learn: 0.9290853\ttest: 0.9295975\tbestTest: 0.9295975 (4)\ttotal: 928ms\tremaining: 1m 31s\n",
      "5: learn: 0.931674\ttest: 0.9296516\tbestTest: 0.9296516 (5)\ttotal: 1.12s\tremaining: 1m 31s\n",
      "6: learn: 0.9320075\ttest: 0.9300083\tbestTest: 0.9300083 (6)\ttotal: 1.33s\tremaining: 1m 33s\n",
      "7: learn: 0.9324186\ttest: 0.9289035\tbestTest: 0.9300083 (6)\ttotal: 1.54s\tremaining: 1m 34s\n",
      "8: learn: 0.933159\ttest: 0.9305942\tbestTest: 0.9305942 (8)\ttotal: 1.75s\tremaining: 1m 35s\n",
      "9: learn: 0.9340096\ttest: 0.9325336\tbestTest: 0.9325336 (9)\ttotal: 1.97s\tremaining: 1m 36s\n",
      "10: learn: 0.9346506\ttest: 0.9331736\tbestTest: 0.9331736 (10)\ttotal: 2.18s\tremaining: 1m 36s\n",
      "11: learn: 0.9354985\ttest: 0.9347995\tbestTest: 0.9347995 (11)\ttotal: 2.39s\tremaining: 1m 37s\n",
      "12: learn: 0.935533\ttest: 0.9351455\tbestTest: 0.9351455 (12)\ttotal: 2.6s\tremaining: 1m 37s\n",
      "13: learn: 0.9356145\ttest: 0.9357206\tbestTest: 0.9357206 (13)\ttotal: 2.81s\tremaining: 1m 37s\n",
      "14: learn: 0.9362193\ttest: 0.9356038\tbestTest: 0.9357206 (13)\ttotal: 3.02s\tremaining: 1m 37s\n",
      "15: learn: 0.9369149\ttest: 0.9359844\tbestTest: 0.9359844 (15)\ttotal: 3.24s\tremaining: 1m 38s\n",
      "16: learn: 0.9373352\ttest: 0.9361746\tbestTest: 0.9361746 (16)\ttotal: 3.46s\tremaining: 1m 38s\n",
      "17: learn: 0.9377296\ttest: 0.9359973\tbestTest: 0.9361746 (16)\ttotal: 3.69s\tremaining: 1m 38s\n",
      "18: learn: 0.9378987\ttest: 0.9361141\tbestTest: 0.9361746 (16)\ttotal: 3.91s\tremaining: 1m 38s\n",
      "19: learn: 0.938394\ttest: 0.9355476\tbestTest: 0.9361746 (16)\ttotal: 4.13s\tremaining: 1m 39s\n",
      "20: learn: 0.9383347\ttest: 0.9354482\tbestTest: 0.9361746 (16)\ttotal: 4.35s\tremaining: 1m 39s\n",
      "21: learn: 0.9385459\ttest: 0.9354568\tbestTest: 0.9361746 (16)\ttotal: 4.57s\tremaining: 1m 39s\n",
      "22: learn: 0.938701\ttest: 0.9360017\tbestTest: 0.9361746 (16)\ttotal: 4.79s\tremaining: 1m 39s\n",
      "23: learn: 0.9387474\ttest: 0.9362611\tbestTest: 0.9362611 (23)\ttotal: 5.02s\tremaining: 1m 39s\n",
      "24: learn: 0.9388555\ttest: 0.935526\tbestTest: 0.9362611 (23)\ttotal: 5.24s\tremaining: 1m 39s\n",
      "25: learn: 0.9389987\ttest: 0.9358633\tbestTest: 0.9362611 (23)\ttotal: 5.46s\tremaining: 1m 39s\n",
      "26: learn: 0.9394893\ttest: 0.9357682\tbestTest: 0.9362611 (23)\ttotal: 5.67s\tremaining: 1m 39s\n",
      "27: learn: 0.939714\ttest: 0.9360103\tbestTest: 0.9362611 (23)\ttotal: 5.87s\tremaining: 1m 38s\n",
      "28: learn: 0.9400129\ttest: 0.9360752\tbestTest: 0.9362611 (23)\ttotal: 6.05s\tremaining: 1m 38s\n",
      "29: learn: 0.9403069\ttest: 0.9360622\tbestTest: 0.9362611 (23)\ttotal: 6.24s\tremaining: 1m 37s\n",
      "30: learn: 0.9405165\ttest: 0.9362568\tbestTest: 0.9362611 (23)\ttotal: 6.4s\tremaining: 1m 36s\n",
      "31: learn: 0.9407275\ttest: 0.9363346\tbestTest: 0.9363346 (31)\ttotal: 6.63s\tremaining: 1m 36s\n",
      "32: learn: 0.9409496\ttest: 0.9365162\tbestTest: 0.9365162 (32)\ttotal: 6.85s\tremaining: 1m 36s\n",
      "33: learn: 0.9412172\ttest: 0.9368103\tbestTest: 0.9368103 (33)\ttotal: 7.07s\tremaining: 1m 36s\n",
      "34: learn: 0.941331\ttest: 0.9368406\tbestTest: 0.9368406 (34)\ttotal: 7.29s\tremaining: 1m 36s\n",
      "35: learn: 0.9417889\ttest: 0.9367022\tbestTest: 0.9368406 (34)\ttotal: 7.51s\tremaining: 1m 36s\n",
      "36: learn: 0.9422025\ttest: 0.9366416\tbestTest: 0.9368406 (34)\ttotal: 7.73s\tremaining: 1m 36s\n",
      "37: learn: 0.9426747\ttest: 0.9364903\tbestTest: 0.9368406 (34)\ttotal: 7.95s\tremaining: 1m 36s\n",
      "38: learn: 0.9428264\ttest: 0.9365725\tbestTest: 0.9368406 (34)\ttotal: 8.18s\tremaining: 1m 36s\n",
      "39: learn: 0.9428483\ttest: 0.93662\tbestTest: 0.9368406 (34)\ttotal: 8.4s\tremaining: 1m 36s\n",
      "40: learn: 0.9429504\ttest: 0.9363822\tbestTest: 0.9368406 (34)\ttotal: 8.62s\tremaining: 1m 36s\n",
      "41: learn: 0.943189\ttest: 0.9363606\tbestTest: 0.9368406 (34)\ttotal: 8.84s\tremaining: 1m 36s\n",
      "42: learn: 0.9433349\ttest: 0.9363952\tbestTest: 0.9368406 (34)\ttotal: 9.06s\tremaining: 1m 36s\n",
      "43: learn: 0.9435051\ttest: 0.9364254\tbestTest: 0.9368406 (34)\ttotal: 9.27s\tremaining: 1m 36s\n",
      "44: learn: 0.943585\ttest: 0.9361184\tbestTest: 0.9368406 (34)\ttotal: 9.47s\tremaining: 1m 35s\n",
      "45: learn: 0.9437328\ttest: 0.9361054\tbestTest: 0.9368406 (34)\ttotal: 9.7s\tremaining: 1m 35s\n",
      "46: learn: 0.9438437\ttest: 0.9362481\tbestTest: 0.9368406 (34)\ttotal: 9.9s\tremaining: 1m 35s\n",
      "47: learn: 0.9441359\ttest: 0.9364514\tbestTest: 0.9368406 (34)\ttotal: 10.1s\tremaining: 1m 35s\n",
      "48: learn: 0.9443951\ttest: 0.9363952\tbestTest: 0.9368406 (34)\ttotal: 10.3s\tremaining: 1m 34s\n",
      "49: learn: 0.9445684\ttest: 0.9363217\tbestTest: 0.9368406 (34)\ttotal: 10.5s\tremaining: 1m 34s\n",
      "50: learn: 0.9447984\ttest: 0.9363389\tbestTest: 0.9368406 (34)\ttotal: 10.7s\tremaining: 1m 33s\n",
      "51: learn: 0.9450123\ttest: 0.9363\tbestTest: 0.9368406 (34)\ttotal: 10.9s\tremaining: 1m 33s\n",
      "52: learn: 0.9453187\ttest: 0.9361703\tbestTest: 0.9368406 (34)\ttotal: 11.1s\tremaining: 1m 33s\n",
      "53: learn: 0.9454558\ttest: 0.9362006\tbestTest: 0.9368406 (34)\ttotal: 11.3s\tremaining: 1m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54: learn: 0.9456461\ttest: 0.9363\tbestTest: 0.9368406 (34)\ttotal: 11.5s\tremaining: 1m 32s\n",
      "55: learn: 0.9457941\ttest: 0.9361617\tbestTest: 0.9368406 (34)\ttotal: 11.7s\tremaining: 1m 32s\n",
      "56: learn: 0.9459226\ttest: 0.936179\tbestTest: 0.9368406 (34)\ttotal: 11.9s\tremaining: 1m 32s\n",
      "57: learn: 0.9461017\ttest: 0.9363\tbestTest: 0.9368406 (34)\ttotal: 12.1s\tremaining: 1m 32s\n",
      "58: learn: 0.9463165\ttest: 0.9365898\tbestTest: 0.9368406 (34)\ttotal: 12.3s\tremaining: 1m 32s\n",
      "59: learn: 0.9467744\ttest: 0.9368233\tbestTest: 0.9368406 (34)\ttotal: 12.5s\tremaining: 1m 31s\n",
      "60: learn: 0.9468637\ttest: 0.9368492\tbestTest: 0.9368492 (60)\ttotal: 12.8s\tremaining: 1m 31s\n",
      "61: learn: 0.9470331\ttest: 0.9369184\tbestTest: 0.9369184 (61)\ttotal: 13s\tremaining: 1m 31s\n",
      "62: learn: 0.9473263\ttest: 0.9370611\tbestTest: 0.9370611 (62)\ttotal: 13.2s\tremaining: 1m 31s\n",
      "63: learn: 0.9476153\ttest: 0.9371951\tbestTest: 0.9371951 (63)\ttotal: 13.4s\tremaining: 1m 31s\n",
      "64: learn: 0.9478868\ttest: 0.9372081\tbestTest: 0.9372081 (64)\ttotal: 13.6s\tremaining: 1m 31s\n",
      "65: learn: 0.9480795\ttest: 0.9369703\tbestTest: 0.9372081 (64)\ttotal: 13.8s\tremaining: 1m 30s\n",
      "66: learn: 0.9481734\ttest: 0.9369097\tbestTest: 0.9372081 (64)\ttotal: 14s\tremaining: 1m 30s\n",
      "67: learn: 0.9484509\ttest: 0.9371\tbestTest: 0.9372081 (64)\ttotal: 14.2s\tremaining: 1m 30s\n",
      "68: learn: 0.9485995\ttest: 0.9369314\tbestTest: 0.9372081 (64)\ttotal: 14.4s\tremaining: 1m 30s\n",
      "69: learn: 0.9487767\ttest: 0.9369746\tbestTest: 0.9372081 (64)\ttotal: 14.6s\tremaining: 1m 29s\n",
      "70: learn: 0.9489926\ttest: 0.9369833\tbestTest: 0.9372081 (64)\ttotal: 14.9s\tremaining: 1m 29s\n",
      "71: learn: 0.9493036\ttest: 0.9369616\tbestTest: 0.9372081 (64)\ttotal: 15s\tremaining: 1m 29s\n",
      "72: learn: 0.949331\ttest: 0.9370524\tbestTest: 0.9372081 (64)\ttotal: 15.2s\tremaining: 1m 29s\n",
      "73: learn: 0.9496589\ttest: 0.9370092\tbestTest: 0.9372081 (64)\ttotal: 15.4s\tremaining: 1m 28s\n",
      "74: learn: 0.9499455\ttest: 0.9370697\tbestTest: 0.9372081 (64)\ttotal: 15.6s\tremaining: 1m 28s\n",
      "75: learn: 0.9502867\ttest: 0.9370092\tbestTest: 0.9372081 (64)\ttotal: 15.8s\tremaining: 1m 28s\n",
      "76: learn: 0.9504713\ttest: 0.9370092\tbestTest: 0.9372081 (64)\ttotal: 16s\tremaining: 1m 28s\n",
      "77: learn: 0.9506906\ttest: 0.9370049\tbestTest: 0.9372081 (64)\ttotal: 16.2s\tremaining: 1m 27s\n",
      "78: learn: 0.9509268\ttest: 0.9369227\tbestTest: 0.9372081 (64)\ttotal: 16.6s\tremaining: 1m 28s\n",
      "79: learn: 0.9510942\ttest: 0.9368449\tbestTest: 0.9372081 (64)\ttotal: 16.8s\tremaining: 1m 28s\n",
      "80: learn: 0.9514317\ttest: 0.9368665\tbestTest: 0.9372081 (64)\ttotal: 17s\tremaining: 1m 28s\n",
      "81: learn: 0.9515335\ttest: 0.9369746\tbestTest: 0.9372081 (64)\ttotal: 17.2s\tremaining: 1m 27s\n",
      "82: learn: 0.9516364\ttest: 0.9370784\tbestTest: 0.9372081 (64)\ttotal: 17.5s\tremaining: 1m 27s\n",
      "83: learn: 0.9517479\ttest: 0.9370351\tbestTest: 0.9372081 (64)\ttotal: 17.7s\tremaining: 1m 27s\n",
      "84: learn: 0.9519144\ttest: 0.9370741\tbestTest: 0.9372081 (64)\ttotal: 17.9s\tremaining: 1m 27s\n",
      "85: learn: 0.9520324\ttest: 0.9370438\tbestTest: 0.9372081 (64)\ttotal: 18.1s\tremaining: 1m 27s\n",
      "86: learn: 0.9523663\ttest: 0.9368924\tbestTest: 0.9372081 (64)\ttotal: 18.3s\tremaining: 1m 26s\n",
      "87: learn: 0.9525587\ttest: 0.9369487\tbestTest: 0.9372081 (64)\ttotal: 18.5s\tremaining: 1m 26s\n",
      "88: learn: 0.9527112\ttest: 0.9367152\tbestTest: 0.9372081 (64)\ttotal: 18.8s\tremaining: 1m 26s\n",
      "89: learn: 0.9528167\ttest: 0.9368319\tbestTest: 0.9372081 (64)\ttotal: 19s\tremaining: 1m 26s\n",
      "90: learn: 0.95319\ttest: 0.9366027\tbestTest: 0.9372081 (64)\ttotal: 19.2s\tremaining: 1m 26s\n",
      "91: learn: 0.9534432\ttest: 0.9365206\tbestTest: 0.9372081 (64)\ttotal: 19.4s\tremaining: 1m 25s\n",
      "92: learn: 0.9536847\ttest: 0.9364211\tbestTest: 0.9372081 (64)\ttotal: 19.6s\tremaining: 1m 25s\n",
      "93: learn: 0.9539813\ttest: 0.9359584\tbestTest: 0.9372081 (64)\ttotal: 19.8s\tremaining: 1m 25s\n",
      "94: learn: 0.9542645\ttest: 0.9360708\tbestTest: 0.9372081 (64)\ttotal: 20s\tremaining: 1m 25s\n",
      "95: learn: 0.9544916\ttest: 0.9362092\tbestTest: 0.9372081 (64)\ttotal: 20.2s\tremaining: 1m 24s\n",
      "96: learn: 0.954659\ttest: 0.9362092\tbestTest: 0.9372081 (64)\ttotal: 20.4s\tremaining: 1m 24s\n",
      "97: learn: 0.9546966\ttest: 0.9363087\tbestTest: 0.9372081 (64)\ttotal: 20.6s\tremaining: 1m 24s\n",
      "98: learn: 0.954944\ttest: 0.9363476\tbestTest: 0.9372081 (64)\ttotal: 20.8s\tremaining: 1m 24s\n",
      "99: learn: 0.9551012\ttest: 0.9363995\tbestTest: 0.9372081 (64)\ttotal: 21s\tremaining: 1m 24s\n",
      "100: learn: 0.9553445\ttest: 0.9365076\tbestTest: 0.9372081 (64)\ttotal: 21.2s\tremaining: 1m 23s\n",
      "101: learn: 0.9555714\ttest: 0.9364081\tbestTest: 0.9372081 (64)\ttotal: 21.4s\tremaining: 1m 23s\n",
      "102: learn: 0.9557458\ttest: 0.936313\tbestTest: 0.9372081 (64)\ttotal: 21.7s\tremaining: 1m 23s\n",
      "103: learn: 0.9558755\ttest: 0.9362481\tbestTest: 0.9372081 (64)\ttotal: 21.9s\tremaining: 1m 23s\n",
      "104: learn: 0.9560306\ttest: 0.9363173\tbestTest: 0.9372081 (64)\ttotal: 22.1s\tremaining: 1m 23s\n",
      "105: learn: 0.9562702\ttest: 0.9363044\tbestTest: 0.9372081 (64)\ttotal: 22.3s\tremaining: 1m 22s\n",
      "106: learn: 0.9563715\ttest: 0.9363606\tbestTest: 0.9372081 (64)\ttotal: 22.6s\tremaining: 1m 22s\n",
      "107: learn: 0.9565242\ttest: 0.9363822\tbestTest: 0.9372081 (64)\ttotal: 22.8s\tremaining: 1m 22s\n",
      "108: learn: 0.9567623\ttest: 0.9363\tbestTest: 0.9372081 (64)\ttotal: 23s\tremaining: 1m 22s\n",
      "109: learn: 0.9569106\ttest: 0.9363389\tbestTest: 0.9372081 (64)\ttotal: 23.2s\tremaining: 1m 22s\n",
      "110: learn: 0.9573014\ttest: 0.9363908\tbestTest: 0.9372081 (64)\ttotal: 23.3s\tremaining: 1m 21s\n",
      "111: learn: 0.9574051\ttest: 0.9363865\tbestTest: 0.9372081 (64)\ttotal: 23.5s\tremaining: 1m 21s\n",
      "112: learn: 0.9575061\ttest: 0.936326\tbestTest: 0.9372081 (64)\ttotal: 23.7s\tremaining: 1m 21s\n",
      "113: learn: 0.9577512\ttest: 0.9362957\tbestTest: 0.9372081 (64)\ttotal: 23.9s\tremaining: 1m 21s\n",
      "114: learn: 0.9580303\ttest: 0.9363822\tbestTest: 0.9372081 (64)\ttotal: 24.2s\tremaining: 1m 20s\n",
      "115: learn: 0.9581219\ttest: 0.9363217\tbestTest: 0.9372081 (64)\ttotal: 24.4s\tremaining: 1m 20s\n",
      "116: learn: 0.9583788\ttest: 0.9363649\tbestTest: 0.9372081 (64)\ttotal: 24.5s\tremaining: 1m 20s\n",
      "117: learn: 0.9585676\ttest: 0.9361184\tbestTest: 0.9372081 (64)\ttotal: 24.7s\tremaining: 1m 20s\n",
      "118: learn: 0.9589038\ttest: 0.9361357\tbestTest: 0.9372081 (64)\ttotal: 24.9s\tremaining: 1m 19s\n",
      "119: learn: 0.9590589\ttest: 0.9361703\tbestTest: 0.9372081 (64)\ttotal: 25.2s\tremaining: 1m 19s\n",
      "120: learn: 0.9591349\ttest: 0.9361746\tbestTest: 0.9372081 (64)\ttotal: 25.4s\tremaining: 1m 19s\n",
      "121: learn: 0.9594719\ttest: 0.9361573\tbestTest: 0.9372081 (64)\ttotal: 25.6s\tremaining: 1m 19s\n",
      "122: learn: 0.9597343\ttest: 0.9359195\tbestTest: 0.9372081 (64)\ttotal: 25.8s\tremaining: 1m 19s\n",
      "123: learn: 0.9599961\ttest: 0.9358806\tbestTest: 0.9372081 (64)\ttotal: 26s\tremaining: 1m 18s\n",
      "124: learn: 0.9603015\ttest: 0.9361487\tbestTest: 0.9372081 (64)\ttotal: 26.2s\tremaining: 1m 18s\n",
      "125: learn: 0.9605999\ttest: 0.9362438\tbestTest: 0.9372081 (64)\ttotal: 26.4s\tremaining: 1m 18s\n",
      "126: learn: 0.9607861\ttest: 0.9361703\tbestTest: 0.9372081 (64)\ttotal: 26.6s\tremaining: 1m 18s\n",
      "127: learn: 0.9610641\ttest: 0.9360449\tbestTest: 0.9372081 (64)\ttotal: 26.9s\tremaining: 1m 18s\n",
      "128: learn: 0.961422\ttest: 0.93598\tbestTest: 0.9372081 (64)\ttotal: 27.1s\tremaining: 1m 18s\n",
      "129: learn: 0.9615541\ttest: 0.9359152\tbestTest: 0.9372081 (64)\ttotal: 27.4s\tremaining: 1m 17s\n",
      "130: learn: 0.9617134\ttest: 0.9358546\tbestTest: 0.9372081 (64)\ttotal: 27.6s\tremaining: 1m 17s\n",
      "131: learn: 0.9620245\ttest: 0.9356125\tbestTest: 0.9372081 (64)\ttotal: 27.8s\tremaining: 1m 17s\n",
      "132: learn: 0.9622363\ttest: 0.9355865\tbestTest: 0.9372081 (64)\ttotal: 27.9s\tremaining: 1m 17s\n",
      "133: learn: 0.9624054\ttest: 0.9355433\tbestTest: 0.9372081 (64)\ttotal: 28.1s\tremaining: 1m 16s\n",
      "134: learn: 0.9626038\ttest: 0.9356255\tbestTest: 0.9372081 (64)\ttotal: 28.3s\tremaining: 1m 16s\n",
      "135: learn: 0.9627526\ttest: 0.93566\tbestTest: 0.9372081 (64)\ttotal: 28.5s\tremaining: 1m 16s\n",
      "136: learn: 0.9628798\ttest: 0.93566\tbestTest: 0.9372081 (64)\ttotal: 28.7s\tremaining: 1m 16s\n",
      "137: learn: 0.9631356\ttest: 0.9355909\tbestTest: 0.9372081 (64)\ttotal: 28.9s\tremaining: 1m 15s\n",
      "138: learn: 0.9634507\ttest: 0.9353357\tbestTest: 0.9372081 (64)\ttotal: 29.1s\tremaining: 1m 15s\n",
      "139: learn: 0.9637285\ttest: 0.9353401\tbestTest: 0.9372081 (64)\ttotal: 29.3s\tremaining: 1m 15s\n",
      "140: learn: 0.9638919\ttest: 0.9352795\tbestTest: 0.9372081 (64)\ttotal: 29.5s\tremaining: 1m 15s\n",
      "141: learn: 0.9642389\ttest: 0.9353833\tbestTest: 0.9372081 (64)\ttotal: 29.7s\tremaining: 1m 15s\n",
      "142: learn: 0.9643253\ttest: 0.9353919\tbestTest: 0.9372081 (64)\ttotal: 30s\tremaining: 1m 14s\n",
      "143: learn: 0.9644561\ttest: 0.9352276\tbestTest: 0.9372081 (64)\ttotal: 30.2s\tremaining: 1m 14s\n",
      "144: learn: 0.964537\ttest: 0.9352233\tbestTest: 0.9372081 (64)\ttotal: 30.4s\tremaining: 1m 14s\n",
      "145: learn: 0.9647017\ttest: 0.9351238\tbestTest: 0.9372081 (64)\ttotal: 30.6s\tremaining: 1m 14s\n",
      "146: learn: 0.964963\ttest: 0.9352752\tbestTest: 0.9372081 (64)\ttotal: 30.8s\tremaining: 1m 14s\n",
      "147: learn: 0.9651505\ttest: 0.9353271\tbestTest: 0.9372081 (64)\ttotal: 31s\tremaining: 1m 13s\n",
      "148: learn: 0.9654115\ttest: 0.9352622\tbestTest: 0.9372081 (64)\ttotal: 31.3s\tremaining: 1m 13s\n",
      "149: learn: 0.9656011\ttest: 0.9352103\tbestTest: 0.9372081 (64)\ttotal: 31.5s\tremaining: 1m 13s\n",
      "150: learn: 0.9657979\ttest: 0.935232\tbestTest: 0.9372081 (64)\ttotal: 31.7s\tremaining: 1m 13s\n",
      "151: learn: 0.9659903\ttest: 0.9352882\tbestTest: 0.9372081 (64)\ttotal: 31.9s\tremaining: 1m 13s\n",
      "152: learn: 0.9662931\ttest: 0.9353919\tbestTest: 0.9372081 (64)\ttotal: 32.1s\tremaining: 1m 12s\n",
      "153: learn: 0.9665652\ttest: 0.9353833\tbestTest: 0.9372081 (64)\ttotal: 32.3s\tremaining: 1m 12s\n",
      "154: learn: 0.9667414\ttest: 0.9354482\tbestTest: 0.9372081 (64)\ttotal: 32.5s\tremaining: 1m 12s\n",
      "155: learn: 0.9669672\ttest: 0.935353\tbestTest: 0.9372081 (64)\ttotal: 32.7s\tremaining: 1m 12s\n",
      "156: learn: 0.9671847\ttest: 0.935379\tbestTest: 0.9372081 (64)\ttotal: 32.9s\tremaining: 1m 11s\n",
      "157: learn: 0.9674713\ttest: 0.935353\tbestTest: 0.9372081 (64)\ttotal: 33.1s\tremaining: 1m 11s\n",
      "158: learn: 0.9676363\ttest: 0.9354265\tbestTest: 0.9372081 (64)\ttotal: 33.3s\tremaining: 1m 11s\n",
      "159: learn: 0.9678253\ttest: 0.9352795\tbestTest: 0.9372081 (64)\ttotal: 33.5s\tremaining: 1m 11s\n",
      "160: learn: 0.9680965\ttest: 0.9352925\tbestTest: 0.9372081 (64)\ttotal: 33.7s\tremaining: 1m 10s\n",
      "161: learn: 0.9682756\ttest: 0.9352968\tbestTest: 0.9372081 (64)\ttotal: 33.9s\tremaining: 1m 10s\n",
      "162: learn: 0.9684009\ttest: 0.9355606\tbestTest: 0.9372081 (64)\ttotal: 34.1s\tremaining: 1m 10s\n",
      "163: learn: 0.9686315\ttest: 0.9355303\tbestTest: 0.9372081 (64)\ttotal: 34.3s\tremaining: 1m 10s\n",
      "164: learn: 0.9687923\ttest: 0.9354092\tbestTest: 0.9372081 (64)\ttotal: 34.5s\tremaining: 1m 10s\n",
      "165: learn: 0.9689714\ttest: 0.9354049\tbestTest: 0.9372081 (64)\ttotal: 34.7s\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9372081157\n",
      "bestIteration = 64\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.968971363202 0.935404919224\n",
      "[0.94201687457107108, 0.93540491922371738]\n",
      "0: learn: 0.9001752\ttest: 0.9086098\tbestTest: 0.9086098 (0)\ttotal: 150ms\tremaining: 1m 14s\n",
      "1: learn: 0.9030122\ttest: 0.9093459\tbestTest: 0.9093459 (1)\ttotal: 371ms\tremaining: 1m 32s\n",
      "2: learn: 0.9144145\ttest: 0.9174698\tbestTest: 0.9174698 (2)\ttotal: 593ms\tremaining: 1m 38s\n",
      "3: learn: 0.9174911\ttest: 0.9231019\tbestTest: 0.9231019 (3)\ttotal: 815ms\tremaining: 1m 41s\n",
      "4: learn: 0.9289072\ttest: 0.936026\tbestTest: 0.936026 (4)\ttotal: 1.05s\tremaining: 1m 44s\n",
      "5: learn: 0.9295828\ttest: 0.9395521\tbestTest: 0.9395521 (5)\ttotal: 1.28s\tremaining: 1m 45s\n",
      "6: learn: 0.9292697\ttest: 0.9402214\tbestTest: 0.9402214 (6)\ttotal: 1.5s\tremaining: 1m 45s\n",
      "7: learn: 0.9298859\ttest: 0.9395021\tbestTest: 0.9402214 (6)\ttotal: 1.73s\tremaining: 1m 46s\n",
      "8: learn: 0.9309987\ttest: 0.9397523\tbestTest: 0.9402214 (6)\ttotal: 1.94s\tremaining: 1m 46s\n",
      "9: learn: 0.9310809\ttest: 0.939844\tbestTest: 0.9402214 (6)\ttotal: 2.13s\tremaining: 1m 44s\n",
      "10: learn: 0.9312014\ttest: 0.939673\tbestTest: 0.9402214 (6)\ttotal: 2.29s\tremaining: 1m 41s\n",
      "11: learn: 0.9331795\ttest: 0.9402527\tbestTest: 0.9402527 (11)\ttotal: 2.5s\tremaining: 1m 41s\n",
      "12: learn: 0.9338628\ttest: 0.9398649\tbestTest: 0.9402527 (11)\ttotal: 2.7s\tremaining: 1m 41s\n",
      "13: learn: 0.9338329\ttest: 0.9403987\tbestTest: 0.9403987 (13)\ttotal: 2.91s\tremaining: 1m 41s\n",
      "14: learn: 0.9359857\ttest: 0.9404738\tbestTest: 0.9404738 (14)\ttotal: 3.08s\tremaining: 1m 39s\n",
      "15: learn: 0.9361134\ttest: 0.941018\tbestTest: 0.941018 (15)\ttotal: 3.29s\tremaining: 1m 39s\n",
      "16: learn: 0.9364998\ttest: 0.9417145\tbestTest: 0.9417145 (16)\ttotal: 3.5s\tremaining: 1m 39s\n",
      "17: learn: 0.9372728\ttest: 0.9419855\tbestTest: 0.9419855 (17)\ttotal: 3.72s\tremaining: 1m 39s\n",
      "18: learn: 0.937429\ttest: 0.9414184\tbestTest: 0.9419855 (17)\ttotal: 3.94s\tremaining: 1m 39s\n",
      "19: learn: 0.9376197\ttest: 0.9415018\tbestTest: 0.9419855 (17)\ttotal: 4.31s\tremaining: 1m 43s\n",
      "20: learn: 0.9378778\ttest: 0.9416978\tbestTest: 0.9419855 (17)\ttotal: 4.53s\tremaining: 1m 43s\n",
      "21: learn: 0.937984\ttest: 0.9421357\tbestTest: 0.9421357 (21)\ttotal: 4.73s\tremaining: 1m 42s\n",
      "22: learn: 0.9383227\ttest: 0.9416811\tbestTest: 0.9421357 (21)\ttotal: 4.95s\tremaining: 1m 42s\n",
      "23: learn: 0.9384133\ttest: 0.9418187\tbestTest: 0.9421357 (21)\ttotal: 5.17s\tremaining: 1m 42s\n",
      "24: learn: 0.9384473\ttest: 0.9421357\tbestTest: 0.9421357 (24)\ttotal: 5.52s\tremaining: 1m 44s\n",
      "25: learn: 0.9386137\ttest: 0.9420147\tbestTest: 0.9421357 (24)\ttotal: 5.74s\tremaining: 1m 44s\n",
      "26: learn: 0.9387757\ttest: 0.9419313\tbestTest: 0.9421357 (24)\ttotal: 5.96s\tremaining: 1m 44s\n",
      "27: learn: 0.9388057\ttest: 0.9423358\tbestTest: 0.9423358 (27)\ttotal: 6.2s\tremaining: 1m 44s\n",
      "28: learn: 0.9389174\ttest: 0.9423108\tbestTest: 0.9423358 (27)\ttotal: 6.42s\tremaining: 1m 44s\n",
      "29: learn: 0.9391255\ttest: 0.9424484\tbestTest: 0.9424484 (29)\ttotal: 6.78s\tremaining: 1m 46s\n",
      "30: learn: 0.9392432\ttest: 0.9426445\tbestTest: 0.9426445 (30)\ttotal: 6.99s\tremaining: 1m 45s\n",
      "31: learn: 0.939622\ttest: 0.9426653\tbestTest: 0.9426653 (31)\ttotal: 7.15s\tremaining: 1m 44s\n",
      "32: learn: 0.9397202\ttest: 0.9425193\tbestTest: 0.9426653 (31)\ttotal: 7.36s\tremaining: 1m 44s\n",
      "33: learn: 0.9399728\ttest: 0.942682\tbestTest: 0.942682 (33)\ttotal: 7.56s\tremaining: 1m 43s\n",
      "34: learn: 0.9407493\ttest: 0.9425527\tbestTest: 0.942682 (33)\ttotal: 7.93s\tremaining: 1m 45s\n",
      "35: learn: 0.9410677\ttest: 0.9424818\tbestTest: 0.942682 (33)\ttotal: 8.15s\tremaining: 1m 45s\n",
      "36: learn: 0.9413411\ttest: 0.9421732\tbestTest: 0.942682 (33)\ttotal: 8.36s\tremaining: 1m 44s\n",
      "37: learn: 0.9414628\ttest: 0.9420981\tbestTest: 0.942682 (33)\ttotal: 8.57s\tremaining: 1m 44s\n",
      "38: learn: 0.9416027\ttest: 0.941998\tbestTest: 0.942682 (33)\ttotal: 8.78s\tremaining: 1m 43s\n",
      "39: learn: 0.9418729\ttest: 0.9422983\tbestTest: 0.942682 (33)\ttotal: 9.15s\tremaining: 1m 45s\n",
      "40: learn: 0.9419669\ttest: 0.9423025\tbestTest: 0.942682 (33)\ttotal: 9.37s\tremaining: 1m 44s\n",
      "41: learn: 0.9421452\ttest: 0.9424484\tbestTest: 0.942682 (33)\ttotal: 9.58s\tremaining: 1m 44s\n",
      "42: learn: 0.9424052\ttest: 0.9426027\tbestTest: 0.942682 (33)\ttotal: 9.79s\tremaining: 1m 44s\n",
      "43: learn: 0.9426488\ttest: 0.9427779\tbestTest: 0.9427779 (43)\ttotal: 9.99s\tremaining: 1m 43s\n",
      "44: learn: 0.9429343\ttest: 0.9426945\tbestTest: 0.9427779 (43)\ttotal: 10.3s\tremaining: 1m 44s\n",
      "45: learn: 0.9433086\ttest: 0.9424818\tbestTest: 0.9427779 (43)\ttotal: 10.6s\tremaining: 1m 44s\n",
      "46: learn: 0.9435299\ttest: 0.9424109\tbestTest: 0.9427779 (43)\ttotal: 10.8s\tremaining: 1m 43s\n",
      "47: learn: 0.9437127\ttest: 0.9422316\tbestTest: 0.9427779 (43)\ttotal: 11s\tremaining: 1m 43s\n",
      "48: learn: 0.9439402\ttest: 0.9425485\tbestTest: 0.9427779 (43)\ttotal: 11.2s\tremaining: 1m 42s\n",
      "49: learn: 0.9441201\ttest: 0.9422691\tbestTest: 0.9427779 (43)\ttotal: 11.6s\tremaining: 1m 44s\n",
      "50: learn: 0.9442015\ttest: 0.9420773\tbestTest: 0.9427779 (43)\ttotal: 11.8s\tremaining: 1m 44s\n",
      "51: learn: 0.9444064\ttest: 0.9418646\tbestTest: 0.9427779 (43)\ttotal: 12s\tremaining: 1m 43s\n",
      "52: learn: 0.9448228\ttest: 0.9418729\tbestTest: 0.9427779 (43)\ttotal: 12.2s\tremaining: 1m 43s\n",
      "53: learn: 0.9448939\ttest: 0.9417395\tbestTest: 0.9427779 (43)\ttotal: 12.4s\tremaining: 1m 42s\n",
      "54: learn: 0.9451426\ttest: 0.9420356\tbestTest: 0.9427779 (43)\ttotal: 12.7s\tremaining: 1m 43s\n",
      "55: learn: 0.945486\ttest: 0.9419021\tbestTest: 0.9427779 (43)\ttotal: 12.9s\tremaining: 1m 42s\n",
      "56: learn: 0.9455816\ttest: 0.9419188\tbestTest: 0.9427779 (43)\ttotal: 13.1s\tremaining: 1m 42s\n",
      "57: learn: 0.9457586\ttest: 0.9420773\tbestTest: 0.9427779 (43)\ttotal: 13.3s\tremaining: 1m 41s\n",
      "58: learn: 0.9459235\ttest: 0.9420022\tbestTest: 0.9427779 (43)\ttotal: 13.5s\tremaining: 1m 41s\n",
      "59: learn: 0.9464203\ttest: 0.9422358\tbestTest: 0.9427779 (43)\ttotal: 13.9s\tremaining: 1m 42s\n",
      "60: learn: 0.9465989\ttest: 0.9421482\tbestTest: 0.9427779 (43)\ttotal: 14.1s\tremaining: 1m 41s\n",
      "61: learn: 0.9470219\ttest: 0.9423775\tbestTest: 0.9427779 (43)\ttotal: 14.3s\tremaining: 1m 41s\n",
      "62: learn: 0.9470967\ttest: 0.9422858\tbestTest: 0.9427779 (43)\ttotal: 14.6s\tremaining: 1m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63: learn: 0.9473814\ttest: 0.942119\tbestTest: 0.9427779 (43)\ttotal: 14.8s\tremaining: 1m 40s\n",
      "64: learn: 0.9475265\ttest: 0.942144\tbestTest: 0.9427779 (43)\ttotal: 15.1s\tremaining: 1m 41s\n",
      "65: learn: 0.9476885\ttest: 0.9422566\tbestTest: 0.9427779 (43)\ttotal: 15.3s\tremaining: 1m 40s\n",
      "66: learn: 0.9477733\ttest: 0.9422941\tbestTest: 0.9427779 (43)\ttotal: 15.6s\tremaining: 1m 40s\n",
      "67: learn: 0.948078\ttest: 0.9422441\tbestTest: 0.9427779 (43)\ttotal: 15.8s\tremaining: 1m 40s\n",
      "68: learn: 0.9484021\ttest: 0.9423942\tbestTest: 0.9427779 (43)\ttotal: 16s\tremaining: 1m 39s\n",
      "69: learn: 0.9487804\ttest: 0.9426445\tbestTest: 0.9427779 (43)\ttotal: 16.4s\tremaining: 1m 40s\n",
      "70: learn: 0.9489247\ttest: 0.9426153\tbestTest: 0.9427779 (43)\ttotal: 16.7s\tremaining: 1m 40s\n",
      "71: learn: 0.949137\ttest: 0.9427195\tbestTest: 0.9427779 (43)\ttotal: 17s\tremaining: 1m 41s\n",
      "72: learn: 0.9492197\ttest: 0.9425902\tbestTest: 0.9427779 (43)\ttotal: 17.4s\tremaining: 1m 41s\n",
      "73: learn: 0.9493709\ttest: 0.9424735\tbestTest: 0.9427779 (43)\ttotal: 17.8s\tremaining: 1m 42s\n",
      "74: learn: 0.9496029\ttest: 0.9425485\tbestTest: 0.9427779 (43)\ttotal: 18.1s\tremaining: 1m 42s\n",
      "75: learn: 0.949781\ttest: 0.942536\tbestTest: 0.9427779 (43)\ttotal: 18.5s\tremaining: 1m 43s\n",
      "76: learn: 0.9500225\ttest: 0.9426027\tbestTest: 0.9427779 (43)\ttotal: 18.9s\tremaining: 1m 43s\n",
      "77: learn: 0.950199\ttest: 0.942486\tbestTest: 0.9427779 (43)\ttotal: 19.3s\tremaining: 1m 44s\n",
      "78: learn: 0.950303\ttest: 0.942486\tbestTest: 0.9427779 (43)\ttotal: 19.7s\tremaining: 1m 44s\n",
      "79: learn: 0.9504803\ttest: 0.94229\tbestTest: 0.9427779 (43)\ttotal: 20s\tremaining: 1m 45s\n",
      "80: learn: 0.9506894\ttest: 0.9421732\tbestTest: 0.9427779 (43)\ttotal: 20.4s\tremaining: 1m 45s\n",
      "81: learn: 0.9509565\ttest: 0.9419814\tbestTest: 0.9427779 (43)\ttotal: 20.8s\tremaining: 1m 46s\n",
      "82: learn: 0.9509438\ttest: 0.9420189\tbestTest: 0.9427779 (43)\ttotal: 21.1s\tremaining: 1m 46s\n",
      "83: learn: 0.951262\ttest: 0.9419313\tbestTest: 0.9427779 (43)\ttotal: 21.3s\tremaining: 1m 45s\n",
      "84: learn: 0.9513916\ttest: 0.941973\tbestTest: 0.9427779 (43)\ttotal: 21.5s\tremaining: 1m 45s\n",
      "85: learn: 0.9516342\ttest: 0.9419814\tbestTest: 0.9427779 (43)\ttotal: 21.7s\tremaining: 1m 44s\n",
      "86: learn: 0.9517171\ttest: 0.942169\tbestTest: 0.9427779 (43)\ttotal: 21.9s\tremaining: 1m 44s\n",
      "87: learn: 0.9520184\ttest: 0.9424985\tbestTest: 0.9427779 (43)\ttotal: 22.2s\tremaining: 1m 43s\n",
      "88: learn: 0.9524338\ttest: 0.9425485\tbestTest: 0.9427779 (43)\ttotal: 22.4s\tremaining: 1m 43s\n",
      "89: learn: 0.9526287\ttest: 0.9424067\tbestTest: 0.9427779 (43)\ttotal: 22.6s\tremaining: 1m 42s\n",
      "90: learn: 0.9527138\ttest: 0.9423066\tbestTest: 0.9427779 (43)\ttotal: 22.8s\tremaining: 1m 42s\n",
      "91: learn: 0.9528995\ttest: 0.9422483\tbestTest: 0.9427779 (43)\ttotal: 23s\tremaining: 1m 41s\n",
      "92: learn: 0.9530227\ttest: 0.9422066\tbestTest: 0.9427779 (43)\ttotal: 23.2s\tremaining: 1m 41s\n",
      "93: learn: 0.9533185\ttest: 0.9421899\tbestTest: 0.9427779 (43)\ttotal: 23.4s\tremaining: 1m 41s\n",
      "94: learn: 0.953603\ttest: 0.9422358\tbestTest: 0.9427779 (43)\ttotal: 23.6s\tremaining: 1m 40s\n",
      "95: learn: 0.9538685\ttest: 0.9423233\tbestTest: 0.9427779 (43)\ttotal: 23.8s\tremaining: 1m 40s\n",
      "96: learn: 0.9541532\ttest: 0.9422733\tbestTest: 0.9427779 (43)\ttotal: 24s\tremaining: 1m 39s\n",
      "97: learn: 0.9544068\ttest: 0.9424276\tbestTest: 0.9427779 (43)\ttotal: 24.2s\tremaining: 1m 39s\n",
      "98: learn: 0.9547708\ttest: 0.9423692\tbestTest: 0.9427779 (43)\ttotal: 24.4s\tremaining: 1m 39s\n",
      "99: learn: 0.9550171\ttest: 0.9424901\tbestTest: 0.9427779 (43)\ttotal: 24.7s\tremaining: 1m 38s\n",
      "100: learn: 0.9552918\ttest: 0.9423817\tbestTest: 0.9427779 (43)\ttotal: 24.9s\tremaining: 1m 38s\n",
      "101: learn: 0.955473\ttest: 0.9424818\tbestTest: 0.9427779 (43)\ttotal: 25.1s\tremaining: 1m 37s\n",
      "102: learn: 0.9556553\ttest: 0.9424651\tbestTest: 0.9427779 (43)\ttotal: 25.3s\tremaining: 1m 37s\n",
      "103: learn: 0.956014\ttest: 0.9425861\tbestTest: 0.9427779 (43)\ttotal: 25.5s\tremaining: 1m 37s\n",
      "104: learn: 0.9562558\ttest: 0.942657\tbestTest: 0.9427779 (43)\ttotal: 25.7s\tremaining: 1m 36s\n",
      "105: learn: 0.9563259\ttest: 0.9425277\tbestTest: 0.9427779 (43)\ttotal: 26s\tremaining: 1m 36s\n",
      "106: learn: 0.9566412\ttest: 0.942461\tbestTest: 0.9427779 (43)\ttotal: 26.2s\tremaining: 1m 36s\n",
      "107: learn: 0.9569045\ttest: 0.9425819\tbestTest: 0.9427779 (43)\ttotal: 26.4s\tremaining: 1m 35s\n",
      "108: learn: 0.9571434\ttest: 0.9427153\tbestTest: 0.9427779 (43)\ttotal: 26.6s\tremaining: 1m 35s\n",
      "109: learn: 0.9573075\ttest: 0.9427988\tbestTest: 0.9427988 (109)\ttotal: 26.8s\tremaining: 1m 35s\n",
      "110: learn: 0.9575209\ttest: 0.9429114\tbestTest: 0.9429114 (110)\ttotal: 27s\tremaining: 1m 34s\n",
      "111: learn: 0.9578625\ttest: 0.9428613\tbestTest: 0.9429114 (110)\ttotal: 27.2s\tremaining: 1m 34s\n",
      "112: learn: 0.9580226\ttest: 0.9428655\tbestTest: 0.9429114 (110)\ttotal: 27.4s\tremaining: 1m 33s\n",
      "113: learn: 0.9581156\ttest: 0.9428822\tbestTest: 0.9429114 (110)\ttotal: 27.6s\tremaining: 1m 33s\n",
      "114: learn: 0.9583421\ttest: 0.9427821\tbestTest: 0.9429114 (110)\ttotal: 27.8s\tremaining: 1m 33s\n",
      "115: learn: 0.958517\ttest: 0.9426361\tbestTest: 0.9429114 (110)\ttotal: 28.1s\tremaining: 1m 32s\n",
      "116: learn: 0.9587325\ttest: 0.9425902\tbestTest: 0.9429114 (110)\ttotal: 28.3s\tremaining: 1m 32s\n",
      "117: learn: 0.9588805\ttest: 0.9425652\tbestTest: 0.9429114 (110)\ttotal: 28.5s\tremaining: 1m 32s\n",
      "118: learn: 0.9589687\ttest: 0.942486\tbestTest: 0.9429114 (110)\ttotal: 28.7s\tremaining: 1m 31s\n",
      "119: learn: 0.9590841\ttest: 0.9425527\tbestTest: 0.9429114 (110)\ttotal: 28.9s\tremaining: 1m 31s\n",
      "120: learn: 0.9592648\ttest: 0.9426069\tbestTest: 0.9429114 (110)\ttotal: 29.1s\tremaining: 1m 31s\n",
      "121: learn: 0.9594981\ttest: 0.9427612\tbestTest: 0.9429114 (110)\ttotal: 29.3s\tremaining: 1m 30s\n",
      "122: learn: 0.95983\ttest: 0.9429114\tbestTest: 0.9429114 (122)\ttotal: 29.5s\tremaining: 1m 30s\n",
      "123: learn: 0.96017\ttest: 0.9428738\tbestTest: 0.9429114 (122)\ttotal: 29.8s\tremaining: 1m 30s\n",
      "124: learn: 0.9604245\ttest: 0.9427737\tbestTest: 0.9429114 (122)\ttotal: 30s\tremaining: 1m 29s\n",
      "125: learn: 0.960637\ttest: 0.9428029\tbestTest: 0.9429114 (122)\ttotal: 30.2s\tremaining: 1m 29s\n",
      "126: learn: 0.9608712\ttest: 0.9427821\tbestTest: 0.9429114 (122)\ttotal: 30.4s\tremaining: 1m 29s\n",
      "127: learn: 0.960976\ttest: 0.9427362\tbestTest: 0.9429114 (122)\ttotal: 30.6s\tremaining: 1m 29s\n",
      "128: learn: 0.9612149\ttest: 0.9428488\tbestTest: 0.9429114 (122)\ttotal: 30.9s\tremaining: 1m 28s\n",
      "129: learn: 0.9612997\ttest: 0.9428488\tbestTest: 0.9429114 (122)\ttotal: 31.1s\tremaining: 1m 28s\n",
      "130: learn: 0.9616674\ttest: 0.942828\tbestTest: 0.9429114 (122)\ttotal: 31.3s\tremaining: 1m 28s\n",
      "131: learn: 0.9618241\ttest: 0.9429948\tbestTest: 0.9429948 (131)\ttotal: 31.5s\tremaining: 1m 27s\n",
      "132: learn: 0.9620598\ttest: 0.9426945\tbestTest: 0.9429948 (131)\ttotal: 31.8s\tremaining: 1m 27s\n",
      "133: learn: 0.9622158\ttest: 0.9424943\tbestTest: 0.9429948 (131)\ttotal: 32s\tremaining: 1m 27s\n",
      "134: learn: 0.962393\ttest: 0.9424234\tbestTest: 0.9429948 (131)\ttotal: 32.2s\tremaining: 1m 27s\n",
      "135: learn: 0.9627594\ttest: 0.9424193\tbestTest: 0.9429948 (131)\ttotal: 32.4s\tremaining: 1m 26s\n",
      "136: learn: 0.9630678\ttest: 0.9426903\tbestTest: 0.9429948 (131)\ttotal: 32.6s\tremaining: 1m 26s\n",
      "137: learn: 0.9631987\ttest: 0.9427362\tbestTest: 0.9429948 (131)\ttotal: 32.8s\tremaining: 1m 26s\n",
      "138: learn: 0.9633375\ttest: 0.9426486\tbestTest: 0.9429948 (131)\ttotal: 33s\tremaining: 1m 25s\n",
      "139: learn: 0.9634376\ttest: 0.9426027\tbestTest: 0.9429948 (131)\ttotal: 33.2s\tremaining: 1m 25s\n",
      "140: learn: 0.963608\ttest: 0.9425944\tbestTest: 0.9429948 (131)\ttotal: 33.4s\tremaining: 1m 25s\n",
      "141: learn: 0.9637721\ttest: 0.9426069\tbestTest: 0.9429948 (131)\ttotal: 33.7s\tremaining: 1m 24s\n",
      "142: learn: 0.9639012\ttest: 0.9426445\tbestTest: 0.9429948 (131)\ttotal: 33.9s\tremaining: 1m 24s\n",
      "143: learn: 0.9640416\ttest: 0.9426319\tbestTest: 0.9429948 (131)\ttotal: 34.1s\tremaining: 1m 24s\n",
      "144: learn: 0.9641825\ttest: 0.9427946\tbestTest: 0.9429948 (131)\ttotal: 34.3s\tremaining: 1m 23s\n",
      "145: learn: 0.9644472\ttest: 0.9426486\tbestTest: 0.9429948 (131)\ttotal: 34.5s\tremaining: 1m 23s\n",
      "146: learn: 0.9646157\ttest: 0.9426903\tbestTest: 0.9429948 (131)\ttotal: 34.7s\tremaining: 1m 23s\n",
      "147: learn: 0.9648823\ttest: 0.9428071\tbestTest: 0.9429948 (131)\ttotal: 35s\tremaining: 1m 23s\n",
      "148: learn: 0.9649919\ttest: 0.9428196\tbestTest: 0.9429948 (131)\ttotal: 35.2s\tremaining: 1m 22s\n",
      "149: learn: 0.9651944\ttest: 0.9428238\tbestTest: 0.9429948 (131)\ttotal: 35.4s\tremaining: 1m 22s\n",
      "150: learn: 0.9653643\ttest: 0.9428113\tbestTest: 0.9429948 (131)\ttotal: 35.6s\tremaining: 1m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151: learn: 0.9654293\ttest: 0.9427946\tbestTest: 0.9429948 (131)\ttotal: 35.8s\tremaining: 1m 22s\n",
      "152: learn: 0.9656348\ttest: 0.9427696\tbestTest: 0.9429948 (131)\ttotal: 36s\tremaining: 1m 21s\n",
      "153: learn: 0.9658813\ttest: 0.942828\tbestTest: 0.9429948 (131)\ttotal: 36.3s\tremaining: 1m 21s\n",
      "154: learn: 0.9661966\ttest: 0.942878\tbestTest: 0.9429948 (131)\ttotal: 36.5s\tremaining: 1m 21s\n",
      "155: learn: 0.966312\ttest: 0.9429531\tbestTest: 0.9429948 (131)\ttotal: 36.7s\tremaining: 1m 20s\n",
      "156: learn: 0.9665416\ttest: 0.9428029\tbestTest: 0.9429948 (131)\ttotal: 37s\tremaining: 1m 20s\n",
      "157: learn: 0.9667315\ttest: 0.9425902\tbestTest: 0.9429948 (131)\ttotal: 37.2s\tremaining: 1m 20s\n",
      "158: learn: 0.9670215\ttest: 0.9425819\tbestTest: 0.9429948 (131)\ttotal: 37.4s\tremaining: 1m 20s\n",
      "159: learn: 0.9673758\ttest: 0.9425277\tbestTest: 0.9429948 (131)\ttotal: 37.6s\tremaining: 1m 19s\n",
      "160: learn: 0.9675006\ttest: 0.9424151\tbestTest: 0.9429948 (131)\ttotal: 37.8s\tremaining: 1m 19s\n",
      "161: learn: 0.9676368\ttest: 0.9425277\tbestTest: 0.9429948 (131)\ttotal: 38s\tremaining: 1m 19s\n",
      "162: learn: 0.9678011\ttest: 0.9426319\tbestTest: 0.9429948 (131)\ttotal: 38.2s\tremaining: 1m 18s\n",
      "163: learn: 0.9679681\ttest: 0.9425819\tbestTest: 0.9429948 (131)\ttotal: 38.4s\tremaining: 1m 18s\n",
      "164: learn: 0.9680919\ttest: 0.9426987\tbestTest: 0.9429948 (131)\ttotal: 38.6s\tremaining: 1m 18s\n",
      "165: learn: 0.9683066\ttest: 0.9424151\tbestTest: 0.9429948 (131)\ttotal: 38.8s\tremaining: 1m 18s\n",
      "166: learn: 0.9684138\ttest: 0.9424818\tbestTest: 0.9429948 (131)\ttotal: 39s\tremaining: 1m 17s\n",
      "167: learn: 0.9686079\ttest: 0.9426528\tbestTest: 0.9429948 (131)\ttotal: 39.3s\tremaining: 1m 17s\n",
      "168: learn: 0.9688916\ttest: 0.9424693\tbestTest: 0.9429948 (131)\ttotal: 39.5s\tremaining: 1m 17s\n",
      "169: learn: 0.9690546\ttest: 0.9426361\tbestTest: 0.9429948 (131)\ttotal: 39.7s\tremaining: 1m 17s\n",
      "170: learn: 0.969274\ttest: 0.9425736\tbestTest: 0.9429948 (131)\ttotal: 39.9s\tremaining: 1m 16s\n",
      "171: learn: 0.9693567\ttest: 0.9424901\tbestTest: 0.9429948 (131)\ttotal: 40.2s\tremaining: 1m 16s\n",
      "172: learn: 0.9694402\ttest: 0.9424484\tbestTest: 0.9429948 (131)\ttotal: 40.4s\tremaining: 1m 16s\n",
      "173: learn: 0.969519\ttest: 0.9423901\tbestTest: 0.9429948 (131)\ttotal: 40.6s\tremaining: 1m 16s\n",
      "174: learn: 0.9696164\ttest: 0.9424526\tbestTest: 0.9429948 (131)\ttotal: 40.8s\tremaining: 1m 15s\n",
      "175: learn: 0.9697589\ttest: 0.9426361\tbestTest: 0.9429948 (131)\ttotal: 41s\tremaining: 1m 15s\n",
      "176: learn: 0.9699175\ttest: 0.9425068\tbestTest: 0.9429948 (131)\ttotal: 41.2s\tremaining: 1m 15s\n",
      "177: learn: 0.9701371\ttest: 0.9424818\tbestTest: 0.9429948 (131)\ttotal: 41.5s\tremaining: 1m 15s\n",
      "178: learn: 0.9703075\ttest: 0.9423901\tbestTest: 0.9429948 (131)\ttotal: 41.6s\tremaining: 1m 14s\n",
      "179: learn: 0.9703723\ttest: 0.9424359\tbestTest: 0.9429948 (131)\ttotal: 42s\tremaining: 1m 14s\n",
      "180: learn: 0.9705741\ttest: 0.9423025\tbestTest: 0.9429948 (131)\ttotal: 42.2s\tremaining: 1m 14s\n",
      "181: learn: 0.9708456\ttest: 0.9421315\tbestTest: 0.9429948 (131)\ttotal: 42.4s\tremaining: 1m 14s\n",
      "182: learn: 0.9710851\ttest: 0.9419605\tbestTest: 0.9429948 (131)\ttotal: 42.6s\tremaining: 1m 13s\n",
      "183: learn: 0.9711725\ttest: 0.9419814\tbestTest: 0.9429948 (131)\ttotal: 42.8s\tremaining: 1m 13s\n",
      "184: learn: 0.9714177\ttest: 0.9421273\tbestTest: 0.9429948 (131)\ttotal: 43s\tremaining: 1m 13s\n",
      "185: learn: 0.9717419\ttest: 0.9420231\tbestTest: 0.9429948 (131)\ttotal: 43.2s\tremaining: 1m 12s\n",
      "186: learn: 0.971916\ttest: 0.942144\tbestTest: 0.9429948 (131)\ttotal: 43.4s\tremaining: 1m 12s\n",
      "187: learn: 0.9720198\ttest: 0.9421148\tbestTest: 0.9429948 (131)\ttotal: 43.6s\tremaining: 1m 12s\n",
      "188: learn: 0.9723251\ttest: 0.9422066\tbestTest: 0.9429948 (131)\ttotal: 43.8s\tremaining: 1m 12s\n",
      "189: learn: 0.9725071\ttest: 0.9423358\tbestTest: 0.9429948 (131)\ttotal: 44s\tremaining: 1m 11s\n",
      "190: learn: 0.9726048\ttest: 0.942365\tbestTest: 0.9429948 (131)\ttotal: 44.3s\tremaining: 1m 11s\n",
      "191: learn: 0.9727117\ttest: 0.9423734\tbestTest: 0.9429948 (131)\ttotal: 44.5s\tremaining: 1m 11s\n",
      "192: learn: 0.9728548\ttest: 0.9424026\tbestTest: 0.9429948 (131)\ttotal: 44.7s\tremaining: 1m 11s\n",
      "193: learn: 0.9730073\ttest: 0.9423942\tbestTest: 0.9429948 (131)\ttotal: 44.9s\tremaining: 1m 10s\n",
      "194: learn: 0.9731181\ttest: 0.9424067\tbestTest: 0.9429948 (131)\ttotal: 45.1s\tremaining: 1m 10s\n",
      "195: learn: 0.9732949\ttest: 0.9423484\tbestTest: 0.9429948 (131)\ttotal: 45.3s\tremaining: 1m 10s\n",
      "196: learn: 0.9734803\ttest: 0.9422858\tbestTest: 0.9429948 (131)\ttotal: 45.5s\tremaining: 1m 10s\n",
      "197: learn: 0.9736389\ttest: 0.9419605\tbestTest: 0.9429948 (131)\ttotal: 45.8s\tremaining: 1m 9s\n",
      "198: learn: 0.9737669\ttest: 0.9419146\tbestTest: 0.9429948 (131)\ttotal: 46s\tremaining: 1m 9s\n",
      "199: learn: 0.9738369\ttest: 0.941948\tbestTest: 0.9429948 (131)\ttotal: 46.2s\tremaining: 1m 9s\n",
      "200: learn: 0.9740237\ttest: 0.9420731\tbestTest: 0.9429948 (131)\ttotal: 46.4s\tremaining: 1m 8s\n",
      "201: learn: 0.9742112\ttest: 0.9421815\tbestTest: 0.9429948 (131)\ttotal: 46.6s\tremaining: 1m 8s\n",
      "202: learn: 0.9743832\ttest: 0.9422775\tbestTest: 0.9429948 (131)\ttotal: 46.8s\tremaining: 1m 8s\n",
      "203: learn: 0.9744401\ttest: 0.9422816\tbestTest: 0.9429948 (131)\ttotal: 47s\tremaining: 1m 8s\n",
      "204: learn: 0.9746371\ttest: 0.9421565\tbestTest: 0.9429948 (131)\ttotal: 47.1s\tremaining: 1m 7s\n",
      "205: learn: 0.9748046\ttest: 0.9422066\tbestTest: 0.9429948 (131)\ttotal: 47.3s\tremaining: 1m 7s\n",
      "206: learn: 0.9749903\ttest: 0.9421398\tbestTest: 0.9429948 (131)\ttotal: 47.5s\tremaining: 1m 7s\n",
      "207: learn: 0.9752634\ttest: 0.9420356\tbestTest: 0.9429948 (131)\ttotal: 47.7s\tremaining: 1m 6s\n",
      "208: learn: 0.9754325\ttest: 0.9419021\tbestTest: 0.9429948 (131)\ttotal: 47.9s\tremaining: 1m 6s\n",
      "209: learn: 0.9755347\ttest: 0.9418854\tbestTest: 0.9429948 (131)\ttotal: 48.1s\tremaining: 1m 6s\n",
      "210: learn: 0.9756738\ttest: 0.9419021\tbestTest: 0.9429948 (131)\ttotal: 48.4s\tremaining: 1m 6s\n",
      "211: learn: 0.975934\ttest: 0.941973\tbestTest: 0.9429948 (131)\ttotal: 48.6s\tremaining: 1m 5s\n",
      "212: learn: 0.9761147\ttest: 0.9419688\tbestTest: 0.9429948 (131)\ttotal: 48.8s\tremaining: 1m 5s\n",
      "213: learn: 0.9762746\ttest: 0.9419522\tbestTest: 0.9429948 (131)\ttotal: 49s\tremaining: 1m 5s\n",
      "214: learn: 0.976366\ttest: 0.9419897\tbestTest: 0.9429948 (131)\ttotal: 49.2s\tremaining: 1m 5s\n",
      "215: learn: 0.9764576\ttest: 0.9420231\tbestTest: 0.9429948 (131)\ttotal: 49.4s\tremaining: 1m 5s\n",
      "216: learn: 0.9766734\ttest: 0.9421607\tbestTest: 0.9429948 (131)\ttotal: 49.6s\tremaining: 1m 4s\n",
      "217: learn: 0.9768827\ttest: 0.9422566\tbestTest: 0.9429948 (131)\ttotal: 49.9s\tremaining: 1m 4s\n",
      "218: learn: 0.9770405\ttest: 0.9424318\tbestTest: 0.9429948 (131)\ttotal: 50.1s\tremaining: 1m 4s\n",
      "219: learn: 0.9771617\ttest: 0.9423567\tbestTest: 0.9429948 (131)\ttotal: 50.3s\tremaining: 1m 3s\n",
      "220: learn: 0.9772844\ttest: 0.9425986\tbestTest: 0.9429948 (131)\ttotal: 50.5s\tremaining: 1m 3s\n",
      "221: learn: 0.9774606\ttest: 0.942511\tbestTest: 0.9429948 (131)\ttotal: 50.6s\tremaining: 1m 3s\n",
      "222: learn: 0.9776537\ttest: 0.9425819\tbestTest: 0.9429948 (131)\ttotal: 50.8s\tremaining: 1m 3s\n",
      "223: learn: 0.9778955\ttest: 0.9424943\tbestTest: 0.9429948 (131)\ttotal: 51s\tremaining: 1m 2s\n",
      "224: learn: 0.9780909\ttest: 0.9425193\tbestTest: 0.9429948 (131)\ttotal: 51.2s\tremaining: 1m 2s\n",
      "225: learn: 0.9783032\ttest: 0.9425569\tbestTest: 0.9429948 (131)\ttotal: 51.4s\tremaining: 1m 2s\n",
      "226: learn: 0.9783975\ttest: 0.9424776\tbestTest: 0.9429948 (131)\ttotal: 51.6s\tremaining: 1m 2s\n",
      "227: learn: 0.9784794\ttest: 0.9424276\tbestTest: 0.9429948 (131)\ttotal: 51.8s\tremaining: 1m 1s\n",
      "228: learn: 0.9786208\ttest: 0.9423734\tbestTest: 0.9429948 (131)\ttotal: 52s\tremaining: 1m 1s\n",
      "229: learn: 0.9788136\ttest: 0.9423275\tbestTest: 0.9429948 (131)\ttotal: 52.2s\tremaining: 1m 1s\n",
      "230: learn: 0.9789337\ttest: 0.9424276\tbestTest: 0.9429948 (131)\ttotal: 52.4s\tremaining: 1m 1s\n",
      "231: learn: 0.979121\ttest: 0.9425027\tbestTest: 0.9429948 (131)\ttotal: 52.7s\tremaining: 1m\n",
      "232: learn: 0.979238\ttest: 0.9425444\tbestTest: 0.9429948 (131)\ttotal: 52.9s\tremaining: 1m\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9429947661\n",
      "bestIteration = 131\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.979237956872 0.942544362658\n",
      "[0.94201687457107108, 0.93540491922371738, 0.94254436265821473]\n",
      "0: learn: 0.8983947\ttest: 0.8636951\tbestTest: 0.8636951 (0)\ttotal: 172ms\tremaining: 1m 25s\n",
      "1: learn: 0.9117598\ttest: 0.870615\tbestTest: 0.870615 (1)\ttotal: 382ms\tremaining: 1m 35s\n",
      "2: learn: 0.9213928\ttest: 0.8964215\tbestTest: 0.8964215 (2)\ttotal: 582ms\tremaining: 1m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: learn: 0.9335149\ttest: 0.9122607\tbestTest: 0.9122607 (3)\ttotal: 781ms\tremaining: 1m 36s\n",
      "4: learn: 0.9367297\ttest: 0.9157507\tbestTest: 0.9157507 (4)\ttotal: 992ms\tremaining: 1m 38s\n",
      "5: learn: 0.9372758\ttest: 0.9186629\tbestTest: 0.9186629 (5)\ttotal: 1.18s\tremaining: 1m 37s\n",
      "6: learn: 0.9369475\ttest: 0.9194511\tbestTest: 0.9194511 (6)\ttotal: 1.37s\tremaining: 1m 36s\n",
      "7: learn: 0.937511\ttest: 0.9193846\tbestTest: 0.9194511 (6)\ttotal: 1.57s\tremaining: 1m 36s\n",
      "8: learn: 0.9379512\ttest: 0.9197454\tbestTest: 0.9197454 (8)\ttotal: 1.75s\tremaining: 1m 35s\n",
      "9: learn: 0.9381117\ttest: 0.9214828\tbestTest: 0.9214828 (9)\ttotal: 1.94s\tremaining: 1m 35s\n",
      "10: learn: 0.9385141\ttest: 0.9224214\tbestTest: 0.9224214 (10)\ttotal: 2.13s\tremaining: 1m 34s\n",
      "11: learn: 0.9386534\ttest: 0.9258426\tbestTest: 0.9258426 (11)\ttotal: 2.33s\tremaining: 1m 34s\n",
      "12: learn: 0.9385128\ttest: 0.9255914\tbestTest: 0.9258426 (11)\ttotal: 2.52s\tremaining: 1m 34s\n",
      "13: learn: 0.9386646\ttest: 0.9260553\tbestTest: 0.9260553 (13)\ttotal: 2.73s\tremaining: 1m 34s\n",
      "14: learn: 0.9388134\ttest: 0.927288\tbestTest: 0.927288 (14)\ttotal: 2.94s\tremaining: 1m 35s\n",
      "15: learn: 0.9391406\ttest: 0.927404\tbestTest: 0.927404 (15)\ttotal: 3.15s\tremaining: 1m 35s\n",
      "16: learn: 0.939349\ttest: 0.9280698\tbestTest: 0.9280698 (16)\ttotal: 3.36s\tremaining: 1m 35s\n",
      "17: learn: 0.93981\ttest: 0.9291136\tbestTest: 0.9291136 (17)\ttotal: 3.57s\tremaining: 1m 35s\n",
      "18: learn: 0.939902\ttest: 0.929032\tbestTest: 0.9291136 (17)\ttotal: 3.78s\tremaining: 1m 35s\n",
      "19: learn: 0.9404621\ttest: 0.9288129\tbestTest: 0.9291136 (17)\ttotal: 3.99s\tremaining: 1m 35s\n",
      "20: learn: 0.9406093\ttest: 0.9288558\tbestTest: 0.9291136 (17)\ttotal: 4.2s\tremaining: 1m 35s\n",
      "21: learn: 0.9411022\ttest: 0.9295044\tbestTest: 0.9295044 (21)\ttotal: 4.43s\tremaining: 1m 36s\n",
      "22: learn: 0.9416293\ttest: 0.9304623\tbestTest: 0.9304623 (22)\ttotal: 4.65s\tremaining: 1m 36s\n",
      "23: learn: 0.9418623\ttest: 0.9305525\tbestTest: 0.9305525 (23)\ttotal: 4.86s\tremaining: 1m 36s\n",
      "24: learn: 0.9417655\ttest: 0.9311238\tbestTest: 0.9311238 (24)\ttotal: 5.07s\tremaining: 1m 36s\n",
      "25: learn: 0.9418516\ttest: 0.9313429\tbestTest: 0.9313429 (25)\ttotal: 5.28s\tremaining: 1m 36s\n",
      "26: learn: 0.9419651\ttest: 0.9311753\tbestTest: 0.9313429 (25)\ttotal: 5.49s\tremaining: 1m 36s\n",
      "27: learn: 0.9420231\ttest: 0.9320688\tbestTest: 0.9320688 (27)\ttotal: 5.71s\tremaining: 1m 36s\n",
      "28: learn: 0.9420895\ttest: 0.9321547\tbestTest: 0.9321547 (28)\ttotal: 5.91s\tremaining: 1m 36s\n",
      "29: learn: 0.9424001\ttest: 0.9323566\tbestTest: 0.9323566 (29)\ttotal: 6.06s\tremaining: 1m 34s\n",
      "30: learn: 0.9424574\ttest: 0.9324339\tbestTest: 0.9324339 (30)\ttotal: 6.26s\tremaining: 1m 34s\n",
      "31: learn: 0.9425392\ttest: 0.9325198\tbestTest: 0.9325198 (31)\ttotal: 6.4s\tremaining: 1m 33s\n",
      "32: learn: 0.9428146\ttest: 0.9326272\tbestTest: 0.9326272 (32)\ttotal: 6.61s\tremaining: 1m 33s\n",
      "33: learn: 0.9431568\ttest: 0.9326014\tbestTest: 0.9326272 (32)\ttotal: 6.83s\tremaining: 1m 33s\n",
      "34: learn: 0.9433064\ttest: 0.9324983\tbestTest: 0.9326272 (32)\ttotal: 7.02s\tremaining: 1m 33s\n",
      "35: learn: 0.943439\ttest: 0.9325971\tbestTest: 0.9326272 (32)\ttotal: 7.24s\tremaining: 1m 33s\n",
      "36: learn: 0.9436401\ttest: 0.9324124\tbestTest: 0.9326272 (32)\ttotal: 7.45s\tremaining: 1m 33s\n",
      "37: learn: 0.94373\ttest: 0.9325627\tbestTest: 0.9326272 (32)\ttotal: 7.66s\tremaining: 1m 33s\n",
      "38: learn: 0.9437654\ttest: 0.9326701\tbestTest: 0.9326701 (38)\ttotal: 7.87s\tremaining: 1m 33s\n",
      "39: learn: 0.9440345\ttest: 0.9326916\tbestTest: 0.9326916 (39)\ttotal: 8.1s\tremaining: 1m 33s\n",
      "40: learn: 0.9443613\ttest: 0.932567\tbestTest: 0.9326916 (39)\ttotal: 8.29s\tremaining: 1m 32s\n",
      "41: learn: 0.9444476\ttest: 0.9327346\tbestTest: 0.9327346 (41)\ttotal: 8.51s\tremaining: 1m 32s\n",
      "42: learn: 0.9446725\ttest: 0.9326229\tbestTest: 0.9327346 (41)\ttotal: 8.73s\tremaining: 1m 32s\n",
      "43: learn: 0.9449345\ttest: 0.9323093\tbestTest: 0.9327346 (41)\ttotal: 8.95s\tremaining: 1m 32s\n",
      "44: learn: 0.945192\ttest: 0.9324897\tbestTest: 0.9327346 (41)\ttotal: 9.17s\tremaining: 1m 32s\n",
      "45: learn: 0.9454467\ttest: 0.9323652\tbestTest: 0.9327346 (41)\ttotal: 9.39s\tremaining: 1m 32s\n",
      "46: learn: 0.9456397\ttest: 0.9325241\tbestTest: 0.9327346 (41)\ttotal: 9.6s\tremaining: 1m 32s\n",
      "47: learn: 0.9456846\ttest: 0.9325413\tbestTest: 0.9327346 (41)\ttotal: 9.79s\tremaining: 1m 32s\n",
      "48: learn: 0.9458528\ttest: 0.9325413\tbestTest: 0.9327346 (41)\ttotal: 9.99s\tremaining: 1m 31s\n",
      "49: learn: 0.9459401\ttest: 0.9329493\tbestTest: 0.9329493 (49)\ttotal: 10.2s\tremaining: 1m 31s\n",
      "50: learn: 0.9463145\ttest: 0.9328806\tbestTest: 0.9329493 (49)\ttotal: 10.4s\tremaining: 1m 31s\n",
      "51: learn: 0.9463909\ttest: 0.9330266\tbestTest: 0.9330266 (51)\ttotal: 10.6s\tremaining: 1m 30s\n",
      "52: learn: 0.946673\ttest: 0.9329279\tbestTest: 0.9330266 (51)\ttotal: 10.8s\tremaining: 1m 30s\n",
      "53: learn: 0.9469682\ttest: 0.9330138\tbestTest: 0.9330266 (51)\ttotal: 11s\tremaining: 1m 30s\n",
      "54: learn: 0.9470589\ttest: 0.9332328\tbestTest: 0.9332328 (54)\ttotal: 11.2s\tremaining: 1m 30s\n",
      "55: learn: 0.9473646\ttest: 0.9330181\tbestTest: 0.9332328 (54)\ttotal: 11.4s\tremaining: 1m 30s\n",
      "56: learn: 0.9474436\ttest: 0.9331899\tbestTest: 0.9332328 (54)\ttotal: 11.6s\tremaining: 1m 30s\n",
      "57: learn: 0.9478057\ttest: 0.9336538\tbestTest: 0.9336538 (57)\ttotal: 11.8s\tremaining: 1m 30s\n",
      "58: learn: 0.9480227\ttest: 0.9337483\tbestTest: 0.9337483 (58)\ttotal: 12s\tremaining: 1m 29s\n",
      "59: learn: 0.9483059\ttest: 0.9335936\tbestTest: 0.9337483 (58)\ttotal: 12.3s\tremaining: 1m 29s\n",
      "60: learn: 0.9484045\ttest: 0.9335335\tbestTest: 0.9337483 (58)\ttotal: 12.5s\tremaining: 1m 29s\n",
      "61: learn: 0.9488791\ttest: 0.9335936\tbestTest: 0.9337483 (58)\ttotal: 12.7s\tremaining: 1m 29s\n",
      "62: learn: 0.9489823\ttest: 0.9336624\tbestTest: 0.9337483 (58)\ttotal: 12.9s\tremaining: 1m 29s\n",
      "63: learn: 0.949202\ttest: 0.9336108\tbestTest: 0.9337483 (58)\ttotal: 13.1s\tremaining: 1m 29s\n",
      "64: learn: 0.9495152\ttest: 0.9337697\tbestTest: 0.9337697 (64)\ttotal: 13.3s\tremaining: 1m 29s\n",
      "65: learn: 0.94971\ttest: 0.9338599\tbestTest: 0.9338599 (65)\ttotal: 13.5s\tremaining: 1m 29s\n",
      "66: learn: 0.9499804\ttest: 0.9337354\tbestTest: 0.9338599 (65)\ttotal: 13.8s\tremaining: 1m 28s\n",
      "67: learn: 0.9501707\ttest: 0.9335249\tbestTest: 0.9338599 (65)\ttotal: 14s\tremaining: 1m 28s\n",
      "68: learn: 0.9504442\ttest: 0.9335807\tbestTest: 0.9338599 (65)\ttotal: 14.2s\tremaining: 1m 28s\n",
      "69: learn: 0.9505554\ttest: 0.9335765\tbestTest: 0.9338599 (65)\ttotal: 14.4s\tremaining: 1m 28s\n",
      "70: learn: 0.9507379\ttest: 0.9335507\tbestTest: 0.9338599 (65)\ttotal: 14.6s\tremaining: 1m 28s\n",
      "71: learn: 0.9509\ttest: 0.9333574\tbestTest: 0.9338599 (65)\ttotal: 15s\tremaining: 1m 29s\n",
      "72: learn: 0.951203\ttest: 0.9334862\tbestTest: 0.9338599 (65)\ttotal: 15.3s\tremaining: 1m 29s\n",
      "73: learn: 0.951419\ttest: 0.9333832\tbestTest: 0.9338599 (65)\ttotal: 15.7s\tremaining: 1m 30s\n",
      "74: learn: 0.9516933\ttest: 0.9334905\tbestTest: 0.9338599 (65)\ttotal: 16s\tremaining: 1m 30s\n",
      "75: learn: 0.9518774\ttest: 0.9333746\tbestTest: 0.9338599 (65)\ttotal: 16.3s\tremaining: 1m 30s\n",
      "76: learn: 0.951989\ttest: 0.9335077\tbestTest: 0.9338599 (65)\ttotal: 16.5s\tremaining: 1m 30s\n",
      "77: learn: 0.9521948\ttest: 0.9333316\tbestTest: 0.9338599 (65)\ttotal: 16.7s\tremaining: 1m 30s\n",
      "78: learn: 0.9523682\ttest: 0.9333617\tbestTest: 0.9338599 (65)\ttotal: 16.9s\tremaining: 1m 29s\n",
      "79: learn: 0.9525886\ttest: 0.9334003\tbestTest: 0.9338599 (65)\ttotal: 17.3s\tremaining: 1m 30s\n",
      "80: learn: 0.952711\ttest: 0.9332629\tbestTest: 0.9338599 (65)\ttotal: 17.5s\tremaining: 1m 30s\n",
      "81: learn: 0.9530381\ttest: 0.933293\tbestTest: 0.9338599 (65)\ttotal: 17.7s\tremaining: 1m 30s\n",
      "82: learn: 0.9532033\ttest: 0.9331985\tbestTest: 0.9338599 (65)\ttotal: 17.9s\tremaining: 1m 30s\n",
      "83: learn: 0.9533458\ttest: 0.93325\tbestTest: 0.9338599 (65)\ttotal: 18.1s\tremaining: 1m 29s\n",
      "84: learn: 0.953636\ttest: 0.9332801\tbestTest: 0.9338599 (65)\ttotal: 18.6s\tremaining: 1m 30s\n",
      "85: learn: 0.9538193\ttest: 0.9333617\tbestTest: 0.9338599 (65)\ttotal: 18.8s\tremaining: 1m 30s\n",
      "86: learn: 0.954107\ttest: 0.9332844\tbestTest: 0.9338599 (65)\ttotal: 19s\tremaining: 1m 30s\n",
      "87: learn: 0.9543846\ttest: 0.9332887\tbestTest: 0.9338599 (65)\ttotal: 19.3s\tremaining: 1m 30s\n",
      "88: learn: 0.9547332\ttest: 0.9330438\tbestTest: 0.9338599 (65)\ttotal: 19.6s\tremaining: 1m 30s\n",
      "89: learn: 0.9548903\ttest: 0.9330567\tbestTest: 0.9338599 (65)\ttotal: 19.8s\tremaining: 1m 30s\n",
      "90: learn: 0.9552101\ttest: 0.9330138\tbestTest: 0.9338599 (65)\ttotal: 20s\tremaining: 1m 29s\n",
      "91: learn: 0.9555621\ttest: 0.9328978\tbestTest: 0.9338599 (65)\ttotal: 20.2s\tremaining: 1m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92: learn: 0.9557725\ttest: 0.9327045\tbestTest: 0.9338599 (65)\ttotal: 20.4s\tremaining: 1m 29s\n",
      "93: learn: 0.9559098\ttest: 0.9326143\tbestTest: 0.9338599 (65)\ttotal: 20.7s\tremaining: 1m 29s\n",
      "94: learn: 0.9560178\ttest: 0.9327389\tbestTest: 0.9338599 (65)\ttotal: 20.9s\tremaining: 1m 29s\n",
      "95: learn: 0.9562934\ttest: 0.932799\tbestTest: 0.9338599 (65)\ttotal: 21.1s\tremaining: 1m 28s\n",
      "96: learn: 0.9564785\ttest: 0.9326229\tbestTest: 0.9338599 (65)\ttotal: 21.3s\tremaining: 1m 28s\n",
      "97: learn: 0.9566874\ttest: 0.9326701\tbestTest: 0.9338599 (65)\ttotal: 21.5s\tremaining: 1m 28s\n",
      "98: learn: 0.9568812\ttest: 0.9327131\tbestTest: 0.9338599 (65)\ttotal: 21.9s\tremaining: 1m 28s\n",
      "99: learn: 0.9571029\ttest: 0.9324854\tbestTest: 0.9338599 (65)\ttotal: 22.1s\tremaining: 1m 28s\n",
      "100: learn: 0.9572985\ttest: 0.9325327\tbestTest: 0.9338599 (65)\ttotal: 22.3s\tremaining: 1m 28s\n",
      "101: learn: 0.9575098\ttest: 0.932464\tbestTest: 0.9338599 (65)\ttotal: 22.5s\tremaining: 1m 27s\n",
      "102: learn: 0.957782\ttest: 0.9325799\tbestTest: 0.9338599 (65)\ttotal: 22.7s\tremaining: 1m 27s\n",
      "103: learn: 0.9579898\ttest: 0.9325155\tbestTest: 0.9338599 (65)\ttotal: 23s\tremaining: 1m 27s\n",
      "104: learn: 0.9580916\ttest: 0.9325284\tbestTest: 0.9338599 (65)\ttotal: 23.3s\tremaining: 1m 27s\n",
      "105: learn: 0.9582427\ttest: 0.9323952\tbestTest: 0.9338599 (65)\ttotal: 23.5s\tremaining: 1m 27s\n",
      "106: learn: 0.9585904\ttest: 0.9324167\tbestTest: 0.9338599 (65)\ttotal: 23.7s\tremaining: 1m 26s\n",
      "107: learn: 0.9588843\ttest: 0.9326529\tbestTest: 0.9338599 (65)\ttotal: 23.9s\tremaining: 1m 26s\n",
      "108: learn: 0.9592243\ttest: 0.9327045\tbestTest: 0.9338599 (65)\ttotal: 24.1s\tremaining: 1m 26s\n",
      "109: learn: 0.9594894\ttest: 0.9326186\tbestTest: 0.9338599 (65)\ttotal: 24.3s\tremaining: 1m 26s\n",
      "110: learn: 0.9595874\ttest: 0.9326272\tbestTest: 0.9338599 (65)\ttotal: 24.5s\tremaining: 1m 25s\n",
      "111: learn: 0.9598181\ttest: 0.9327002\tbestTest: 0.9338599 (65)\ttotal: 24.7s\tremaining: 1m 25s\n",
      "112: learn: 0.9600309\ttest: 0.9326572\tbestTest: 0.9338599 (65)\ttotal: 24.9s\tremaining: 1m 25s\n",
      "113: learn: 0.9602035\ttest: 0.9327174\tbestTest: 0.9338599 (65)\ttotal: 25.1s\tremaining: 1m 25s\n",
      "114: learn: 0.9604116\ttest: 0.9326487\tbestTest: 0.9338599 (65)\ttotal: 25.4s\tremaining: 1m 25s\n",
      "115: learn: 0.9605452\ttest: 0.9325885\tbestTest: 0.9338599 (65)\ttotal: 25.6s\tremaining: 1m 24s\n",
      "116: learn: 0.9607528\ttest: 0.9324854\tbestTest: 0.9338599 (65)\ttotal: 25.8s\tremaining: 1m 24s\n",
      "117: learn: 0.960841\ttest: 0.9325112\tbestTest: 0.9338599 (65)\ttotal: 26s\tremaining: 1m 24s\n",
      "118: learn: 0.9609978\ttest: 0.9326143\tbestTest: 0.9338599 (65)\ttotal: 26.2s\tremaining: 1m 23s\n",
      "119: learn: 0.9611911\ttest: 0.9325928\tbestTest: 0.9338599 (65)\ttotal: 26.6s\tremaining: 1m 24s\n",
      "120: learn: 0.9615054\ttest: 0.9326744\tbestTest: 0.9338599 (65)\ttotal: 26.8s\tremaining: 1m 23s\n",
      "121: learn: 0.9616669\ttest: 0.9326229\tbestTest: 0.9338599 (65)\ttotal: 27s\tremaining: 1m 23s\n",
      "122: learn: 0.9619674\ttest: 0.9326358\tbestTest: 0.9338599 (65)\ttotal: 27.2s\tremaining: 1m 23s\n",
      "123: learn: 0.9621601\ttest: 0.9326444\tbestTest: 0.9338599 (65)\ttotal: 27.4s\tremaining: 1m 23s\n",
      "124: learn: 0.9624603\ttest: 0.9325842\tbestTest: 0.9338599 (65)\ttotal: 27.8s\tremaining: 1m 23s\n",
      "125: learn: 0.9627748\ttest: 0.9324811\tbestTest: 0.9338599 (65)\ttotal: 28s\tremaining: 1m 23s\n",
      "126: learn: 0.9629516\ttest: 0.9325971\tbestTest: 0.9338599 (65)\ttotal: 28.2s\tremaining: 1m 22s\n",
      "127: learn: 0.9630745\ttest: 0.9326787\tbestTest: 0.9338599 (65)\ttotal: 28.4s\tremaining: 1m 22s\n",
      "128: learn: 0.9632504\ttest: 0.9326916\tbestTest: 0.9338599 (65)\ttotal: 28.7s\tremaining: 1m 22s\n",
      "129: learn: 0.9633953\ttest: 0.9325971\tbestTest: 0.9338599 (65)\ttotal: 28.9s\tremaining: 1m 22s\n",
      "130: learn: 0.9637101\ttest: 0.9326873\tbestTest: 0.9338599 (65)\ttotal: 29.4s\tremaining: 1m 22s\n",
      "131: learn: 0.9639697\ttest: 0.9326873\tbestTest: 0.9338599 (65)\ttotal: 29.7s\tremaining: 1m 22s\n",
      "132: learn: 0.9641347\ttest: 0.9326487\tbestTest: 0.9338599 (65)\ttotal: 30.1s\tremaining: 1m 23s\n",
      "133: learn: 0.9642304\ttest: 0.9326444\tbestTest: 0.9338599 (65)\ttotal: 30.4s\tremaining: 1m 23s\n",
      "134: learn: 0.964404\ttest: 0.9325799\tbestTest: 0.9338599 (65)\ttotal: 30.8s\tremaining: 1m 23s\n",
      "135: learn: 0.9645374\ttest: 0.9326143\tbestTest: 0.9338599 (65)\ttotal: 31.1s\tremaining: 1m 23s\n",
      "136: learn: 0.9646449\ttest: 0.9325928\tbestTest: 0.9338599 (65)\ttotal: 31.5s\tremaining: 1m 23s\n",
      "137: learn: 0.9649597\ttest: 0.9325842\tbestTest: 0.9338599 (65)\ttotal: 31.9s\tremaining: 1m 23s\n",
      "138: learn: 0.9650352\ttest: 0.932464\tbestTest: 0.9338599 (65)\ttotal: 32.3s\tremaining: 1m 23s\n",
      "139: learn: 0.9652771\ttest: 0.93261\tbestTest: 0.9338599 (65)\ttotal: 32.6s\tremaining: 1m 23s\n",
      "140: learn: 0.9655692\ttest: 0.9324081\tbestTest: 0.9338599 (65)\ttotal: 33s\tremaining: 1m 23s\n",
      "141: learn: 0.9657491\ttest: 0.9324983\tbestTest: 0.9338599 (65)\ttotal: 33.4s\tremaining: 1m 24s\n",
      "142: learn: 0.9659431\ttest: 0.9325499\tbestTest: 0.9338599 (65)\ttotal: 33.8s\tremaining: 1m 24s\n",
      "143: learn: 0.9660694\ttest: 0.9326014\tbestTest: 0.9338599 (65)\ttotal: 34.1s\tremaining: 1m 24s\n",
      "144: learn: 0.966243\ttest: 0.9325499\tbestTest: 0.9338599 (65)\ttotal: 34.5s\tremaining: 1m 24s\n",
      "145: learn: 0.9663379\ttest: 0.9324554\tbestTest: 0.9338599 (65)\ttotal: 34.8s\tremaining: 1m 24s\n",
      "146: learn: 0.9665338\ttest: 0.9324339\tbestTest: 0.9338599 (65)\ttotal: 35s\tremaining: 1m 24s\n",
      "147: learn: 0.9666412\ttest: 0.9323566\tbestTest: 0.9338599 (65)\ttotal: 35.2s\tremaining: 1m 23s\n",
      "148: learn: 0.9668088\ttest: 0.9323437\tbestTest: 0.9338599 (65)\ttotal: 35.4s\tremaining: 1m 23s\n",
      "149: learn: 0.9669385\ttest: 0.9322835\tbestTest: 0.9338599 (65)\ttotal: 35.6s\tremaining: 1m 23s\n",
      "150: learn: 0.9671982\ttest: 0.9322664\tbestTest: 0.9338599 (65)\ttotal: 36s\tremaining: 1m 23s\n",
      "151: learn: 0.9673041\ttest: 0.9322707\tbestTest: 0.9338599 (65)\ttotal: 36.4s\tremaining: 1m 23s\n",
      "152: learn: 0.9675002\ttest: 0.9323136\tbestTest: 0.9338599 (65)\ttotal: 36.6s\tremaining: 1m 22s\n",
      "153: learn: 0.9676837\ttest: 0.9322535\tbestTest: 0.9338599 (65)\ttotal: 36.8s\tremaining: 1m 22s\n",
      "154: learn: 0.967987\ttest: 0.9321504\tbestTest: 0.9338599 (65)\ttotal: 37.1s\tremaining: 1m 22s\n",
      "155: learn: 0.9681481\ttest: 0.9320473\tbestTest: 0.9338599 (65)\ttotal: 37.4s\tremaining: 1m 22s\n",
      "156: learn: 0.9683136\ttest: 0.9319743\tbestTest: 0.9338599 (65)\ttotal: 37.6s\tremaining: 1m 22s\n",
      "157: learn: 0.9684862\ttest: 0.9318927\tbestTest: 0.9338599 (65)\ttotal: 37.7s\tremaining: 1m 21s\n",
      "158: learn: 0.9685419\ttest: 0.9318368\tbestTest: 0.9338599 (65)\ttotal: 37.9s\tremaining: 1m 21s\n",
      "159: learn: 0.9686093\ttest: 0.9318196\tbestTest: 0.9338599 (65)\ttotal: 38.3s\tremaining: 1m 21s\n",
      "160: learn: 0.9687558\ttest: 0.9317982\tbestTest: 0.9338599 (65)\ttotal: 38.5s\tremaining: 1m 21s\n",
      "161: learn: 0.9688648\ttest: 0.9316951\tbestTest: 0.9338599 (65)\ttotal: 38.8s\tremaining: 1m 20s\n",
      "162: learn: 0.9690609\ttest: 0.9317509\tbestTest: 0.9338599 (65)\ttotal: 39s\tremaining: 1m 20s\n",
      "163: learn: 0.9693344\ttest: 0.9316478\tbestTest: 0.9338599 (65)\ttotal: 39.2s\tremaining: 1m 20s\n",
      "164: learn: 0.9694494\ttest: 0.9315877\tbestTest: 0.9338599 (65)\ttotal: 39.5s\tremaining: 1m 20s\n",
      "165: learn: 0.9696327\ttest: 0.9315276\tbestTest: 0.9338599 (65)\ttotal: 39.7s\tremaining: 1m 19s\n",
      "166: learn: 0.9698487\ttest: 0.9316478\tbestTest: 0.9338599 (65)\ttotal: 39.9s\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9338599453\n",
      "bestIteration = 65\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.969848711459 0.931647831484\n",
      "[0.94201687457107108, 0.93540491922371738, 0.94254436265821473, 0.93164783148417796]\n",
      "0: learn: 0.866214\ttest: 0.8129743\tbestTest: 0.8129743 (0)\ttotal: 315ms\tremaining: 2m 37s\n",
      "1: learn: 0.8901615\ttest: 0.8258841\tbestTest: 0.8258841 (1)\ttotal: 503ms\tremaining: 2m 5s\n",
      "2: learn: 0.9064419\ttest: 0.8616939\tbestTest: 0.8616939 (2)\ttotal: 702ms\tremaining: 1m 56s\n",
      "3: learn: 0.9198001\ttest: 0.8867462\tbestTest: 0.8867462 (3)\ttotal: 896ms\tremaining: 1m 51s\n",
      "4: learn: 0.9262182\ttest: 0.9021983\tbestTest: 0.9021983 (4)\ttotal: 1.02s\tremaining: 1m 40s\n",
      "5: learn: 0.9322595\ttest: 0.9144904\tbestTest: 0.9144904 (5)\ttotal: 1.18s\tremaining: 1m 37s\n",
      "6: learn: 0.9354621\ttest: 0.9175745\tbestTest: 0.9175745 (6)\ttotal: 1.54s\tremaining: 1m 48s\n",
      "7: learn: 0.9357392\ttest: 0.916959\tbestTest: 0.9175745 (6)\ttotal: 1.7s\tremaining: 1m 44s\n",
      "8: learn: 0.9359871\ttest: 0.9171382\tbestTest: 0.9175745 (6)\ttotal: 1.89s\tremaining: 1m 43s\n",
      "9: learn: 0.9367219\ttest: 0.9172415\tbestTest: 0.9175745 (6)\ttotal: 2.02s\tremaining: 1m 39s\n",
      "10: learn: 0.9369811\ttest: 0.9175008\tbestTest: 0.9175745 (6)\ttotal: 2.21s\tremaining: 1m 38s\n",
      "11: learn: 0.9389409\ttest: 0.9218518\tbestTest: 0.9218518 (11)\ttotal: 2.35s\tremaining: 1m 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: learn: 0.9391897\ttest: 0.921114\tbestTest: 0.9218518 (11)\ttotal: 2.65s\tremaining: 1m 39s\n",
      "13: learn: 0.9393444\ttest: 0.9214049\tbestTest: 0.9218518 (11)\ttotal: 2.83s\tremaining: 1m 38s\n",
      "14: learn: 0.9393288\ttest: 0.9206945\tbestTest: 0.9218518 (11)\ttotal: 3.02s\tremaining: 1m 37s\n",
      "15: learn: 0.9394454\ttest: 0.9206734\tbestTest: 0.9218518 (11)\ttotal: 3.21s\tremaining: 1m 37s\n",
      "16: learn: 0.9399402\ttest: 0.9213438\tbestTest: 0.9218518 (11)\ttotal: 3.42s\tremaining: 1m 37s\n",
      "17: learn: 0.9403857\ttest: 0.9224863\tbestTest: 0.9224863 (17)\ttotal: 3.78s\tremaining: 1m 41s\n",
      "18: learn: 0.9406069\ttest: 0.9220436\tbestTest: 0.9224863 (17)\ttotal: 3.96s\tremaining: 1m 40s\n",
      "19: learn: 0.9413607\ttest: 0.9242318\tbestTest: 0.9242318 (19)\ttotal: 4.15s\tremaining: 1m 39s\n",
      "20: learn: 0.9416389\ttest: 0.9240758\tbestTest: 0.9242318 (19)\ttotal: 4.37s\tremaining: 1m 39s\n",
      "21: learn: 0.9420387\ttest: 0.9243077\tbestTest: 0.9243077 (21)\ttotal: 4.59s\tremaining: 1m 39s\n",
      "22: learn: 0.9423862\ttest: 0.9242276\tbestTest: 0.9243077 (21)\ttotal: 4.95s\tremaining: 1m 42s\n",
      "23: learn: 0.9422916\ttest: 0.9247462\tbestTest: 0.9247462 (23)\ttotal: 5.15s\tremaining: 1m 42s\n",
      "24: learn: 0.9422165\ttest: 0.9244848\tbestTest: 0.9247462 (23)\ttotal: 5.35s\tremaining: 1m 41s\n",
      "25: learn: 0.9426139\ttest: 0.925366\tbestTest: 0.925366 (25)\ttotal: 5.55s\tremaining: 1m 41s\n",
      "26: learn: 0.9433053\ttest: 0.9253196\tbestTest: 0.925366 (25)\ttotal: 5.75s\tremaining: 1m 40s\n",
      "27: learn: 0.943517\ttest: 0.9255978\tbestTest: 0.9255978 (27)\ttotal: 6.12s\tremaining: 1m 43s\n",
      "28: learn: 0.9434697\ttest: 0.9258129\tbestTest: 0.9258129 (28)\ttotal: 6.3s\tremaining: 1m 42s\n",
      "29: learn: 0.9435845\ttest: 0.925952\tbestTest: 0.925952 (29)\ttotal: 6.48s\tremaining: 1m 41s\n",
      "30: learn: 0.9435093\ttest: 0.9259899\tbestTest: 0.9259899 (30)\ttotal: 6.68s\tremaining: 1m 41s\n",
      "31: learn: 0.9435863\ttest: 0.9260827\tbestTest: 0.9260827 (31)\ttotal: 6.87s\tremaining: 1m 40s\n",
      "32: learn: 0.9436291\ttest: 0.9261038\tbestTest: 0.9261038 (32)\ttotal: 7.21s\tremaining: 1m 42s\n",
      "33: learn: 0.9439157\ttest: 0.9262893\tbestTest: 0.9262893 (33)\ttotal: 7.39s\tremaining: 1m 41s\n",
      "34: learn: 0.9443021\ttest: 0.9261038\tbestTest: 0.9262893 (33)\ttotal: 7.59s\tremaining: 1m 40s\n",
      "35: learn: 0.9444431\ttest: 0.9259604\tbestTest: 0.9262893 (33)\ttotal: 7.98s\tremaining: 1m 42s\n",
      "36: learn: 0.9445941\ttest: 0.9257159\tbestTest: 0.9262893 (33)\ttotal: 8.22s\tremaining: 1m 42s\n",
      "37: learn: 0.9449424\ttest: 0.925855\tbestTest: 0.9262893 (33)\ttotal: 8.4s\tremaining: 1m 42s\n",
      "38: learn: 0.9450415\ttest: 0.9259183\tbestTest: 0.9262893 (33)\ttotal: 8.62s\tremaining: 1m 41s\n",
      "39: learn: 0.9453349\ttest: 0.9260321\tbestTest: 0.9262893 (33)\ttotal: 8.84s\tremaining: 1m 41s\n",
      "40: learn: 0.9454909\ttest: 0.9261333\tbestTest: 0.9262893 (33)\ttotal: 9.06s\tremaining: 1m 41s\n",
      "41: learn: 0.945669\ttest: 0.9261965\tbestTest: 0.9262893 (33)\ttotal: 9.28s\tremaining: 1m 41s\n",
      "42: learn: 0.9458555\ttest: 0.9260701\tbestTest: 0.9262893 (33)\ttotal: 9.51s\tremaining: 1m 41s\n",
      "43: learn: 0.9460858\ttest: 0.9259815\tbestTest: 0.9262893 (33)\ttotal: 9.73s\tremaining: 1m 40s\n",
      "44: learn: 0.9462287\ttest: 0.926167\tbestTest: 0.9262893 (33)\ttotal: 9.94s\tremaining: 1m 40s\n",
      "45: learn: 0.9463438\ttest: 0.9263694\tbestTest: 0.9263694 (45)\ttotal: 10.1s\tremaining: 1m 39s\n",
      "46: learn: 0.9467604\ttest: 0.9260785\tbestTest: 0.9263694 (45)\ttotal: 10.3s\tremaining: 1m 39s\n",
      "47: learn: 0.9467714\ttest: 0.9260448\tbestTest: 0.9263694 (45)\ttotal: 10.5s\tremaining: 1m 38s\n",
      "48: learn: 0.9469508\ttest: 0.9262092\tbestTest: 0.9263694 (45)\ttotal: 10.7s\tremaining: 1m 38s\n",
      "49: learn: 0.9471281\ttest: 0.9261459\tbestTest: 0.9263694 (45)\ttotal: 10.9s\tremaining: 1m 37s\n",
      "50: learn: 0.9473569\ttest: 0.9262851\tbestTest: 0.9263694 (45)\ttotal: 11.1s\tremaining: 1m 37s\n",
      "51: learn: 0.9473797\ttest: 0.9264579\tbestTest: 0.9264579 (51)\ttotal: 11.3s\tremaining: 1m 37s\n",
      "52: learn: 0.9475289\ttest: 0.9262766\tbestTest: 0.9264579 (51)\ttotal: 11.5s\tremaining: 1m 36s\n",
      "53: learn: 0.9477624\ttest: 0.9262851\tbestTest: 0.9264579 (51)\ttotal: 11.7s\tremaining: 1m 36s\n",
      "54: learn: 0.9478504\ttest: 0.9260405\tbestTest: 0.9264579 (51)\ttotal: 12s\tremaining: 1m 36s\n",
      "55: learn: 0.9480871\ttest: 0.9259604\tbestTest: 0.9264579 (51)\ttotal: 12.2s\tremaining: 1m 36s\n",
      "56: learn: 0.9485562\ttest: 0.9256358\tbestTest: 0.9264579 (51)\ttotal: 12.4s\tremaining: 1m 36s\n",
      "57: learn: 0.9487742\ttest: 0.9258255\tbestTest: 0.9264579 (51)\ttotal: 12.6s\tremaining: 1m 36s\n",
      "58: learn: 0.9488756\ttest: 0.9257075\tbestTest: 0.9264579 (51)\ttotal: 12.9s\tremaining: 1m 36s\n",
      "59: learn: 0.9490392\ttest: 0.9258087\tbestTest: 0.9264579 (51)\ttotal: 13.2s\tremaining: 1m 36s\n",
      "60: learn: 0.9491585\ttest: 0.9257707\tbestTest: 0.9264579 (51)\ttotal: 13.4s\tremaining: 1m 36s\n",
      "61: learn: 0.9493471\ttest: 0.9257075\tbestTest: 0.9264579 (51)\ttotal: 13.7s\tremaining: 1m 36s\n",
      "62: learn: 0.9495667\ttest: 0.9258424\tbestTest: 0.9264579 (51)\ttotal: 13.9s\tremaining: 1m 36s\n",
      "63: learn: 0.949775\ttest: 0.9256948\tbestTest: 0.9264579 (51)\ttotal: 14.1s\tremaining: 1m 35s\n",
      "64: learn: 0.9498703\ttest: 0.9257075\tbestTest: 0.9264579 (51)\ttotal: 14.4s\tremaining: 1m 36s\n",
      "65: learn: 0.9500379\ttest: 0.9256442\tbestTest: 0.9264579 (51)\ttotal: 14.6s\tremaining: 1m 36s\n",
      "66: learn: 0.9503213\ttest: 0.925737\tbestTest: 0.9264579 (51)\ttotal: 14.8s\tremaining: 1m 35s\n",
      "67: learn: 0.9505183\ttest: 0.925737\tbestTest: 0.9264579 (51)\ttotal: 15s\tremaining: 1m 35s\n",
      "68: learn: 0.950755\ttest: 0.9259141\tbestTest: 0.9264579 (51)\ttotal: 15.2s\tremaining: 1m 34s\n",
      "69: learn: 0.9509654\ttest: 0.9259309\tbestTest: 0.9264579 (51)\ttotal: 15.6s\tremaining: 1m 35s\n",
      "70: learn: 0.9511579\ttest: 0.9258466\tbestTest: 0.9264579 (51)\ttotal: 15.8s\tremaining: 1m 35s\n",
      "71: learn: 0.951351\ttest: 0.9258719\tbestTest: 0.9264579 (51)\ttotal: 15.9s\tremaining: 1m 34s\n",
      "72: learn: 0.9514221\ttest: 0.9258972\tbestTest: 0.9264579 (51)\ttotal: 16.1s\tremaining: 1m 34s\n",
      "73: learn: 0.9515666\ttest: 0.9259436\tbestTest: 0.9264579 (51)\ttotal: 16.4s\tremaining: 1m 34s\n",
      "74: learn: 0.9517914\ttest: 0.9257791\tbestTest: 0.9264579 (51)\ttotal: 16.8s\tremaining: 1m 34s\n",
      "75: learn: 0.9519448\ttest: 0.9258972\tbestTest: 0.9264579 (51)\ttotal: 17s\tremaining: 1m 34s\n",
      "76: learn: 0.9519782\ttest: 0.925952\tbestTest: 0.9264579 (51)\ttotal: 17.2s\tremaining: 1m 34s\n",
      "77: learn: 0.9521962\ttest: 0.9258888\tbestTest: 0.9264579 (51)\ttotal: 17.4s\tremaining: 1m 34s\n",
      "78: learn: 0.9525072\ttest: 0.9260363\tbestTest: 0.9264579 (51)\ttotal: 17.6s\tremaining: 1m 33s\n",
      "79: learn: 0.952648\ttest: 0.9261839\tbestTest: 0.9264579 (51)\ttotal: 18s\tremaining: 1m 34s\n",
      "80: learn: 0.9528116\ttest: 0.9262303\tbestTest: 0.9264579 (51)\ttotal: 18.2s\tremaining: 1m 34s\n",
      "81: learn: 0.9529847\ttest: 0.9259436\tbestTest: 0.9264579 (51)\ttotal: 18.4s\tremaining: 1m 33s\n",
      "82: learn: 0.9531825\ttest: 0.9259857\tbestTest: 0.9264579 (51)\ttotal: 18.6s\tremaining: 1m 33s\n",
      "83: learn: 0.9533648\ttest: 0.9261797\tbestTest: 0.9264579 (51)\ttotal: 18.8s\tremaining: 1m 33s\n",
      "84: learn: 0.953534\ttest: 0.9260869\tbestTest: 0.9264579 (51)\ttotal: 19.2s\tremaining: 1m 33s\n",
      "85: learn: 0.9537152\ttest: 0.9260068\tbestTest: 0.9264579 (51)\ttotal: 19.3s\tremaining: 1m 33s\n",
      "86: learn: 0.9539209\ttest: 0.9260026\tbestTest: 0.9264579 (51)\ttotal: 19.5s\tremaining: 1m 32s\n",
      "87: learn: 0.9540435\ttest: 0.9259647\tbestTest: 0.9264579 (51)\ttotal: 19.7s\tremaining: 1m 32s\n",
      "88: learn: 0.9542763\ttest: 0.9258635\tbestTest: 0.9264579 (51)\ttotal: 19.9s\tremaining: 1m 31s\n",
      "89: learn: 0.9544987\ttest: 0.9259098\tbestTest: 0.9264579 (51)\ttotal: 20.1s\tremaining: 1m 31s\n",
      "90: learn: 0.9545518\ttest: 0.925952\tbestTest: 0.9264579 (51)\ttotal: 20.4s\tremaining: 1m 31s\n",
      "91: learn: 0.9547315\ttest: 0.925699\tbestTest: 0.9264579 (51)\ttotal: 20.6s\tremaining: 1m 31s\n",
      "92: learn: 0.9549319\ttest: 0.9256695\tbestTest: 0.9264579 (51)\ttotal: 20.8s\tremaining: 1m 31s\n",
      "93: learn: 0.955127\ttest: 0.925522\tbestTest: 0.9264579 (51)\ttotal: 21s\tremaining: 1m 30s\n",
      "94: learn: 0.9552484\ttest: 0.9254334\tbestTest: 0.9264579 (51)\ttotal: 21.2s\tremaining: 1m 30s\n",
      "95: learn: 0.9555941\ttest: 0.9252353\tbestTest: 0.9264579 (51)\ttotal: 21.6s\tremaining: 1m 30s\n",
      "96: learn: 0.9558685\ttest: 0.9253449\tbestTest: 0.9264579 (51)\ttotal: 21.8s\tremaining: 1m 30s\n",
      "97: learn: 0.9561522\ttest: 0.9251594\tbestTest: 0.9264579 (51)\ttotal: 22s\tremaining: 1m 30s\n",
      "98: learn: 0.956422\ttest: 0.9249865\tbestTest: 0.9264579 (51)\ttotal: 22.3s\tremaining: 1m 30s\n",
      "99: learn: 0.9566169\ttest: 0.9248474\tbestTest: 0.9264579 (51)\ttotal: 22.4s\tremaining: 1m 29s\n",
      "100: learn: 0.9567172\ttest: 0.9248136\tbestTest: 0.9264579 (51)\ttotal: 22.8s\tremaining: 1m 30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101: learn: 0.9568895\ttest: 0.9249148\tbestTest: 0.9264579 (51)\ttotal: 23s\tremaining: 1m 29s\n",
      "102: learn: 0.9571306\ttest: 0.9250034\tbestTest: 0.9264579 (51)\ttotal: 23.2s\tremaining: 1m 29s\n",
      "103: learn: 0.9574808\ttest: 0.9246872\tbestTest: 0.9264579 (51)\ttotal: 23.5s\tremaining: 1m 29s\n",
      "104: learn: 0.9577193\ttest: 0.9247209\tbestTest: 0.9264579 (51)\ttotal: 23.7s\tremaining: 1m 29s\n",
      "105: learn: 0.9579113\ttest: 0.9246281\tbestTest: 0.9264579 (51)\ttotal: 24.1s\tremaining: 1m 29s\n",
      "106: learn: 0.9579651\ttest: 0.9247504\tbestTest: 0.9264579 (51)\ttotal: 24.3s\tremaining: 1m 29s\n",
      "107: learn: 0.9582669\ttest: 0.9249275\tbestTest: 0.9264579 (51)\ttotal: 24.5s\tremaining: 1m 28s\n",
      "108: learn: 0.9585004\ttest: 0.9249233\tbestTest: 0.9264579 (51)\ttotal: 24.6s\tremaining: 1m 28s\n",
      "109: learn: 0.9589102\ttest: 0.9246703\tbestTest: 0.9264579 (51)\ttotal: 24.8s\tremaining: 1m 28s\n",
      "110: learn: 0.9591403\ttest: 0.9244342\tbestTest: 0.9264579 (51)\ttotal: 25.2s\tremaining: 1m 28s\n",
      "111: learn: 0.959362\ttest: 0.9243962\tbestTest: 0.9264579 (51)\ttotal: 25.4s\tremaining: 1m 28s\n",
      "112: learn: 0.9594878\ttest: 0.9243878\tbestTest: 0.9264579 (51)\ttotal: 25.6s\tremaining: 1m 27s\n",
      "113: learn: 0.9596514\ttest: 0.924215\tbestTest: 0.9264579 (51)\ttotal: 25.8s\tremaining: 1m 27s\n",
      "114: learn: 0.9598245\ttest: 0.9243161\tbestTest: 0.9264579 (51)\ttotal: 26s\tremaining: 1m 27s\n",
      "115: learn: 0.9598298\ttest: 0.9242571\tbestTest: 0.9264579 (51)\ttotal: 26.4s\tremaining: 1m 27s\n",
      "116: learn: 0.960067\ttest: 0.924215\tbestTest: 0.9264579 (51)\ttotal: 26.6s\tremaining: 1m 27s\n",
      "117: learn: 0.9602889\ttest: 0.924059\tbestTest: 0.9264579 (51)\ttotal: 26.8s\tremaining: 1m 26s\n",
      "118: learn: 0.9604799\ttest: 0.9241348\tbestTest: 0.9264579 (51)\ttotal: 27.1s\tremaining: 1m 26s\n",
      "119: learn: 0.9606293\ttest: 0.9241981\tbestTest: 0.9264579 (51)\ttotal: 27.3s\tremaining: 1m 26s\n",
      "120: learn: 0.9608006\ttest: 0.9242023\tbestTest: 0.9264579 (51)\ttotal: 27.6s\tremaining: 1m 26s\n",
      "121: learn: 0.9610859\ttest: 0.9242908\tbestTest: 0.9264579 (51)\ttotal: 27.9s\tremaining: 1m 26s\n",
      "122: learn: 0.9613383\ttest: 0.9242908\tbestTest: 0.9264579 (51)\ttotal: 28.1s\tremaining: 1m 26s\n",
      "123: learn: 0.9614961\ttest: 0.9243035\tbestTest: 0.9264579 (51)\ttotal: 28.3s\tremaining: 1m 25s\n",
      "124: learn: 0.9617735\ttest: 0.9241854\tbestTest: 0.9264579 (51)\ttotal: 28.5s\tremaining: 1m 25s\n",
      "125: learn: 0.9620567\ttest: 0.9240716\tbestTest: 0.9264579 (51)\ttotal: 28.9s\tremaining: 1m 25s\n",
      "126: learn: 0.9622124\ttest: 0.9241939\tbestTest: 0.9264579 (51)\ttotal: 29.1s\tremaining: 1m 25s\n",
      "127: learn: 0.9623732\ttest: 0.924177\tbestTest: 0.9264579 (51)\ttotal: 29.3s\tremaining: 1m 25s\n",
      "128: learn: 0.962634\ttest: 0.9241222\tbestTest: 0.9264579 (51)\ttotal: 29.5s\tremaining: 1m 24s\n",
      "129: learn: 0.9627971\ttest: 0.9239789\tbestTest: 0.9264579 (51)\ttotal: 29.7s\tremaining: 1m 24s\n",
      "130: learn: 0.9629224\ttest: 0.924118\tbestTest: 0.9264579 (51)\ttotal: 30s\tremaining: 1m 24s\n",
      "131: learn: 0.9630745\ttest: 0.9239662\tbestTest: 0.9264579 (51)\ttotal: 30.2s\tremaining: 1m 24s\n",
      "132: learn: 0.9632807\ttest: 0.9240294\tbestTest: 0.9264579 (51)\ttotal: 30.4s\tremaining: 1m 23s\n",
      "133: learn: 0.9634338\ttest: 0.9239831\tbestTest: 0.9264579 (51)\ttotal: 30.6s\tremaining: 1m 23s\n",
      "134: learn: 0.9636384\ttest: 0.9239493\tbestTest: 0.9264579 (51)\ttotal: 30.9s\tremaining: 1m 23s\n",
      "135: learn: 0.9638021\ttest: 0.9241096\tbestTest: 0.9264579 (51)\ttotal: 31.2s\tremaining: 1m 23s\n",
      "136: learn: 0.9639689\ttest: 0.9240421\tbestTest: 0.9264579 (51)\ttotal: 31.4s\tremaining: 1m 23s\n",
      "137: learn: 0.9640343\ttest: 0.9240674\tbestTest: 0.9264579 (51)\ttotal: 31.6s\tremaining: 1m 22s\n",
      "138: learn: 0.9642415\ttest: 0.9239831\tbestTest: 0.9264579 (51)\ttotal: 31.9s\tremaining: 1m 22s\n",
      "139: learn: 0.964515\ttest: 0.9238987\tbestTest: 0.9264579 (51)\ttotal: 32.1s\tremaining: 1m 22s\n",
      "140: learn: 0.9647577\ttest: 0.923806\tbestTest: 0.9264579 (51)\ttotal: 32.5s\tremaining: 1m 22s\n",
      "141: learn: 0.9648651\ttest: 0.9238229\tbestTest: 0.9264579 (51)\ttotal: 32.7s\tremaining: 1m 22s\n",
      "142: learn: 0.965087\ttest: 0.9238945\tbestTest: 0.9264579 (51)\ttotal: 32.9s\tremaining: 1m 22s\n",
      "143: learn: 0.9653355\ttest: 0.9238355\tbestTest: 0.9264579 (51)\ttotal: 33.1s\tremaining: 1m 21s\n",
      "144: learn: 0.9654233\ttest: 0.923806\tbestTest: 0.9264579 (51)\ttotal: 33.3s\tremaining: 1m 21s\n",
      "145: learn: 0.965569\ttest: 0.9240885\tbestTest: 0.9264579 (51)\ttotal: 33.7s\tremaining: 1m 21s\n",
      "146: learn: 0.9658477\ttest: 0.9242698\tbestTest: 0.9264579 (51)\ttotal: 34s\tremaining: 1m 21s\n",
      "147: learn: 0.9658703\ttest: 0.9242571\tbestTest: 0.9264579 (51)\ttotal: 34.2s\tremaining: 1m 21s\n",
      "148: learn: 0.9661414\ttest: 0.9241222\tbestTest: 0.9264579 (51)\ttotal: 34.4s\tremaining: 1m 20s\n",
      "149: learn: 0.9662323\ttest: 0.9241433\tbestTest: 0.9264579 (51)\ttotal: 34.5s\tremaining: 1m 20s\n",
      "150: learn: 0.9664069\ttest: 0.9243204\tbestTest: 0.9264579 (51)\ttotal: 34.9s\tremaining: 1m 20s\n",
      "151: learn: 0.966523\ttest: 0.924333\tbestTest: 0.9264579 (51)\ttotal: 35.1s\tremaining: 1m 20s\n",
      "152: learn: 0.96673\ttest: 0.9244637\tbestTest: 0.9264579 (51)\ttotal: 35.3s\tremaining: 1m 20s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9264579398\n",
      "bestIteration = 51\n",
      "\n",
      "Depth :  6\n",
      "Train and Test loss :  0.966730012805 0.924463707501\n",
      "[0.94201687457107108, 0.93540491922371738, 0.94254436265821473, 0.93164783148417796, 0.92446370750134921]\n",
      "0.934300527164\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "pred_val_full = np.zeros(train_X.shape[0])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val, loss, pred_test = runCatB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_val_full[val_index] = pred_val\n",
    "    pred_test_full = pred_test_full + pred_test\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5.\n",
    "print(metrics.roc_auc_score(train_y, pred_val_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'UniqueID':test['UniqueID']})\n",
    "sub['Probability1'] = pred_test_full\n",
    "sub.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
